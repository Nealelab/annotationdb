

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>hail.dataset &mdash; Hail</title>
  

  
  
    <link rel="shortcut icon" href="../../hail_logo_sq.png"/>
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  

  
    <link rel="stylesheet" href="../../navbar.css" type="text/css" />
  
    <link rel="stylesheet" href="../../_static/rtd_modifications.css" type="text/css" />
  

  
        <link rel="index" title="Index"
              href="../../genindex.html"/>
        <link rel="search" title="Search" href="../../search.html"/>
    <link rel="top" title="Hail" href="../../index.html"/>
        <link rel="up" title="Module code" href="../index.html"/> 

  
  <script src="../../_static/js/modernizr.min.js"></script>
  
  

</head>

<body class="wy-body-for-nav" role="document">

  <nav class="navbar navbar-default navbar-static-top" id="hail-navbar">
<div class="container-fluid" id="hail-container-fluid">
    <div class="navbar-header" id="hail-navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#hail-navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
   
      <a class="navbar-left" id="hail-navbar-brand" href="../index.html"><img alt="Hail" id="logo" src="hail-logo-cropped.png"></a>

    </div>

    <div class="collapse navbar-collapse" id="hail-navbar-collapse">
      <ul class="nav navbar-nav navbar-right">
          <li id="home" class="nav-item"><a href="../index.html">HOME</a></li>
          <li id="docs" class="nav-item"><a href="index.html">DOCS</a></li>
          <li id="forum" class="nav-item"><a href="http://discuss.hail.is">FORUM</a></li>
          <li id="chat" class="nav-item dropdown">
          <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">CHAT<span class="caret"></span></a>
          <ul class="dropdown-menu dropdown-menu-left">
            <li><a class="dropdown-item" href="https://gitter.im/hail-is/hail">General</a></li>
            <li><a class="dropdown-item" href="https://gitter.im/hail-is/hail-dev">Developers</a></li>
          </ul>
        </li>
       <li id="code" class="nav-item"><a href="https://github.com/hail-is/hail">CODE</a></li>
      </ul>
    </div>
  </div>
</nav>

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../index.html" class="icon icon-home"> Hail
          

          
          </a>

          
            
            
              <div class="version">
                devel
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorial.html">Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../exprlang.html">Expression Language</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../annotationdb.html">Annotation Database</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../other_resources.html">Other Resources</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../../index.html">Hail</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../index.html">Module code</a> &raquo;</li>
        
      <li>hail.dataset</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for hail.dataset</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">print_function</span>  <span class="c1"># Python 2 and 3 print compatibility</span>

<span class="kn">from</span> <span class="nn">hail.java</span> <span class="k">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">hail.keytable</span> <span class="k">import</span> <span class="n">KeyTable</span>
<span class="kn">from</span> <span class="nn">hail.expr</span> <span class="k">import</span> <span class="n">Type</span><span class="p">,</span> <span class="n">TGenotype</span><span class="p">,</span> <span class="n">TVariant</span>
<span class="kn">from</span> <span class="nn">hail.representation</span> <span class="k">import</span> <span class="n">Interval</span><span class="p">,</span> <span class="n">IntervalTree</span>
<span class="kn">from</span> <span class="nn">hail.utils</span> <span class="k">import</span> <span class="n">TextTableConfig</span><span class="p">,</span> <span class="n">Summary</span>
<span class="kn">from</span> <span class="nn">hail.kinshipMatrix</span> <span class="k">import</span> <span class="n">KinshipMatrix</span>
<span class="kn">from</span> <span class="nn">py4j.protocol</span> <span class="k">import</span> <span class="n">Py4JJavaError</span>
<span class="kn">from</span> <span class="nn">decorator</span> <span class="k">import</span> <span class="n">decorator</span>

<span class="kn">import</span> <span class="nn">warnings</span>

<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="n">module</span><span class="o">=</span><span class="n">__name__</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="s1">&#39;once&#39;</span><span class="p">)</span>


<span class="nd">@decorator</span>
<span class="k">def</span> <span class="nf">requireTGenotype</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">vds</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">vds</span><span class="o">.</span><span class="n">_is_generic_genotype</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">vds</span><span class="o">.</span><span class="n">genotype_schema</span><span class="p">,</span> <span class="n">TGenotype</span><span class="p">):</span>
            <span class="n">coerced_vds</span> <span class="o">=</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="n">vds</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">vds</span><span class="o">.</span><span class="n">_jvdf</span><span class="o">.</span><span class="n">toVDS</span><span class="p">())</span>
            <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="n">coerced_vds</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Genotype signature must be of type TGenotype, but found &#39;</span><span class="si">%s</span><span class="s2">&#39;&quot;</span> <span class="o">%</span> <span class="nb">type</span><span class="p">(</span><span class="n">vds</span><span class="o">.</span><span class="n">genotype_schema</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="n">vds</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>


<span class="nd">@decorator</span>
<span class="k">def</span> <span class="nf">convertVDS</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">vds</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">vds</span><span class="o">.</span><span class="n">_is_generic_genotype</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">vds</span><span class="o">.</span><span class="n">genotype_schema</span><span class="p">,</span> <span class="n">TGenotype</span><span class="p">):</span>
            <span class="n">vds</span> <span class="o">=</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="n">vds</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">vds</span><span class="o">.</span><span class="n">_jvdf</span><span class="o">.</span><span class="n">toVDS</span><span class="p">())</span>

    <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="n">vds</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>


<div class="viewcode-block" id="VariantDataset"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset">[docs]</a><span class="k">class</span> <span class="nc">VariantDataset</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Hail&#39;s primary representation of genomic data, a matrix keyed by sample and variant.</span>

<span class="sd">    Variant datasets may be generated from other formats using the :py:class:`.HailContext` import methods,</span>
<span class="sd">    constructed from a variant-keyed :py:class:`KeyTable` using :py:meth:`.VariantDataset.from_keytable`,</span>
<span class="sd">    and simulated using :py:meth:`~hail.HailContext.balding_nichols_model`.</span>

<span class="sd">    Once a variant dataset has been written to disk with :py:meth:`~hail.VariantDataset.write`,</span>
<span class="sd">    use :py:meth:`~hail.HailContext.read` to load the variant dataset into the environment.</span>

<span class="sd">    &gt;&gt;&gt; vds = hc.read(&quot;data/example.vds&quot;)</span>

<span class="sd">    :ivar hc: Hail Context</span>
<span class="sd">    :vartype hc: :class:`.HailContext`</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hc</span><span class="p">,</span> <span class="n">jvds</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hc</span> <span class="o">=</span> <span class="n">hc</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span> <span class="o">=</span> <span class="n">jvds</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_globals</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_sample_annotations</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_sa_schema</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_va_schema</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_global_schema</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_genotype_schema</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_sample_ids</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_num_samples</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_jvdf_cache</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nd">@staticmethod</span>
    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.from_keytable"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.from_keytable">[docs]</a>    <span class="k">def</span> <span class="nf">from_keytable</span><span class="p">(</span><span class="n">key_table</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Construct a sites-only variant dataset from a key table.</span>

<span class="sd">        The key table must be keyed by one column of type :py:class:`.TVariant`.</span>

<span class="sd">        All columns in the key table become variant annotations in the result.</span>
<span class="sd">        For example, a key table with key column ``v`` (*Variant*) and column</span>
<span class="sd">        ``gene`` (*String*) will produce a sites-only variant dataset with a</span>
<span class="sd">        ``va.gene`` variant annotation.</span>

<span class="sd">        :param key_table: variant-keyed key table</span>
<span class="sd">        :type key_table: :py:class:`.KeyTable`</span>

<span class="sd">        :return: Sites-only variant dataset.</span>
<span class="sd">        :rtype: :py:class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key_table</span><span class="p">,</span> <span class="n">KeyTable</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;parameter `key_table&#39; must be a KeyTable, but found </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="nb">type</span><span class="p">(</span><span class="n">key_table</span><span class="p">))</span>
        <span class="n">jvds</span> <span class="o">=</span> <span class="n">scala_object</span><span class="p">(</span><span class="n">Env</span><span class="o">.</span><span class="n">hail</span><span class="p">()</span><span class="o">.</span><span class="n">variant</span><span class="p">,</span> <span class="s1">&#39;VariantDataset&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">fromKeyTable</span><span class="p">(</span><span class="n">key_table</span><span class="o">.</span><span class="n">_jkt</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="n">key_table</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">jvds</span><span class="p">)</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_jvdf</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvdf_cache</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_generic_genotype</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_jvdf_cache</span> <span class="o">=</span> <span class="n">Env</span><span class="o">.</span><span class="n">hail</span><span class="p">()</span><span class="o">.</span><span class="n">variant</span><span class="o">.</span><span class="n">GenericDatasetFunctions</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_jvdf_cache</span> <span class="o">=</span> <span class="n">Env</span><span class="o">.</span><span class="n">hail</span><span class="p">()</span><span class="o">.</span><span class="n">variant</span><span class="o">.</span><span class="n">VariantDatasetFunctions</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvdf_cache</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_is_generic_genotype</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">isGenericGenotype</span><span class="p">()</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">sample_ids</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return sampleIDs.</span>

<span class="sd">        :return: List of sample IDs.</span>
<span class="sd">        :rtype: list of str</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sample_ids</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_sample_ids</span> <span class="o">=</span> <span class="n">jiterable_to_list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">sampleIds</span><span class="p">())</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sample_ids</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">sample_annotations</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return a dict of sample annotations.</span>

<span class="sd">        The keys of this dictionary are the sample IDs (strings).</span>
<span class="sd">        The values are sample annotations.</span>

<span class="sd">        :return: dict</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sample_annotations</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">zipped_annotations</span> <span class="o">=</span> <span class="n">Env</span><span class="o">.</span><span class="n">jutils</span><span class="p">()</span><span class="o">.</span><span class="n">iterableToArrayList</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">sampleIdsAndAnnotations</span><span class="p">()</span>
            <span class="p">)</span>
            <span class="n">r</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">element</span> <span class="ow">in</span> <span class="n">zipped_annotations</span><span class="p">:</span>
                <span class="n">r</span><span class="p">[</span><span class="n">element</span><span class="o">.</span><span class="n">_1</span><span class="p">()]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_schema</span><span class="o">.</span><span class="n">_convert_to_py</span><span class="p">(</span><span class="n">element</span><span class="o">.</span><span class="n">_2</span><span class="p">())</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_sample_annotations</span> <span class="o">=</span> <span class="n">r</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sample_annotations</span>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.num_partitions"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.num_partitions">[docs]</a>    <span class="k">def</span> <span class="nf">num_partitions</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Number of partitions.</span>

<span class="sd">        **Notes**</span>

<span class="sd">        The data in a variant dataset is divided into chunks called partitions, which may be stored together or across a network, so that each partition may be read and processed in parallel by available cores. Partitions are a core concept of distributed computation in Spark, see `here &lt;http://spark.apache.org/docs/latest/programming-guide.html#resilient-distributed-datasets-rdds&gt;`_ for details.</span>

<span class="sd">        :rtype: int</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">nPartitions</span><span class="p">()</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">num_samples</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Number of samples.</span>

<span class="sd">        :rtype: int</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_samples</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_num_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">nSamples</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_samples</span>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.count_variants"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.count_variants">[docs]</a>    <span class="k">def</span> <span class="nf">count_variants</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Count number of variants in variant dataset.</span>

<span class="sd">        :rtype: long</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">countVariants</span><span class="p">()</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.was_split"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.was_split">[docs]</a>    <span class="k">def</span> <span class="nf">was_split</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;True if multiallelic variants have been split into multiple biallelic variants.</span>

<span class="sd">        Result is True if :py:meth:`~hail.VariantDataset.split_multi` or :py:meth:`~hail.VariantDataset.filter_multi` has been called on this variant dataset,</span>
<span class="sd">        or if the variant dataset was imported with :py:meth:`~hail.HailContext.import_plink`, :py:meth:`~hail.HailContext.import_gen`,</span>
<span class="sd">        or :py:meth:`~hail.HailContext.import_bgen`, or if the variant dataset was simulated with :py:meth:`~hail.HailContext.balding_nichols_model`.</span>

<span class="sd">        :rtype: bool</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">wasSplit</span><span class="p">()</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.is_dosage"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.is_dosage">[docs]</a>    <span class="k">def</span> <span class="nf">is_dosage</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;True if genotype probabilities are dosages.</span>

<span class="sd">        The result of ``is_dosage()`` will be True if the variant dataset was imported with :py:meth:`~hail.HailContext.import_gen` or</span>
<span class="sd">        :py:meth:`~hail.HailContext.import_bgen`.</span>

<span class="sd">        :rtype: bool</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">isDosage</span><span class="p">()</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.file_version"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.file_version">[docs]</a>    <span class="k">def</span> <span class="nf">file_version</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;File version of variant dataset.</span>

<span class="sd">        :rtype: int</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">fileVersion</span><span class="p">()</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.aggregate_by_key"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.aggregate_by_key">[docs]</a>    <span class="k">def</span> <span class="nf">aggregate_by_key</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key_code</span><span class="p">,</span> <span class="n">agg_code</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Aggregate by user-defined key and aggregation expressions to produce a KeyTable.</span>
<span class="sd">        Equivalent to a group-by operation in SQL.</span>

<span class="sd">        **Examples**</span>

<span class="sd">        Compute the number of LOF heterozygote calls per gene per sample:</span>

<span class="sd">        &gt;&gt;&gt; kt_result = (vds</span>
<span class="sd">        ...     .aggregate_by_key([&#39;Sample = s&#39;, &#39;Gene = va.gene&#39;],</span>
<span class="sd">        ...                        &#39;nHet = g.filter(g =&gt; g.isHet() &amp;&amp; va.consequence == &quot;LOF&quot;).count()&#39;)</span>
<span class="sd">        ...     .export(&quot;test.tsv&quot;))</span>

<span class="sd">        This will produce a :class:`KeyTable` with 3 columns (`Sample`, `Gene`, `nHet`).</span>

<span class="sd">        :param key_code: Named expression(s) for which fields are keys.</span>
<span class="sd">        :type key_code: str or list of str</span>

<span class="sd">        :param agg_code: Named aggregation expression(s).</span>
<span class="sd">        :type agg_code: str or list of str</span>

<span class="sd">        :rtype: :class:`.KeyTable`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key_code</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">key_code</span> <span class="o">=</span> <span class="s2">&quot;,&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">key_code</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">agg_code</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">agg_code</span> <span class="o">=</span> <span class="s2">&quot;,&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">agg_code</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">KeyTable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">aggregateByKey</span><span class="p">(</span><span class="n">key_code</span><span class="p">,</span> <span class="n">agg_code</span><span class="p">))</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.aggregate_intervals"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.aggregate_intervals">[docs]</a>    <span class="k">def</span> <span class="nf">aggregate_intervals</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">expr</span><span class="p">,</span> <span class="n">output</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;Aggregate over intervals and export.</span>

<span class="sd">        **Examples**</span>

<span class="sd">        Calculate the total number of SNPs, indels, and variants contained in</span>
<span class="sd">        the intervals specified by *data/capture_intervals.txt*:</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds.aggregate_intervals(&#39;data/capture_intervals.txt&#39;,</span>
<span class="sd">        ...   &#39;n_SNP = variants.filter(v =&gt; v.altAllele().isSNP()).count(), &#39; +</span>
<span class="sd">        ...   &#39;n_indel = variants.filter(v =&gt; v.altAllele().isIndel()).count(), &#39; +</span>
<span class="sd">        ...   &#39;n_total = variants.count()&#39;,</span>
<span class="sd">        ...   &#39;output/out.txt&#39;)</span>

<span class="sd">        If *data/capture_intervals.txt* contains:</span>

<span class="sd">        .. code-block:: text</span>

<span class="sd">            4:1500-123123</span>
<span class="sd">            5:1-1000000</span>
<span class="sd">            16:29500000-30200000</span>

<span class="sd">        then the previous expression writes something like the following to</span>
<span class="sd">        *out.txt*:</span>

<span class="sd">        .. code-block:: text</span>

<span class="sd">            Contig    Start       End         n_SNP   n_indel     n_total</span>
<span class="sd">            4         1500        123123      502     51          553</span>
<span class="sd">            5         1           1000000     25024   4500        29524</span>
<span class="sd">            16        29500000    30200000    17222   2021        19043</span>

<span class="sd">        The parameter ``expr`` defines the names of the column headers (in</span>
<span class="sd">        the previous case: ``n_SNP``, ``n_indel``, ``n_total``) and how to</span>
<span class="sd">        calculate the value of that column for each interval.</span>

<span class="sd">        Count the number of LOF, missense, and synonymous non-reference calls</span>
<span class="sd">        per interval:</span>

<span class="sd">        &gt;&gt;&gt; vds_result = (vds.annotate_variants_expr(&#39;va.n_calls = gs.filter(g =&gt; g.isCalledNonRef()).count()&#39;)</span>
<span class="sd">        ...     .aggregate_intervals(&#39;data/intervals.txt&#39;,</span>
<span class="sd">        ...            &#39;LOF_CALLS = variants.filter(v =&gt; va.consequence == &quot;LOF&quot;).map(v =&gt; va.n_calls).sum(), &#39; +</span>
<span class="sd">        ...            &#39;MISSENSE_CALLS = variants.filter(v =&gt; va.consequence == &quot;missense&quot;).map(v =&gt; va.n_calls).sum(), &#39; +</span>
<span class="sd">        ...            &#39;SYN_CALLS = variants.filter(v =&gt; va.consequence == &quot;synonymous&quot;).map(v =&gt; va.n_calls).sum()&#39;,</span>
<span class="sd">        ...            &#39;output/out.txt&#39;))</span>

<span class="sd">        If *data/intervals.txt* contains:</span>

<span class="sd">        .. code-block:: text</span>

<span class="sd">            4:1500-123123</span>
<span class="sd">            5:1-1000000</span>
<span class="sd">            16:29500000-30200000</span>

<span class="sd">        then the previous expression writes something like the following to</span>
<span class="sd">        *out.txt*:</span>

<span class="sd">        .. code-block:: text</span>

<span class="sd">            Contig    Start       End         LOF_CALLS   MISSENSE_CALLS   SYN_CALLS</span>
<span class="sd">            4         1500        123123      42          122              553</span>
<span class="sd">            5         1           1000000     3           12               66</span>
<span class="sd">            16        29500000    30200000    17          22               202</span>

<span class="sd">        **Notes**</span>

<span class="sd">        Intervals are **left inclusive, right exclusive**.  This means that</span>
<span class="sd">        [chr1:1, chr1:3) contains chr1:1 and chr1:2.</span>

<span class="sd">        **Designating output with an expression**</span>

<span class="sd">        An export expression designates a list of computations to perform, and</span>
<span class="sd">        what these columns are named.  These expressions should take the form</span>
<span class="sd">        ``COL_NAME_1 = &lt;expression&gt;, COL_NAME_2 = &lt;expression&gt;, ...``.</span>

<span class="sd">        ``expr`` has the following symbols in scope:</span>

<span class="sd">        - ``interval`` (*Interval*): genomic interval</span>
<span class="sd">        - ``global``: global annotations</span>
<span class="sd">        - ``variants`` (*Aggregable[Variant]*): aggregable of :py:class:`~hail.representation.Variant` s Aggregator namespace below.</span>

<span class="sd">        The ``variants`` aggregator has the following namespace:</span>

<span class="sd">        - ``v`` (*Variant*): :ref:`variant`</span>
<span class="sd">        - ``va``: variant annotations</span>
<span class="sd">        - ``global``: Global annotations</span>

<span class="sd">        :param str input: Input interval list file.</span>

<span class="sd">        :param str expr: Export expression.</span>

<span class="sd">        :param str output: Output file.</span>
<span class="sd">        &#39;&#39;&#39;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">aggregateIntervals</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">expr</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
    <span class="nd">@requireTGenotype</span>
<div class="viewcode-block" id="VariantDataset.annotate_alleles_expr"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.annotate_alleles_expr">[docs]</a>    <span class="k">def</span> <span class="nf">annotate_alleles_expr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">expr</span><span class="p">,</span> <span class="n">propagate_gq</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Annotate alleles with expression.</span>

<span class="sd">        .. include:: requireTGenotype.rst</span>

<span class="sd">        **Examples**</span>

<span class="sd">        To create a variant annotation ``va.nNonRefSamples: Array[Int]`` where the ith entry of</span>
<span class="sd">        the array is the number of samples carrying the ith alternate allele:</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds.annotate_alleles_expr(&#39;va.nNonRefSamples = gs.filter(g =&gt; g.isCalledNonRef()).count()&#39;)</span>

<span class="sd">        **Notes**</span>

<span class="sd">        This command is similar to :py:meth:`.annotate_variants_expr`. :py:meth:`.annotate_alleles_expr` dynamically splits multi-allelic sites,</span>
<span class="sd">        evaluates each expression on each split allele separately, and for each expression annotates with an array with one element per alternate allele. In the splitting, genotypes are downcoded and each alternate allele is represented</span>
<span class="sd">        using its minimal representation (see :py:meth:`split_multi` for more details).</span>


<span class="sd">        :param expr: Annotation expression.</span>
<span class="sd">        :type expr: str or list of str</span>
<span class="sd">        :param bool propagate_gq: Propagate GQ instead of computing from (split) PL.</span>

<span class="sd">        :return: Annotated variant dataset.</span>
<span class="sd">        :rtype: :py:class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">expr</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">expr</span> <span class="o">=</span> <span class="s2">&quot;,&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">expr</span><span class="p">)</span>

        <span class="n">jvds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvdf</span><span class="o">.</span><span class="n">annotateAllelesExpr</span><span class="p">(</span><span class="n">expr</span><span class="p">,</span> <span class="n">propagate_gq</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">jvds</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.annotate_genotypes_expr"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.annotate_genotypes_expr">[docs]</a>    <span class="k">def</span> <span class="nf">annotate_genotypes_expr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">expr</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Annotate genotypes with expression.</span>

<span class="sd">        **Examples**</span>

<span class="sd">        Convert the genotype schema to a :py:class:`~hail.expr.TStruct` with two fields ``GT`` and ``CASE_HET``:</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds.annotate_genotypes_expr(&#39;g = {GT: g.gt, CASE_HET: sa.pheno.isCase &amp;&amp; g.isHet()}&#39;)</span>

<span class="sd">        Assume a VCF is imported with ``generic=True`` and the resulting genotype schema</span>
<span class="sd">        is a ``Struct`` and the field ``GTA`` is a ``Call`` type. Use the ``.toGenotype()`` method in the</span>
<span class="sd">        expression language to convert a ``Call`` to a ``Genotype``. ``vds_gta`` will have a genotype schema equal to</span>
<span class="sd">        :py:class:`~hail.expr.TGenotype`</span>

<span class="sd">        &gt;&gt;&gt; vds_gta = (hc.import_vcf(&#39;data/example3.vcf.bgz&#39;, generic=True, call_fields=[&#39;GTA&#39;])</span>
<span class="sd">        ...                 .annotate_genotypes_expr(&#39;g = g.GTA.toGenotype()&#39;))</span>

<span class="sd">        **Notes**</span>

<span class="sd">        :py:meth:`~hail.VariantDataset.annotate_genotypes_expr` evaluates the expression given by ``expr`` and assigns</span>
<span class="sd">        the result of the right hand side to the annotation path specified by the left-hand side (must</span>
<span class="sd">        begin with ``g``). This is analogous to :py:meth:`~hail.VariantDataset.annotate_variants_expr` and</span>
<span class="sd">        :py:meth:`~hail.VariantDataset.annotate_samples_expr` where the annotation paths are ``va`` and ``sa`` respectively.</span>

<span class="sd">        ``expr`` is in genotype context so the following symbols are in scope:</span>

<span class="sd">          - ``g``: genotype annotation</span>
<span class="sd">          - ``v`` (*Variant*): :ref:`variant`</span>
<span class="sd">          - ``va``: variant annotations</span>
<span class="sd">          - ``s`` (*Sample*): :ref:`sample`</span>
<span class="sd">          - ``sa``: sample annotations</span>
<span class="sd">          - ``global``: global annotations</span>

<span class="sd">        For more information, see the documentation on writing `expressions &lt;overview.html#expressions&gt;`_</span>
<span class="sd">        and using the `Hail Expression Language &lt;exprlang.html&gt;`_.</span>

<span class="sd">        .. warning::</span>

<span class="sd">            - If the resulting genotype schema is not :py:class:`~hail.expr.TGenotype`,</span>
<span class="sd">              subsequent function calls on the annotated variant dataset may not work such as</span>
<span class="sd">              :py:meth:`~hail.VariantDataset.pca` and :py:meth:`~hail.VariantDataset.linreg`.</span>

<span class="sd">            - Hail performance may be significantly slower if the annotated variant dataset does not have a</span>
<span class="sd">              genotype schema equal to :py:class:`~hail.expr.TGenotype`.</span>

<span class="sd">            - Genotypes are immutable. For example, if ``g`` is initially of type ``Genotype``, the expression</span>
<span class="sd">              ``g.gt = g.gt + 1`` will return a ``Struct`` with one field ``gt`` of type ``Int`` and **NOT** a ``Genotype``</span>
<span class="sd">              with the ``gt`` incremented by 1.</span>

<span class="sd">        :param expr: Annotation expression.</span>
<span class="sd">        :type expr: str or list of str</span>

<span class="sd">        :return: Annotated variant dataset.</span>
<span class="sd">        :rtype: :py:class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">expr</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">expr</span> <span class="o">=</span> <span class="s2">&quot;,&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">expr</span><span class="p">)</span>

        <span class="n">jvds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvdf</span><span class="o">.</span><span class="n">annotateGenotypesExpr</span><span class="p">(</span><span class="n">expr</span><span class="p">)</span>
        <span class="n">vds</span> <span class="o">=</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">jvds</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">vds</span><span class="o">.</span><span class="n">genotype_schema</span><span class="p">,</span> <span class="n">TGenotype</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">vds</span><span class="o">.</span><span class="n">_jvdf</span><span class="o">.</span><span class="n">toVDS</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">vds</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.annotate_global_expr"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.annotate_global_expr">[docs]</a>    <span class="k">def</span> <span class="nf">annotate_global_expr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">expr</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Annotate global with expression.</span>

<span class="sd">        **Example**</span>

<span class="sd">        Annotate global with an array of populations:</span>

<span class="sd">        &gt;&gt;&gt; vds = vds.annotate_global_expr(&#39;global.pops = [&quot;FIN&quot;, &quot;AFR&quot;, &quot;EAS&quot;, &quot;NFE&quot;]&#39;)</span>

<span class="sd">        Create, then overwrite, then drop a global annotation:</span>

<span class="sd">        &gt;&gt;&gt; vds = vds.annotate_global_expr(&#39;global.pops = [&quot;FIN&quot;, &quot;AFR&quot;, &quot;EAS&quot;]&#39;)</span>
<span class="sd">        &gt;&gt;&gt; vds = vds.annotate_global_expr(&#39;global.pops = [&quot;FIN&quot;, &quot;AFR&quot;, &quot;EAS&quot;, &quot;NFE&quot;]&#39;)</span>
<span class="sd">        &gt;&gt;&gt; vds = vds.annotate_global_expr(&#39;global.pops = drop(global, pops)&#39;)</span>

<span class="sd">        The expression namespace contains only one variable:</span>

<span class="sd">        - ``global``: global annotations</span>

<span class="sd">        :param expr: Annotation expression</span>
<span class="sd">        :type expr: str or list of str</span>

<span class="sd">        :return: Annotated variant dataset.</span>
<span class="sd">        :rtype: :py:class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">expr</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">expr</span> <span class="o">=</span> <span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">expr</span><span class="p">)</span>

        <span class="n">jvds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">annotateGlobalExpr</span><span class="p">(</span><span class="n">expr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">jvds</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.annotate_global_py"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.annotate_global_py">[docs]</a>    <span class="k">def</span> <span class="nf">annotate_global_py</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">annotation</span><span class="p">,</span> <span class="n">annotation_type</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Annotate global from Python objects.</span>

<span class="sd">        **Example**</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds.annotate_global_py(&#39;global.populations&#39;,</span>
<span class="sd">        ...                                     [&#39;EAS&#39;, &#39;AFR&#39;, &#39;EUR&#39;, &#39;SAS&#39;, &#39;AMR&#39;],</span>
<span class="sd">        ...                                     TArray(TString()))</span>

<span class="sd">        **Notes**</span>

<span class="sd">        This method registers new global annotations in a VDS. These annotations</span>
<span class="sd">        can then be accessed through expressions in downstream operations. The</span>
<span class="sd">        Hail data type must be provided and must match the given ``annotation``</span>
<span class="sd">        parameter.</span>

<span class="sd">        :param str path: annotation path starting in &#39;global&#39;</span>

<span class="sd">        :param annotation: annotation to add to global</span>

<span class="sd">        :param annotation_type: Hail type of annotation</span>
<span class="sd">        :type annotation_type: :py:class:`.Type`</span>

<span class="sd">        :return: Annotated variant dataset.</span>
<span class="sd">        :rtype: :py:class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">annotation_type</span><span class="o">.</span><span class="n">_typecheck</span><span class="p">(</span><span class="n">annotation</span><span class="p">)</span>

        <span class="n">annotated</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">annotateGlobal</span><span class="p">(</span><span class="n">annotation_type</span><span class="o">.</span><span class="n">_convert_to_j</span><span class="p">(</span><span class="n">annotation</span><span class="p">),</span> <span class="n">annotation_type</span><span class="o">.</span><span class="n">_jtype</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">annotated</span><span class="o">.</span><span class="n">globalSignature</span><span class="p">()</span><span class="o">.</span><span class="n">typeCheck</span><span class="p">(</span><span class="n">annotated</span><span class="o">.</span><span class="n">globalAnnotation</span><span class="p">()),</span> <span class="s1">&#39;error in java type checking&#39;</span>
        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">annotated</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.annotate_global_list"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.annotate_global_list">[docs]</a>    <span class="k">def</span> <span class="nf">annotate_global_list</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">root</span><span class="p">,</span> <span class="n">as_set</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Load text file into global annotations as Array[String] or</span>
<span class="sd">        Set[String].</span>

<span class="sd">        **Examples**</span>

<span class="sd">        Add a list of genes in a file to global annotations:</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds.annotate_global_list(&#39;data/genes.txt&#39;, &#39;global.genes&#39;)</span>

<span class="sd">        For the gene list</span>

<span class="sd">        .. code-block:: text</span>

<span class="sd">            $ cat data/genes.txt</span>
<span class="sd">            SCN2A</span>
<span class="sd">            SONIC-HEDGEHOG</span>
<span class="sd">            PRNP</span>

<span class="sd">        this adds ``global.genes: Array[String]`` with value ``[&quot;SCN2A&quot;, &quot;SONIC-HEDGEHOG&quot;, &quot;PRNP&quot;]``.</span>

<span class="sd">        To filter to those variants in genes listed in *genes.txt* given a variant annotation ``va.gene: String``, annotate as type ``Set[String]`` instead:</span>

<span class="sd">        &gt;&gt;&gt; vds_result = (vds.annotate_global_list(&#39;data/genes.txt&#39;, &#39;global.genes&#39;, as_set=True)</span>
<span class="sd">        ...     .filter_variants_expr(&#39;global.genes.contains(va.gene)&#39;))</span>

<span class="sd">        :param str input: Input text file.</span>

<span class="sd">        :param str root: Global annotation path to store text file.</span>

<span class="sd">        :param bool as_set: If True, load text file as Set[String],</span>
<span class="sd">            otherwise, load as Array[String].</span>

<span class="sd">        :return: Annotated variant dataset with new global annotation given by the list.</span>
<span class="sd">        :rtype: :class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">jvds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">annotateGlobalList</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">root</span><span class="p">,</span> <span class="n">as_set</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">jvds</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.annotate_global_table"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.annotate_global_table">[docs]</a>    <span class="k">def</span> <span class="nf">annotate_global_table</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">root</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">TextTableConfig</span><span class="p">()):</span>
        <span class="sd">&quot;&quot;&quot;Load delimited text file (text table) into global annotations as</span>
<span class="sd">        Array[Struct].</span>

<span class="sd">        **Examples**</span>

<span class="sd">        Load a file as a global annotation.  Consider the file *data/genes_pli_exac.txt* with contents:</span>

<span class="sd">        .. code-block:: text</span>

<span class="sd">          GENE    PLI     EXAC_LOF_COUNT</span>
<span class="sd">          Gene1   0.12312 2</span>
<span class="sd">          ...</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds.annotate_global_table(&#39;data/genes_pli_exac.txt&#39;, &#39;global.genes&#39;,</span>
<span class="sd">        ...                           config=TextTableConfig(types=&#39;PLI: Double, EXAC_LOF_COUNT: Int&#39;))</span>

<span class="sd">        creates a new global annotation ``global.genes`` with type:</span>

<span class="sd">        .. code-block:: text</span>

<span class="sd">          global.genes: Array[Struct {</span>
<span class="sd">              GENE: String,</span>
<span class="sd">              PLI: Double,</span>
<span class="sd">              EXAC_LOF_COUNT: Int</span>
<span class="sd">          }]</span>

<span class="sd">        where each line is stored as an element of the array.</span>

<span class="sd">        **Notes**</span>

<span class="sd">        :param str input: Input text file.</span>

<span class="sd">        :param str root: Global annotation path to store text table.</span>

<span class="sd">        :param config: Configuration options for importing text files</span>
<span class="sd">        :type config: :class:`.TextTableConfig`</span>

<span class="sd">        :return: Annotated variant dataset.</span>
<span class="sd">        :rtype: :class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">jvds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">annotateGlobalTable</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">root</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">_to_java</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">jvds</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.annotate_samples_expr"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.annotate_samples_expr">[docs]</a>    <span class="k">def</span> <span class="nf">annotate_samples_expr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">expr</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Annotate samples with expression.</span>

<span class="sd">        **Examples**</span>

<span class="sd">        Compute per-sample GQ statistics for hets:</span>

<span class="sd">        &gt;&gt;&gt; vds_result = (vds.annotate_samples_expr(&#39;sa.gqHetStats = gs.filter(g =&gt; g.isHet()).map(g =&gt; g.gq).stats()&#39;)</span>
<span class="sd">        ...     .export_samples(&#39;output/samples.txt&#39;, &#39;sample = s, het_gq_mean = sa.gqHetStats.mean&#39;))</span>

<span class="sd">        Compute the list of genes with a singleton LOF per sample:</span>

<span class="sd">        &gt;&gt;&gt; vds_result = (vds.annotate_variants_table(&#39;data/consequence.tsv&#39;, &#39;Variant&#39;, code=&#39;va.consequence = table.Consequence&#39;, config=TextTableConfig(impute=True))</span>
<span class="sd">        ...     .annotate_variants_expr(&#39;va.isSingleton = gs.map(g =&gt; g.nNonRefAlleles()).sum() == 1&#39;)</span>
<span class="sd">        ...     .annotate_samples_expr(&#39;sa.LOF_genes = gs.filter(g =&gt; va.isSingleton &amp;&amp; g.isHet() &amp;&amp; va.consequence == &quot;LOF&quot;).map(g =&gt; va.gene).collect()&#39;))</span>

<span class="sd">        To create an annotation for only a subset of samples based on an existing annotation:</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds.annotate_samples_expr(&#39;sa.newpheno = if (sa.pheno.cohortName == &quot;cohort1&quot;) sa.pheno.bloodPressure else NA: Double&#39;)</span>

<span class="sd">        .. note::</span>

<span class="sd">            For optimal performance, be sure to explicitly give the alternative (``NA``) the same type as the consequent (``sa.pheno.bloodPressure``).</span>

<span class="sd">        **Notes**</span>

<span class="sd">        ``expr`` is in sample context so the following symbols are in scope:</span>

<span class="sd">        - ``s`` (*Sample*): :ref:`sample`</span>
<span class="sd">        - ``sa``: sample annotations</span>
<span class="sd">        - ``global``: global annotations</span>
<span class="sd">        - ``gs`` (*Aggregable[Genotype]*): aggregable of :ref:`genotype` for sample ``s``</span>

<span class="sd">        :param expr: Annotation expression.</span>
<span class="sd">        :type expr: str or list of str</span>

<span class="sd">        :return: Annotated variant dataset.</span>
<span class="sd">        :rtype: :class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">expr</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">expr</span> <span class="o">=</span> <span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">expr</span><span class="p">)</span>

        <span class="n">jvds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">annotateSamplesExpr</span><span class="p">(</span><span class="n">expr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">jvds</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.annotate_samples_fam"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.annotate_samples_fam">[docs]</a>    <span class="k">def</span> <span class="nf">annotate_samples_fam</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">quantpheno</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\\\\</span><span class="s1">s+&#39;</span><span class="p">,</span> <span class="n">root</span><span class="o">=</span><span class="s1">&#39;sa.fam&#39;</span><span class="p">,</span> <span class="n">missing</span><span class="o">=</span><span class="s1">&#39;NA&#39;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Import PLINK .fam file into sample annotations.</span>

<span class="sd">        **Examples**</span>

<span class="sd">        Import case-control phenotype data from a tab-separated `PLINK .fam</span>
<span class="sd">        &lt;https://www.cog-genomics.org/plink2/formats#fam&gt;`_ file into sample</span>
<span class="sd">        annotations:</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds.annotate_samples_fam(&quot;data/myStudy.fam&quot;)</span>

<span class="sd">        In Hail, unlike PLINK, the user must *explicitly* distinguish between</span>
<span class="sd">        case-control and quantitative phenotypes. Importing a quantitative</span>
<span class="sd">        phenotype without ``quantpheno=True`` will return an error</span>
<span class="sd">        (unless all values happen to be ``0``, ``1``, ``2``, and ``-9``):</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds.annotate_samples_fam(&quot;data/myStudy.fam&quot;, quantpheno=True)</span>

<span class="sd">        **Annotations**</span>

<span class="sd">        The annotation names, types, and missing values are shown below,</span>
<span class="sd">        assuming the default root ``sa.fam``.</span>

<span class="sd">        - **sa.fam.famID** (*String*) -- Family ID (missing = &quot;0&quot;)</span>
<span class="sd">        - **s** (*String*) -- Sample ID</span>
<span class="sd">        - **sa.fam.patID** (*String*) -- Paternal ID (missing = &quot;0&quot;)</span>
<span class="sd">        - **sa.fam.matID** (*String*) -- Maternal ID (missing = &quot;0&quot;)</span>
<span class="sd">        - **sa.fam.isFemale** (*Boolean*) -- Sex (missing = &quot;NA&quot;, &quot;-9&quot;, &quot;0&quot;)</span>
<span class="sd">        - **sa.fam.isCase** (*Boolean*) -- Case-control phenotype (missing = &quot;0&quot;, &quot;-9&quot;, non-numeric or the ``missing`` argument, if given.</span>
<span class="sd">        - **sa.fam.qPheno** (*Double*) -- Quantitative phenotype (missing = &quot;NA&quot; or the ``missing`` argument, if given.</span>

<span class="sd">        :param str input: Path to .fam file.</span>

<span class="sd">        :param str root: Sample annotation path to store .fam file.</span>

<span class="sd">        :param bool quantpheno: If True, .fam phenotype is interpreted as quantitative.</span>

<span class="sd">        :param str delimiter: .fam file field delimiter regex.</span>

<span class="sd">        :param str missing: The string used to denote missing values.</span>
<span class="sd">            For case-control, 0, -9, and non-numeric are also treated</span>
<span class="sd">            as missing.</span>

<span class="sd">        :return: Annotated variant dataset with sample annotations from fam file.</span>
<span class="sd">        :rtype: :class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">ffc</span> <span class="o">=</span> <span class="n">Env</span><span class="o">.</span><span class="n">hail</span><span class="p">()</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">plink</span><span class="o">.</span><span class="n">FamFileConfig</span><span class="p">(</span><span class="n">quantpheno</span><span class="p">,</span> <span class="n">delimiter</span><span class="p">,</span> <span class="n">missing</span><span class="p">)</span>
        <span class="n">jvds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">annotateSamplesFam</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">root</span><span class="p">,</span> <span class="n">ffc</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">jvds</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.annotate_samples_list"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.annotate_samples_list">[docs]</a>    <span class="k">def</span> <span class="nf">annotate_samples_list</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">root</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Annotate samples with a Boolean indicating presence in a list of samples in a text file.</span>

<span class="sd">        **Examples**</span>

<span class="sd">        Add the sample annotation ``sa.inBatch1: Boolean`` with value true if the sample is in *batch1.txt*:</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds.annotate_samples_list(&#39;data/batch1.txt&#39;,&#39;sa.inBatch1&#39;)</span>

<span class="sd">        The file must have no header and one sample per line</span>

<span class="sd">        .. code-block:: text</span>

<span class="sd">            $ cat data/batch1.txt</span>
<span class="sd">            SampleA</span>
<span class="sd">            SampleB</span>
<span class="sd">            ...</span>

<span class="sd">        :param str input: Sample list file.</span>

<span class="sd">        :param str root: Sample annotation path to store Boolean.</span>

<span class="sd">        :return: Annotated variant dataset with a new boolean sample annotation</span>
<span class="sd">        :rtype: :class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">jvds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">annotateSamplesList</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">root</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">jvds</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.annotate_samples_table"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.annotate_samples_table">[docs]</a>    <span class="k">def</span> <span class="nf">annotate_samples_table</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">sample_expr</span><span class="p">,</span> <span class="n">root</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">code</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">TextTableConfig</span><span class="p">()):</span>
        <span class="sd">&quot;&quot;&quot;Annotate samples with delimited text file (text table).</span>

<span class="sd">        **Examples**</span>

<span class="sd">        To annotates samples using `samples1.tsv` with type imputation::</span>

<span class="sd">        &gt;&gt;&gt; conf = TextTableConfig(impute=True)</span>
<span class="sd">        &gt;&gt;&gt; vds_result = vds.annotate_samples_table(&#39;data/samples1.tsv&#39;, &#39;Sample&#39;, root=&#39;sa.pheno&#39;, config=conf)</span>

<span class="sd">        Given this file</span>

<span class="sd">        .. code-block:: text</span>

<span class="sd">            $ cat data/samples1.tsv</span>
<span class="sd">            Sample	Height	Status  Age</span>
<span class="sd">            PT-1234	154.1	ADHD	24</span>
<span class="sd">            PT-1236	160.9	Control	19</span>
<span class="sd">            PT-1238	NA	ADHD	89</span>
<span class="sd">            PT-1239	170.3	Control	55</span>

<span class="sd">        the three new sample annotations are ``sa.pheno.Height: Double``, ``sa.pheno.Status: String``, and ``sa.pheno.Age: Int``.</span>

<span class="sd">        To annotate without type imputation, resulting in all String types:</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds.annotate_samples_table(&#39;data/samples1.tsv&#39;, &#39;Sample&#39;, root=&#39;sa.phenotypes&#39;)</span>

<span class="sd">        **Detailed examples**</span>

<span class="sd">        Let&#39;s import annotations from a CSV file with missing data and special characters</span>

<span class="sd">        .. code-block:: text</span>

<span class="sd">            $ cat data/samples2.tsv</span>
<span class="sd">            Batch,PT-ID</span>
<span class="sd">            1kg,PT-0001</span>
<span class="sd">            1kg,PT-0002</span>
<span class="sd">            study1,PT-0003</span>
<span class="sd">            study3,PT-0003</span>
<span class="sd">            .,PT-0004</span>
<span class="sd">            1kg,PT-0005</span>
<span class="sd">            .,PT-0006</span>
<span class="sd">            1kg,PT-0007</span>

<span class="sd">        In this case, we should:</span>

<span class="sd">        - Escape the ``PT-ID`` column with backticks in the ``sample_expr`` argument because it contains a dash</span>

<span class="sd">        - Pass the non-default delimiter ``,``</span>

<span class="sd">        - Pass the non-default missing value ``.``</span>

<span class="sd">        - Add the only useful column using ``code`` rather than the ``root`` parameter.</span>

<span class="sd">        &gt;&gt;&gt; conf = TextTableConfig(delimiter=&#39;,&#39;, missing=&#39;.&#39;)</span>
<span class="sd">        &gt;&gt;&gt; vds_result = vds.annotate_samples_table(&#39;data/samples2.tsv&#39;, &#39;`PT-ID`&#39;, code=&#39;sa.batch = table.Batch&#39;, config=conf)</span>

<span class="sd">        Let&#39;s import annotations from a file with no header and sample IDs that need to be transformed. Suppose the vds sample IDs are of the form ``NA#####``. This file has no header line, and the sample ID is hidden in a field with other information</span>

<span class="sd">        .. code-block:: text</span>

<span class="sd">            $ cat data/samples3.tsv</span>
<span class="sd">            1kg_NA12345   female</span>
<span class="sd">            1kg_NA12346   male</span>
<span class="sd">            1kg_NA12348   female</span>
<span class="sd">            pgc_NA23415   male</span>
<span class="sd">            pgc_NA23418   male</span>

<span class="sd">        To import it:</span>

<span class="sd">        &gt;&gt;&gt; conf = TextTableConfig(noheader=True)</span>
<span class="sd">        &gt;&gt;&gt; vds_result = vds.annotate_samples_table(&#39;data/samples3.tsv&#39;,</span>
<span class="sd">        ...                             &#39;_0.split(&quot;_&quot;)[1]&#39;,</span>
<span class="sd">        ...                             code=&#39;sa.sex = table._1, sa.batch = table._0.split(&quot;_&quot;)[0]&#39;,</span>
<span class="sd">        ...                             config=conf)</span>

<span class="sd">        **Using the** ``sample_expr`` **argument**</span>

<span class="sd">        This argument tells Hail how to get a sample ID out of your table. Each column in the table is exposed to the Hail expr language. Possibilities include ``Sample`` (if your sample id is in a column called &#39;Sample&#39;), ``_2`` (if your sample ID is the 3rd column of a table with no header), or something more complicated like ``&#39;if (&quot;PGC&quot; ~ ID1) ID1 else ID2&#39;``.  All that matters is that this expr results in a string.  If the expr evaluates to missing, it will not be mapped to any VDS samples.</span>

<span class="sd">        **Using the** ``root`` **and** ``code`` **arguments**</span>

<span class="sd">        This module requires exactly one of these two arguments to tell Hail how to insert the table into the sample annotation schema.</span>

<span class="sd">        The ``root`` argument is the simpler of these two, and simply packages up all table annotations as a ``Struct`` and drops it at the given ``root`` location.  If your table has columns ``Sample``, ``Sex``, and ``Batch``, then ``root=&#39;sa.metadata&#39;`` creates the struct ``{Sample, Sex, Batch}`` at ``sa.metadata``, which gives you access to the paths ``sa.metadata.Sample``, ``sa.metadata.Sex``, and ``sa.metadata.Batch``.</span>

<span class="sd">        The ``code`` argument expects an annotation expression and has access to ``sa`` (the sample annotations in the VDS) and ``table`` (a struct with all the columns in the table).  ``root=&#39;sa.anno&#39;`` is equivalent to ``code=&#39;sa.anno = table&#39;``.</span>

<span class="sd">        **Common uses for the** ``code`` **argument**</span>

<span class="sd">        Don&#39;t generate a full struct in a table with only one annotation column</span>

<span class="sd">        .. code-block:: text</span>

<span class="sd">            code=&#39;sa.annot = table._1&#39;</span>

<span class="sd">        Put annotations on the top level under `sa`</span>

<span class="sd">        .. code-block:: text</span>

<span class="sd">            code=&#39;sa = merge(sa, table)&#39;</span>

<span class="sd">        Load only specific annotations from the table</span>

<span class="sd">        .. code-block:: text</span>

<span class="sd">            code=&#39;sa.annotations = select(table, toKeep1, toKeep2, toKeep3)&#39;</span>

<span class="sd">        The above is equivalent to</span>

<span class="sd">        .. code-block:: text</span>

<span class="sd">            code=&#39;sa.annotations.toKeep1 = table.toKeep1,</span>
<span class="sd">                sa.annotations.toKeep2 = table.toKeep2,</span>
<span class="sd">                sa.annotations.toKeep3 = table.toKeep3&#39;</span>


<span class="sd">        :param str input: Path to delimited text file.</span>

<span class="sd">        :param str sample_expr: Expression for sample id (key).</span>

<span class="sd">        :param str root: Sample annotation path to store text table.</span>

<span class="sd">        :param str code: Annotation expression.</span>

<span class="sd">        :param config: Configuration options for importing text files</span>
<span class="sd">        :type config: :class:`.TextTableConfig`</span>

<span class="sd">        :return: Annotated variant dataset with new samples annotations imported from a text file</span>
<span class="sd">        :rtype: :class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">jvds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">annotateSamplesTable</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">sample_expr</span><span class="p">,</span> <span class="n">joption</span><span class="p">(</span><span class="n">root</span><span class="p">),</span> <span class="n">joption</span><span class="p">(</span><span class="n">code</span><span class="p">),</span> <span class="n">config</span><span class="o">.</span><span class="n">_to_java</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">jvds</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.annotate_samples_vds"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.annotate_samples_vds">[docs]</a>    <span class="k">def</span> <span class="nf">annotate_samples_vds</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">right</span><span class="p">,</span> <span class="n">root</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">code</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Annotate samples with sample annotations from .vds file.</span>

<span class="sd">        :param right: Dataset to annotate with.</span>
<span class="sd">        :type right: :py:class:`.VariantDataset`</span>

<span class="sd">        :param str root: Sample annotation path to add sample annotations.</span>

<span class="sd">        :param str code: Annotation expression.</span>

<span class="sd">        :return: Annotated variant dataset.</span>
<span class="sd">        :rtype: :class:`.VariantDataset`</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">jvds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">annotateSamplesVDS</span><span class="p">(</span><span class="n">right</span><span class="o">.</span><span class="n">_jvds</span><span class="p">,</span> <span class="n">joption</span><span class="p">(</span><span class="n">root</span><span class="p">),</span> <span class="n">joption</span><span class="p">(</span><span class="n">code</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">jvds</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.annotate_samples_keytable"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.annotate_samples_keytable">[docs]</a>    <span class="k">def</span> <span class="nf">annotate_samples_keytable</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">keytable</span><span class="p">,</span> <span class="n">expr</span><span class="p">,</span> <span class="n">vds_key</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Annotate samples with a :py:class:`.KeyTable`.</span>

<span class="sd">        If `vds_key` is None, the key table must have exactly one key of</span>
<span class="sd">        type *String*.</span>

<span class="sd">        If `vds_key` is not None, it must be a list of Hail expressions whose types</span>
<span class="sd">        match, in order, the `keytable`&#39;s key types.</span>

<span class="sd">        **Examples**</span>

<span class="sd">        Add annotations from a sample-keyed TSV:</span>

<span class="sd">        &gt;&gt;&gt; kt = hc.import_keytable(&#39;data/samples2.tsv&#39;,</span>
<span class="sd">        ...                         config=TextTableConfig(impute=True, delimiter=&quot;,&quot;)).key_by(&#39;PT-ID&#39;)</span>
<span class="sd">        ... annotate_vds = vds.annotate_samples_keytable(kt, expr=&#39;sa.batch = table.Batch&#39;)</span>

<span class="sd">        **Notes**</span>

<span class="sd">        ``expr`` has the following symbols in scope:</span>

<span class="sd">          - ``sa``: sample annotations</span>
<span class="sd">          - ``table``: :py:class:`.KeyTable` value</span>

<span class="sd">        each expression in the list ``vds_key`` has the following symbols in</span>
<span class="sd">        scope:</span>

<span class="sd">          - ``s`` (*Sample*): :ref:`sample`</span>
<span class="sd">          - ``sa``: sample annotations</span>

<span class="sd">        :param keytable: Key table with which to annotate samples.</span>
<span class="sd">        :type keytable: :class:`.KeyTable`</span>

<span class="sd">        :param str expr: Annotation expression.</span>

<span class="sd">        :param vds_key: Join key(s) in the dataset. Sample ID is used if this parameter is None.</span>
<span class="sd">        :type vds_key: list of str, str, or None</span>

<span class="sd">        :rtype: :class:`VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">expr</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">expr</span> <span class="o">=</span> <span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">expr</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">vds_key</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">jvds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">annotateSamplesKeyTable</span><span class="p">(</span><span class="n">keytable</span><span class="o">.</span><span class="n">_jkt</span><span class="p">,</span> <span class="n">expr</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">vds_key</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                <span class="n">vds_key</span> <span class="o">=</span> <span class="p">[</span><span class="n">vds_key</span><span class="p">]</span>
            <span class="n">jvds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">annotateSamplesKeyTable</span><span class="p">(</span><span class="n">keytable</span><span class="o">.</span><span class="n">_jkt</span><span class="p">,</span> <span class="n">vds_key</span><span class="p">,</span> <span class="n">expr</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">jvds</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.annotate_variants_bed"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.annotate_variants_bed">[docs]</a>    <span class="k">def</span> <span class="nf">annotate_variants_bed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">root</span><span class="p">,</span> <span class="nb">all</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Annotate variants based on the intervals in a .bed file.</span>

<span class="sd">        **Examples**</span>

<span class="sd">        Add the variant annotation ``va.cnvRegion: Boolean`` indicating inclusion in at least one interval of the three-column BED file `file1.bed`:</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds.annotate_variants_bed(&#39;data/file1.bed&#39;, &#39;va.cnvRegion&#39;)</span>

<span class="sd">        Add a variant annotation ``va.cnvRegion: String`` with value given by the fourth column of `file2.bed`:</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds.annotate_variants_bed(&#39;data/file2.bed&#39;, &#39;va.cnvRegion&#39;)</span>

<span class="sd">        The file formats are</span>

<span class="sd">        .. code-block:: text</span>

<span class="sd">            $ cat data/file1.bed</span>
<span class="sd">            track name=&quot;BedTest&quot;</span>
<span class="sd">            20    1          14000000</span>
<span class="sd">            20    17000000   18000000</span>
<span class="sd">            ...</span>

<span class="sd">            $ cat file2.bed</span>
<span class="sd">            track name=&quot;BedTest&quot;</span>
<span class="sd">            20    1          14000000  cnv1</span>
<span class="sd">            20    17000000   18000000  cnv2</span>
<span class="sd">            ...</span>


<span class="sd">        **Notes**</span>

<span class="sd">        `UCSC bed files &lt;https://genome.ucsc.edu/FAQ/FAQformat.html#format1&gt;`_ can have up to 12 fields, but Hail will only ever look at the first four.  The first three fields are required (``chrom``, ``chromStart``, and ``chromEnd``).  If a fourth column is found, Hail will parse this field as a string and load it into the specified annotation path.  If the bed file has only three columns, Hail will assign each variant a Boolean annotation, true if and only if the variant lies in the union of the intervals. Hail ignores header lines in BED files.</span>

<span class="sd">        If the ``all`` parameter is set to ``True`` and a fourth column is present, the annotation will be the set (possibly empty) of fourth column strings as a ``Set[String]`` for all intervals that overlap the given variant.</span>

<span class="sd">        .. caution:: UCSC BED files are end-exclusive but 0-indexed, so the line &quot;5  100  105&quot; is interpreted in Hail as loci `5:101, 5:102, 5:103, 5:104. 5:105`. Details `here &lt;http://genome.ucsc.edu/blog/the-ucsc-genome-browser-coordinate-counting-systems/&gt;`_.</span>

<span class="sd">        :param str input: Path to .bed file.</span>

<span class="sd">        :param str root: Variant annotation path to store annotation.</span>

<span class="sd">        :param bool all: Store values from all overlapping intervals as a set.</span>

<span class="sd">        :return: Annotated variant dataset with new variant annotations imported from a .bed file.</span>
<span class="sd">        :rtype: :class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">jvds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">annotateVariantsBED</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">root</span><span class="p">,</span> <span class="nb">all</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">jvds</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.annotate_variants_expr"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.annotate_variants_expr">[docs]</a>    <span class="k">def</span> <span class="nf">annotate_variants_expr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">expr</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Annotate variants with expression.</span>

<span class="sd">        **Examples**</span>

<span class="sd">        Compute GQ statistics about heterozygotes per variant:</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds.annotate_variants_expr(&#39;va.gqHetStats = gs.filter(g =&gt; g.isHet()).map(g =&gt; g.gq).stats()&#39;)</span>

<span class="sd">        Collect a list of sample IDs with non-ref calls in LOF variants:</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds.annotate_variants_expr(&#39;va.nonRefSamples = gs.filter(g =&gt; g.isCalledNonRef()).map(g =&gt; s).collect()&#39;)</span>

<span class="sd">        Substitute a custom string for the rsID field:</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds.annotate_variants_expr(&#39;va.rsid = str(v)&#39;)</span>

<span class="sd">        **Notes**</span>

<span class="sd">        ``expr`` is in variant context so the following symbols are in scope:</span>

<span class="sd">          - ``v`` (*Variant*): :ref:`variant`</span>
<span class="sd">          - ``va``: variant annotations</span>
<span class="sd">          - ``global``: global annotations</span>
<span class="sd">          - ``gs`` (*Aggregable[Genotype]*): aggregable of :ref:`genotype` for variant ``v``</span>

<span class="sd">        For more information, see the documentation on writing `expressions &lt;overview.html#expressions&gt;`_</span>
<span class="sd">        and using the `Hail Expression Language &lt;exprlang.html&gt;`_.</span>

<span class="sd">        :param expr: Annotation expression or list of annotation expressions.</span>
<span class="sd">        :type expr: str or list of str</span>

<span class="sd">        :return: Annotated variant dataset.</span>
<span class="sd">        :rtype: :class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">expr</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">expr</span> <span class="o">=</span> <span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">expr</span><span class="p">)</span>

        <span class="n">jvds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">annotateVariantsExpr</span><span class="p">(</span><span class="n">expr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">jvds</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.annotate_variants_keytable"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.annotate_variants_keytable">[docs]</a>    <span class="k">def</span> <span class="nf">annotate_variants_keytable</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">keytable</span><span class="p">,</span> <span class="n">expr</span><span class="p">,</span> <span class="n">vds_key</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Annotate variants with an expression that may depend on a :py:class:`.KeyTable`.</span>

<span class="sd">        If `vds_key` is None, the keytable&#39;s key must be exactly one column and</span>
<span class="sd">        that column must have type *Variant*.</span>

<span class="sd">        If `vds_key` is not None, it must be a list of Hail expressions whose types</span>
<span class="sd">        match, in order, the `keytable`&#39;s key type.</span>

<span class="sd">        **Examples**</span>

<span class="sd">        Add annotations from a variant-keyed TSV:</span>

<span class="sd">        &gt;&gt;&gt; kt = hc.import_keytable(&#39;data/variant-lof.tsv&#39;, config=TextTableConfig(impute=True)).key_by(&#39;v&#39;)</span>
<span class="sd">        &gt;&gt;&gt; vds_result = vds.annotate_variants_keytable(kt, &#39;va.lof = table.lof&#39;)</span>

<span class="sd">        Add annotations from a gene-and-type-keyed TSV:</span>

<span class="sd">        &gt;&gt;&gt; kt = hc.import_keytable(&#39;data/locus-metadata.tsv&#39;,</span>
<span class="sd">        ...                         config=TextTableConfig(impute=True)).key_by([&#39;gene&#39;, &#39;type&#39;])</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; vds_result = (vds.annotate_variants_keytable(kt,</span>
<span class="sd">        ...       &#39;va.foo = table.foo&#39;,</span>
<span class="sd">        ...       [&#39;va.gene&#39;, &#39;if (va.score &gt; 10) &quot;Type1&quot; else &quot;Type2&quot;&#39;]))</span>

<span class="sd">        **Notes**</span>

<span class="sd">        ``expr`` has the following symbols in scope:</span>

<span class="sd">          - ``va``: variant annotations</span>
<span class="sd">          - ``table``: :py:class:`.KeyTable` value</span>

<span class="sd">        each expression in the list ``vds_key`` has the following symbols in</span>
<span class="sd">        scope:</span>

<span class="sd">          - ``v`` (*Variant*): :ref:`variant`</span>
<span class="sd">          - ``va``: variant annotations</span>

<span class="sd">        :param expr: Annotation expression or list of annotation expressions</span>
<span class="sd">        :type expr: str or list of str</span>

<span class="sd">        :param vds_key: A list of annotation expressions to be used as the VDS&#39;s join key</span>
<span class="sd">        :type vds_key: None or list of str</span>

<span class="sd">        :return: A :py:class:`.VariantDataset` with new variant annotations specified by ``expr``</span>

<span class="sd">        :rtype: :py:class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">expr</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">expr</span> <span class="o">=</span> <span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">expr</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">vds_key</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">jvds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">annotateVariantsKeyTable</span><span class="p">(</span><span class="n">keytable</span><span class="o">.</span><span class="n">_jkt</span><span class="p">,</span> <span class="n">expr</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">jvds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">annotateVariantsKeyTable</span><span class="p">(</span><span class="n">keytable</span><span class="o">.</span><span class="n">_jkt</span><span class="p">,</span> <span class="n">vds_key</span><span class="p">,</span> <span class="n">expr</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">jvds</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.annotate_variants_intervals"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.annotate_variants_intervals">[docs]</a>    <span class="k">def</span> <span class="nf">annotate_variants_intervals</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">root</span><span class="p">,</span> <span class="nb">all</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Annotate variants from an interval list file.</span>

<span class="sd">        **Examples**</span>

<span class="sd">        Consider the file, *data/exons.interval_list*, in</span>
<span class="sd">        ``chromosome:start-end`` format:</span>

<span class="sd">        .. code-block:: text</span>

<span class="sd">            $ cat data/exons.interval_list</span>
<span class="sd">            1:5122980-5123054</span>
<span class="sd">            1:5531412-5531715</span>
<span class="sd">            1:5600022-5601025</span>
<span class="sd">            1:5610246-5610349</span>

<span class="sd">        The following invocation produces a vds with a new variant annotation,</span>
<span class="sd">        ``va.inExon``. The annotation ``va.inExon`` is ``true`` for every</span>
<span class="sd">        variant included by ``exons.interval_list`` and false otherwise.</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds.annotate_variants_intervals(&#39;data/exons.interval_list&#39;, &#39;va.inExon&#39;)</span>

<span class="sd">        Consider the tab-separated, five-column file *data/exons2.interval_list*:</span>

<span class="sd">        .. code-block:: text</span>

<span class="sd">            $ cat data/exons2.interval_list</span>
<span class="sd">            1   5122980 5123054 + gene1</span>
<span class="sd">            1   5531412 5531715 + gene1</span>
<span class="sd">            1   5600022 5601025 - gene2</span>
<span class="sd">            1   5610246 5610349 - gene2</span>

<span class="sd">        This file maps from variant intervals to gene names. The following</span>
<span class="sd">        invocation produces a vds with a new variant annotation ``va.gene``. The</span>
<span class="sd">        annotation ``va.gene`` is set to the gene name occurring in the fifth</span>
<span class="sd">        column and ``NA`` otherwise.</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds.annotate_variants_intervals(&#39;data/exons2.interval_list&#39;, &#39;va.gene&#39;)</span>

<span class="sd">        **Notes**</span>

<span class="sd">        There are two formats for interval list files.  The first appears as</span>
<span class="sd">        ``chromosome:start-end`` as in the first example.  This format will</span>
<span class="sd">        annotate variants with a *Boolean*, which is ``true`` if that variant is</span>
<span class="sd">        found in any interval specified in the file and `false` otherwise.</span>

<span class="sd">        The second interval list format is a TSV with fields chromosome, start,</span>
<span class="sd">        end, strand, target.  **There should not be a header.** This file will</span>
<span class="sd">        annotate variants with the *String* in the fifth column (target). If</span>
<span class="sd">        ``all=True``, the annotation will be the, possibly empty,</span>
<span class="sd">        ``Set[String]`` of fifth column strings (targets) for all intervals that</span>
<span class="sd">        overlap the given variant.</span>

<span class="sd">        :param str input: Path to .interval_list.</span>

<span class="sd">        :param str root: Variant annotation path to store annotation.</span>

<span class="sd">        :param bool all: If true, store values from all overlapping</span>
<span class="sd">            intervals as a set.</span>

<span class="sd">        :return: Annotated variant dataset.</span>
<span class="sd">        :rtype: :py:class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">jvds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">annotateVariantsIntervals</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">root</span><span class="p">,</span> <span class="nb">all</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">jvds</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.annotate_variants_loci"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.annotate_variants_loci">[docs]</a>    <span class="k">def</span> <span class="nf">annotate_variants_loci</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">locus_expr</span><span class="p">,</span> <span class="n">root</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">code</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">TextTableConfig</span><span class="p">()):</span>
        <span class="sd">&quot;&quot;&quot;Annotate variants from an delimited text file (text table) indexed</span>
<span class="sd">        by loci.</span>

<span class="sd">        :param str path: Path to delimited text file.</span>

<span class="sd">        :param str locus_expr: Expression for locus (key).</span>

<span class="sd">        :param str root: Variant annotation path to store annotation.</span>

<span class="sd">        :param str code: Annotation expression.</span>

<span class="sd">        :param config: Configuration options for importing text files</span>
<span class="sd">        :type config: :class:`.TextTableConfig`</span>

<span class="sd">        :return: Annotated variant dataset.</span>
<span class="sd">        :rtype: :py:class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">jvds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">annotateVariantsLoci</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">locus_expr</span><span class="p">,</span> <span class="n">joption</span><span class="p">(</span><span class="n">root</span><span class="p">),</span> <span class="n">joption</span><span class="p">(</span><span class="n">code</span><span class="p">),</span> <span class="n">config</span><span class="o">.</span><span class="n">_to_java</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">jvds</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.annotate_variants_table"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.annotate_variants_table">[docs]</a>    <span class="k">def</span> <span class="nf">annotate_variants_table</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">variant_expr</span><span class="p">,</span> <span class="n">root</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">code</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">TextTableConfig</span><span class="p">()):</span>
        <span class="sd">&quot;&quot;&quot;Annotate variant with delimited text file (text table).</span>

<span class="sd">        :param path: Path to delimited text files.</span>
<span class="sd">        :type path: str or list of str</span>

<span class="sd">        :param str variant_expr: Expression for Variant (key).</span>

<span class="sd">        :param str root: Variant annotation path to store text table.</span>

<span class="sd">        :param str code: Annotation expression.</span>

<span class="sd">        :param config: Configuration options for importing text files</span>
<span class="sd">        :type config: :class:`.TextTableConfig`</span>

<span class="sd">        :return: Annotated variant dataset.</span>
<span class="sd">        :rtype: :py:class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">jvds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">annotateVariantsTable</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">variant_expr</span><span class="p">,</span> <span class="n">joption</span><span class="p">(</span><span class="n">root</span><span class="p">),</span> <span class="n">joption</span><span class="p">(</span><span class="n">code</span><span class="p">),</span> <span class="n">config</span><span class="o">.</span><span class="n">_to_java</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">jvds</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.annotate_variants_vds"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.annotate_variants_vds">[docs]</a>    <span class="k">def</span> <span class="nf">annotate_variants_vds</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">code</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">root</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;Annotate variants with variant annotations from .vds file.</span>

<span class="sd">        **Examples**</span>

<span class="sd">        Import a second variant dataset with annotations to merge into ``vds``:</span>

<span class="sd">        &gt;&gt;&gt; vds1 = vds.annotate_variants_expr(&#39;va = drop(va, anno1)&#39;)</span>
<span class="sd">        &gt;&gt;&gt; vds2 = (hc.read(&quot;data/example2.vds&quot;)</span>
<span class="sd">        ...           .annotate_variants_expr(&#39;va = select(va, anno1, toKeep1, toKeep2, toKeep3)&#39;))</span>

<span class="sd">        Copy the ``anno1`` annotation from ``other`` to ``va.annot``:</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds1.annotate_variants_vds(vds2, code=&#39;va.annot = vds.anno1&#39;)</span>

<span class="sd">        Merge the variant annotations from the two vds together and places them</span>
<span class="sd">        at ``va``:</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds1.annotate_variants_vds(vds2, code=&#39;va = merge(va, vds)&#39;)</span>

<span class="sd">        Select a subset of the annotations from ``other``:</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds1.annotate_variants_vds(vds2, code=&#39;va.annotations = select(vds, toKeep1, toKeep2, toKeep3)&#39;)</span>

<span class="sd">        The previous expression is equivalent to:</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds1.annotate_variants_vds(vds2, code=&#39;va.annotations.toKeep1 = vds.toKeep1, &#39; +</span>
<span class="sd">        ...                                       &#39;va.annotations.toKeep2 = vds.toKeep2, &#39; +</span>
<span class="sd">        ...                                       &#39;va.annotations.toKeep3 = vds.toKeep3&#39;)</span>

<span class="sd">        **Notes**</span>

<span class="sd">        Using this method requires one of the two optional arguments: ``code``</span>
<span class="sd">        and ``root``. They specify how to insert the annotations from ``other``</span>
<span class="sd">        into the this vds&#39;s variant annotations.</span>

<span class="sd">        The ``root`` argument copies all the variant annotations from ``other``</span>
<span class="sd">        to the specified annotation path.</span>

<span class="sd">        The ``code`` argument expects an annotation expression whose scope</span>
<span class="sd">        includes, ``va``, the variant annotations in the current VDS, and ``vds``,</span>
<span class="sd">        the variant annotations in ``other``.</span>

<span class="sd">        VDSes with multi-allelic variants may produce surprising results because</span>
<span class="sd">        all alternate alleles are considered part of the variant key. For</span>
<span class="sd">        example:</span>

<span class="sd">        - The variant ``22:140012:A:T,TTT`` will not be annotated by</span>
<span class="sd">          ``22:140012:A:T`` or ``22:140012:A:TTT``</span>

<span class="sd">        - The variant ``22:140012:A:T`` will not be annotated by</span>
<span class="sd">          ``22:140012:A:T,TTT``</span>

<span class="sd">        It is possible that an unsplit variant dataset contains no multiallelic</span>
<span class="sd">        variants, so ignore any warnings Hail prints if you know that to be the</span>
<span class="sd">        case.  Otherwise, run :py:meth:`.split_multi` before</span>
<span class="sd">        :py:meth:`.annotate_variants_vds`.</span>

<span class="sd">        :param VariantDataset other: Variant dataset to annotate with.</span>

<span class="sd">        :param str root: Sample annotation path to add variant annotations.</span>

<span class="sd">        :param str code: Annotation expression.</span>

<span class="sd">        :return: Annotated variant dataset.</span>
<span class="sd">        :rtype: :py:class:`.VariantDataset`</span>
<span class="sd">        &#39;&#39;&#39;</span>

        <span class="n">jvds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">annotateVariantsVDS</span><span class="p">(</span><span class="n">other</span><span class="o">.</span><span class="n">_jvds</span><span class="p">,</span> <span class="n">joption</span><span class="p">(</span><span class="n">root</span><span class="p">),</span> <span class="n">joption</span><span class="p">(</span><span class="n">code</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">jvds</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.cache"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.cache">[docs]</a>    <span class="k">def</span> <span class="nf">cache</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Mark this variant dataset to be cached in memory.</span>

<span class="sd">        :py:meth:`~hail.VariantDataset.cache` is the same as :func:`persist(&quot;MEMORY_ONLY&quot;) &lt;hail.VariantDataset.persist&gt;`.</span>
<span class="sd">        </span>
<span class="sd">        :rtype: :class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvdf</span><span class="o">.</span><span class="n">cache</span><span class="p">())</span></div>

    <span class="nd">@handle_py4j</span>
    <span class="nd">@requireTGenotype</span>
<div class="viewcode-block" id="VariantDataset.concordance"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.concordance">[docs]</a>    <span class="k">def</span> <span class="nf">concordance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">right</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Calculate call concordance with another variant dataset.</span>

<span class="sd">        .. include:: requireTGenotype.rst</span>

<span class="sd">        **Example**</span>

<span class="sd">        &gt;&gt;&gt; concordance_pair = vds.concordance(hc.read(&#39;data/example2.vds&#39;))</span>

<span class="sd">        **Notes**</span>

<span class="sd">        The `concordance` command computes the genotype call concordance between two bialellic variant datasets. The concordance</span>
<span class="sd">        results are stored in a global annotation of type Array[Array[Long]], which is a 5x5 table of counts with the</span>
<span class="sd">        following mapping:</span>

<span class="sd">        0. No Data (missing variant)</span>
<span class="sd">        1. No Call (missing genotype call)</span>
<span class="sd">        2. Hom Ref</span>
<span class="sd">        3. Heterozygous</span>
<span class="sd">        4. Hom Var</span>

<span class="sd">        The first index in array is the left dataset, the second is the right. For example, ``concordance[3][2]`` is the count of</span>
<span class="sd">        genotypes which were heterozygous on the left and homozygous reference on the right. This command produces two new datasets</span>
<span class="sd">        and returns them as a Python tuple. The first dataset contains the concordance statistics per variant. This dataset</span>
<span class="sd">        **contains no genotypes** (sites-only). It contains a new variant annotation, ``va.concordance``. This is the concordance</span>
<span class="sd">        table for each variant in the outer join of the two datasets -- if the variant is present in only one dataset, all</span>
<span class="sd">        of the counts will lie in the axis ``va.concordance[0][:]`` (if it is missing on the left) or ``va.concordance.map(x =&gt; x[0])``</span>
<span class="sd">        (if it is missing on the right). The variant annotations from the left and right datasets are included as ``va.left``</span>
<span class="sd">        and ``va.right`` -- these will be missing on one side if a variant was only present in one dataset. This vds also contains</span>
<span class="sd">        the global concordance statistics in ``global.concordance``, as well as the left and right global annotations in ``global.left``</span>
<span class="sd">        and ``global.right``. The second dataset contains the concordance statistics per sample. This dataset **contains no variants**</span>
<span class="sd">        (samples-only). It contains a new sample annotation, ``sa.concordance``. This is a concordance table whose sum is the total number</span>
<span class="sd">        of variants in the outer join of the two datasets. The sum ``sa[0].sum`` is equal to the number of variants in the right dataset</span>
<span class="sd">        but not the left, and the sum ``sa.concordance.map(x =&gt; x[0]).sum)`` is equal to the number of variants in the left dataset but</span>
<span class="sd">        not the right. The sample annotations from the left and right datasets are included as ``sa.left`` and ``sa.right``. This dataset</span>
<span class="sd">        also contains the global concordance statistics in ``global.concordance``, as well as the left and right global annotations in</span>
<span class="sd">        ``global.left`` and ``global.right``.</span>

<span class="sd">        **Notes**</span>

<span class="sd">        Performs inner join on variants, outer join on samples.</span>

<span class="sd">        :param right: right hand variant dataset for concordance</span>
<span class="sd">        :type right: :class:`.VariantDataset`</span>

<span class="sd">        :return: The global concordance stats, a variant dataset with sample concordance</span>
<span class="sd">            statistics, and a variant dataset with variant concordance statistics.</span>
<span class="sd">        :rtype: (list of list of int, :py:class:`.VariantDataset`, :py:class:`.VariantDataset`)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">r</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvdf</span><span class="o">.</span><span class="n">concordance</span><span class="p">(</span><span class="n">right</span><span class="o">.</span><span class="n">_jvds</span><span class="p">)</span>
        <span class="n">j_global_concordance</span> <span class="o">=</span> <span class="n">r</span><span class="o">.</span><span class="n">_1</span><span class="p">()</span>
        <span class="n">sample_vds</span> <span class="o">=</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">r</span><span class="o">.</span><span class="n">_2</span><span class="p">())</span>
        <span class="n">variant_vds</span> <span class="o">=</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">r</span><span class="o">.</span><span class="n">_3</span><span class="p">())</span>
        <span class="n">global_concordance</span> <span class="o">=</span> <span class="p">[[</span><span class="n">j_global_concordance</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">j</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">xrange</span><span class="p">(</span><span class="mi">5</span><span class="p">)]</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">xrange</span><span class="p">(</span><span class="mi">5</span><span class="p">)]</span>

        <span class="k">return</span> <span class="n">global_concordance</span><span class="p">,</span> <span class="n">sample_vds</span><span class="p">,</span> <span class="n">variant_vds</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.count"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.count">[docs]</a>    <span class="k">def</span> <span class="nf">count</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns number of samples and variants in the dataset.</span>
<span class="sd">        </span>
<span class="sd">        **Examples**</span>
<span class="sd">        </span>
<span class="sd">        &gt;&gt;&gt; samples, variants = vds.count()</span>
<span class="sd">        </span>
<span class="sd">        **Notes**</span>
<span class="sd">        </span>
<span class="sd">        This is also the fastest way to force evaluation of a Hail pipeline.</span>
<span class="sd">        </span>
<span class="sd">        :returns: The sample and variant counts.</span>
<span class="sd">        :rtype: (int, int)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">r</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">r</span><span class="o">.</span><span class="n">_1</span><span class="p">(),</span> <span class="n">r</span><span class="o">.</span><span class="n">_2</span><span class="p">()</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.deduplicate"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.deduplicate">[docs]</a>    <span class="k">def</span> <span class="nf">deduplicate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Remove duplicate variants.</span>

<span class="sd">        :return: Deduplicated variant dataset.</span>
<span class="sd">        :rtype: :py:class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">deduplicate</span><span class="p">())</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.sample_variants"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.sample_variants">[docs]</a>    <span class="k">def</span> <span class="nf">sample_variants</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fraction</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Downsample variants to a given fraction of the dataset.</span>
<span class="sd">        </span>
<span class="sd">        **Examples**</span>
<span class="sd">        </span>
<span class="sd">        &gt;&gt;&gt; small_vds = vds.sample_variants(0.01)</span>
<span class="sd">        </span>
<span class="sd">        **Notes**</span>
<span class="sd">        </span>
<span class="sd">        This method may not sample exactly ``(fraction * n_variants)``</span>
<span class="sd">        variants from the dataset.</span>

<span class="sd">        :param float fraction: (Expected) fraction of variants to keep.</span>

<span class="sd">        :param int seed: Random seed.</span>

<span class="sd">        :return: Downsampled variant dataset.</span>
<span class="sd">        :rtype: :py:class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">sampleVariants</span><span class="p">(</span><span class="n">fraction</span><span class="p">,</span> <span class="n">seed</span><span class="p">))</span></div>

    <span class="nd">@handle_py4j</span>
    <span class="nd">@requireTGenotype</span>
<div class="viewcode-block" id="VariantDataset.export_gen"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.export_gen">[docs]</a>    <span class="k">def</span> <span class="nf">export_gen</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Export variant dataset as GEN and SAMPLE file.</span>

<span class="sd">        .. include:: requireTGenotype.rst</span>

<span class="sd">        **Examples**</span>

<span class="sd">        Import dosage data, filter variants based on INFO score, and export data to a GEN and SAMPLE file:</span>

<span class="sd">        &gt;&gt;&gt; vds3 = hc.import_bgen(&quot;data/example3.bgen&quot;, sample_file=&quot;data/example3.sample&quot;)</span>

<span class="sd">        &gt;&gt;&gt; (vds3.filter_variants_expr(&quot;gs.infoScore().score &gt;= 0.9&quot;)</span>
<span class="sd">        ...      .export_gen(&quot;output/infoscore_filtered&quot;))</span>

<span class="sd">        **Notes**</span>

<span class="sd">        Writes out the internal VDS to a GEN and SAMPLE fileset in the `Oxford spec &lt;http://www.stats.ox.ac.uk/%7Emarchini/software/gwas/file_format.html&gt;`_.</span>

<span class="sd">        The first 6 columns of the resulting GEN file are the following:</span>

<span class="sd">        - Chromosome (``v.contig``)</span>
<span class="sd">        - Variant ID (``va.varid`` if defined, else Chromosome:Position:Ref:Alt)</span>
<span class="sd">        - rsID (``va.rsid`` if defined, else &quot;.&quot;)</span>
<span class="sd">        - position (``v.start``)</span>
<span class="sd">        - reference allele (``v.ref``)</span>
<span class="sd">        - alternate allele (``v.alt``)</span>

<span class="sd">        Probability dosages:</span>

<span class="sd">        - 3 probabilities per sample ``(pHomRef, pHet, pHomVar)``.</span>
<span class="sd">        - Any filtered genotypes will be output as ``(0.0, 0.0, 0.0)``.</span>
<span class="sd">        - If the input data contained Phred-scaled likelihoods, the probabilities in the GEN file will be the normalized genotype probabilities assuming a uniform prior.</span>
<span class="sd">        - If the input data did not have genotype probabilities such as data imported using :py:meth:`~hail.HailContext.import_plink`, all genotype probabilities will be ``(0.0, 0.0, 0.0)``.</span>

<span class="sd">        The sample file has 3 columns:</span>

<span class="sd">        - ID_1 and ID_2 are identical and set to the sample ID (``s``).</span>
<span class="sd">        - The third column (&quot;missing&quot;) is set to 0 for all samples.</span>

<span class="sd">        :param str output: Output file base.  Will write GEN and SAMPLE files.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_jvdf</span><span class="o">.</span><span class="n">exportGen</span><span class="p">(</span><span class="n">output</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.export_genotypes"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.export_genotypes">[docs]</a>    <span class="k">def</span> <span class="nf">export_genotypes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">expr</span><span class="p">,</span> <span class="n">types</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">export_ref</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">export_missing</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Export genotype-level information to delimited text file.</span>

<span class="sd">        **Examples**</span>

<span class="sd">        Export genotype information with identifiers that form the header:</span>

<span class="sd">        &gt;&gt;&gt; vds.export_genotypes(&#39;output/genotypes.tsv&#39;, &#39;SAMPLE=s, VARIANT=v, GQ=g.gq, DP=g.dp, ANNO1=va.anno1, ANNO2=va.anno2&#39;)</span>

<span class="sd">        Export the same information without identifiers, resulting in a file with no header:</span>

<span class="sd">        &gt;&gt;&gt; vds.export_genotypes(&#39;output/genotypes.tsv&#39;, &#39;s, v, g.gq, g.dp, va.anno1, va.anno2&#39;)</span>

<span class="sd">        **Notes**</span>

<span class="sd">        :py:meth:`~hail.VariantDataset.export_genotypes` outputs one line per cell (genotype) in the data set, though HomRef and missing genotypes are not output by default if the genotype schema is equal to :py:class:`~hail.expr.TGenotype`. Use the ``export_ref`` and ``export_missing`` parameters to force export of HomRef and missing genotypes, respectively.</span>

<span class="sd">        The ``expr`` argument is a comma-separated list of fields or expressions, all of which must be of the form ``IDENTIFIER = &lt;expression&gt;``, or else of the form ``&lt;expression&gt;``.  If some fields have identifiers and some do not, Hail will throw an exception. The accessible namespace includes ``g``, ``s``, ``sa``, ``v``, ``va``, and ``global``.</span>

<span class="sd">        .. warning::</span>

<span class="sd">            If the genotype schema does not have the type :py:class:`~hail.expr.TGenotype`, all genotypes will be exported unless the value of ``g`` is missing.</span>
<span class="sd">            Use :py:meth:`~hail.VariantDataset.filter_genotypes` to filter out genotypes based on an expression before exporting.</span>

<span class="sd">        :param str output: Output path.</span>

<span class="sd">        :param str expr: Export expression for values to export.</span>

<span class="sd">        :param bool types: Write types of exported columns to a file at (output + &quot;.types&quot;)</span>

<span class="sd">        :param bool export_ref: If True, export reference genotypes. Only applicable if the genotype schema is :py:class:`~hail.expr.TGenotype`.</span>

<span class="sd">        :param bool export_missing: If True, export missing genotypes.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_generic_genotype</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_jvdf</span><span class="o">.</span><span class="n">exportGenotypes</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">expr</span><span class="p">,</span> <span class="n">types</span><span class="p">,</span> <span class="n">export_missing</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_jvdf</span><span class="o">.</span><span class="n">exportGenotypes</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">expr</span><span class="p">,</span> <span class="n">types</span><span class="p">,</span> <span class="n">export_ref</span><span class="p">,</span> <span class="n">export_missing</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
    <span class="nd">@requireTGenotype</span>
<div class="viewcode-block" id="VariantDataset.export_plink"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.export_plink">[docs]</a>    <span class="k">def</span> <span class="nf">export_plink</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">fam_expr</span><span class="o">=</span><span class="s1">&#39;id = s&#39;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Export variant dataset as `PLINK2 &lt;https://www.cog-genomics.org/plink2/formats&gt;`_ BED, BIM and FAM.</span>

<span class="sd">        .. include:: requireTGenotype.rst</span>

<span class="sd">        **Examples**</span>

<span class="sd">        Import data from a VCF file, split multi-allelic variants, and export to a PLINK binary file:</span>

<span class="sd">        &gt;&gt;&gt; vds.split_multi().export_plink(&#39;output/plink&#39;)</span>

<span class="sd">        **Notes**</span>

<span class="sd">        ``fam_expr`` can be used to set the fields in the FAM file.</span>
<span class="sd">        The following fields can be assigned:</span>

<span class="sd">        - ``famID: String``</span>
<span class="sd">        - ``id: String``</span>
<span class="sd">        - ``matID: String``</span>
<span class="sd">        - ``patID: String``</span>
<span class="sd">        - ``isFemale: Boolean``</span>
<span class="sd">        - ``isCase: Boolean`` or ``qPheno: Double``</span>

<span class="sd">        If no assignment is given, the value is missing and the</span>
<span class="sd">        missing value is used: ``0`` for IDs and sex and ``-9`` for</span>
<span class="sd">        phenotype.  Only one of ``isCase`` or ``qPheno`` can be</span>
<span class="sd">        assigned.</span>

<span class="sd">        ``fam_expr`` is in sample context only and the following</span>
<span class="sd">        symbols are in scope:</span>

<span class="sd">        - ``s`` (*Sample*): :ref:`sample`</span>
<span class="sd">        - ``sa``: sample annotations</span>
<span class="sd">        - ``global``: global annotations</span>

<span class="sd">        The BIM file ID field is set to ``CHR:POS:REF:ALT``.</span>

<span class="sd">        This code:</span>

<span class="sd">        &gt;&gt;&gt; vds.split_multi().export_plink(&#39;output/plink&#39;)</span>

<span class="sd">        will behave similarly to the PLINK VCF conversion command</span>

<span class="sd">        .. code-block:: text</span>

<span class="sd">            plink --vcf /path/to/file.vcf --make-bed --out sample --const-fid --keep-allele-order</span>

<span class="sd">        except:</span>

<span class="sd">        - The order among split multi-allelic alternatives in the BED</span>
<span class="sd">          file may disagree.</span>
<span class="sd">        - PLINK uses the rsID for the BIM file ID.</span>

<span class="sd">        :param str output: Output file base.  Will write BED, BIM, and FAM files.</span>

<span class="sd">        :param str fam_expr: Expression for FAM file fields.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_jvdf</span><span class="o">.</span><span class="n">exportPlink</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">fam_expr</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.export_samples"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.export_samples">[docs]</a>    <span class="k">def</span> <span class="nf">export_samples</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">expr</span><span class="p">,</span> <span class="n">types</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Export sample information to delimited text file.</span>

<span class="sd">        **Examples**</span>

<span class="sd">        Export some sample QC metrics:</span>

<span class="sd">        &gt;&gt;&gt; (vds.sample_qc()</span>
<span class="sd">        ...     .export_samples(&#39;output/samples.tsv&#39;, &#39;SAMPLE = s, CALL_RATE = sa.qc.callRate, NHET = sa.qc.nHet&#39;))</span>

<span class="sd">        This will produce a file with a header and three columns.  To</span>
<span class="sd">        produce a file with no header, just leave off the assignment</span>
<span class="sd">        to the column identifier:</span>

<span class="sd">        &gt;&gt;&gt; (vds.sample_qc()</span>
<span class="sd">        ...     .export_samples(&#39;output/samples.tsv&#39;, &#39;s, sa.qc.rTiTv&#39;))</span>

<span class="sd">        **Notes**</span>

<span class="sd">        One line per sample will be exported.  As :py:meth:`~hail.VariantDataset.export_samples` runs in sample context, the following symbols are in scope:</span>

<span class="sd">        - ``s`` (*Sample*): :ref:`sample`</span>
<span class="sd">        - ``sa``: sample annotations</span>
<span class="sd">        - ``global``: global annotations</span>
<span class="sd">        - ``gs`` (*Aggregable[Genotype]*): aggregable of :ref:`genotype` for sample ``s``</span>

<span class="sd">        :param str output: Output file.</span>

<span class="sd">        :param str expr: Export expression for values to export.</span>

<span class="sd">        :param bool types: Write types of exported columns to a file at (output + &quot;.types&quot;).</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">exportSamples</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">expr</span><span class="p">,</span> <span class="n">types</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.export_variants"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.export_variants">[docs]</a>    <span class="k">def</span> <span class="nf">export_variants</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">expr</span><span class="p">,</span> <span class="n">types</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Export variant information to delimited text file.</span>

<span class="sd">        **Examples**</span>

<span class="sd">        Export a four column TSV with ``v``, ``va.pass``, ``va.filters``, and</span>
<span class="sd">        one computed field: ``1 - va.qc.callRate``.</span>

<span class="sd">        &gt;&gt;&gt; vds.export_variants(&#39;output/file.tsv&#39;,</span>
<span class="sd">        ...        &#39;VARIANT = v, PASS = va.pass, FILTERS = va.filters, MISSINGNESS = 1 - va.qc.callRate&#39;)</span>

<span class="sd">        It is also possible to export without identifiers, which will result in</span>
<span class="sd">        a file with no header. In this case, the expressions should look like</span>
<span class="sd">        the examples below:</span>

<span class="sd">        &gt;&gt;&gt; vds.export_variants(&#39;output/file.tsv&#39;, &#39;v, va.pass, va.qc.AF&#39;)</span>

<span class="sd">        .. note::</span>

<span class="sd">            If any field is named, all fields must be named.</span>

<span class="sd">        In the common case that a group of annotations needs to be exported (for</span>
<span class="sd">        example, the annotations produced by ``variantqc``), one can use the</span>
<span class="sd">        ``struct.*`` syntax.  This syntax produces one column per field in the</span>
<span class="sd">        struct, and names them according to the struct field name.</span>

<span class="sd">        For example, the following invocation (assuming ``va.qc`` was generated</span>
<span class="sd">        by :py:meth:`.variant_qc`):</span>

<span class="sd">        &gt;&gt;&gt; vds.export_variants(&#39;output/file.tsv&#39;, &#39;variant = v, va.qc.*&#39;)</span>

<span class="sd">        will produce the following set of columns:</span>

<span class="sd">        .. code-block:: text</span>

<span class="sd">            variant  callRate  AC  AF  nCalled  ...</span>

<span class="sd">        Note that using the ``.*`` syntax always results in named arguments, so it</span>
<span class="sd">        is not possible to export header-less files in this manner.  However,</span>
<span class="sd">        naming the &quot;splatted&quot; struct will apply the name in front of each column</span>
<span class="sd">        like so:</span>

<span class="sd">        &gt;&gt;&gt; vds.export_variants(&#39;output/file.tsv&#39;, &#39;variant = v, QC = va.qc.*&#39;)</span>

<span class="sd">        which produces these columns:</span>

<span class="sd">        .. code-block:: text</span>

<span class="sd">            variant  QC.callRate  QC.AC  QC.AF  QC.nCalled  ...</span>


<span class="sd">        **Notes**</span>

<span class="sd">        This module takes a comma-delimited list of fields or expressions to</span>
<span class="sd">        print. These fields will be printed in the order they appear in the</span>
<span class="sd">        expression in the header and on each line.</span>

<span class="sd">        One line per variant in the VDS will be printed.  The accessible namespace includes:</span>

<span class="sd">        - ``v`` (*Variant*): :ref:`variant`</span>
<span class="sd">        - ``va``: variant annotations</span>
<span class="sd">        - ``global``: global annotations</span>
<span class="sd">        - ``gs`` (*Aggregable[Genotype]*): aggregable of :ref:`genotype` for variant ``v``</span>

<span class="sd">        **Designating output with an expression**</span>

<span class="sd">        Much like the filtering methods, exporting allows flexible expressions</span>
<span class="sd">        to be written on the command line. While the filtering methods expect an</span>
<span class="sd">        expression that evaluates to true or false, this method expects a</span>
<span class="sd">        comma-separated list of fields to print. These fields *must* take the</span>
<span class="sd">        form ``IDENTIFIER = &lt;expression&gt;``.</span>


<span class="sd">        :param str output: Output file.</span>

<span class="sd">        :param str expr: Export expression for values to export.</span>

<span class="sd">        :param bool types: Write types of exported columns to a file at (output + &quot;.types&quot;)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">exportVariants</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">expr</span><span class="p">,</span> <span class="n">types</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.export_vcf"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.export_vcf">[docs]</a>    <span class="k">def</span> <span class="nf">export_vcf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">append_to_header</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">export_pp</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Export variant dataset as a .vcf or .vcf.bgz file.</span>

<span class="sd">        **Examples**</span>

<span class="sd">        Export to VCF as a block-compressed file:</span>

<span class="sd">        &gt;&gt;&gt; vds.export_vcf(&#39;output/example.vcf.bgz&#39;)</span>

<span class="sd">        **Notes**</span>

<span class="sd">        :py:meth:`~hail.VariantDataset.export_vcf` writes the VDS to disk in VCF format as described in the `VCF 4.2 spec &lt;https://samtools.github.io/hts-specs/VCFv4.2.pdf&gt;`_.</span>

<span class="sd">        Use the ``.vcf.bgz`` extension rather than ``.vcf`` in the output file name for `blocked GZIP &lt;http://www.htslib.org/doc/tabix.html&gt;`_ compression.</span>

<span class="sd">        .. note::</span>

<span class="sd">            We strongly recommended compressed (``.bgz`` extension) and parallel output (``parallel=True``) when exporting large VCFs.</span>

<span class="sd">        Consider the workflow of importing VCF to VDS and immediately exporting VDS to VCF:</span>

<span class="sd">        &gt;&gt;&gt; vds.export_vcf(&#39;output/example_out.vcf&#39;)</span>

<span class="sd">        The *example_out.vcf* header will contain the FORMAT, FILTER, and INFO lines present in *example.vcf*. However, it will *not* contain CONTIG lines or lines added by external tools (such as bcftools and GATK) unless they are explicitly inserted using the ``append_to_header`` option.</span>

<span class="sd">        Hail only exports the contents of ``va.info`` to the INFO field. No other annotations besides ``va.info`` are exported.</span>

<span class="sd">        The genotype schema must have the type :py:class:`~hail.expr.TGenotype` or :py:class:`~hail.expr.TStruct`. If the type is</span>
<span class="sd">        :py:class:`~hail.expr.TGenotype`, then the FORMAT fields will be GT, AD, DP, GQ, and PL (or PP if ``export_pp`` is True).</span>
<span class="sd">        If the type is :py:class:`~hail.expr.TStruct`, then the exported FORMAT fields will be the names of each field of the Struct.</span>
<span class="sd">        Each field must have a type of String, Char, Int, Double, or Call. Arrays and Sets are also allowed as long as they are not nested.</span>
<span class="sd">        For example, a field with type ``Array[Int]`` can be exported but not a field with type ``Array[Array[Int]]``.</span>
<span class="sd">        Nested Structs are also not allowed.</span>

<span class="sd">        .. caution::</span>

<span class="sd">            If samples or genotypes are filtered after import, the value stored in ``va.info.AC`` value may no longer reflect the number of called alternate alleles in the filtered VDS. If the filtered VDS is then exported to VCF, downstream tools may produce erroneous results. The solution is to create new annotations in ``va.info`` or overwrite existing annotations. For example, in order to produce an accurate ``AC`` field, one can run :py:meth:`~hail.VariantDataset.variant_qc` and copy the ``va.qc.AC`` field to ``va.info.AC``:</span>

<span class="sd">            &gt;&gt;&gt; (vds.filter_genotypes(&#39;g.gq &gt;= 20&#39;)</span>
<span class="sd">            ...     .variant_qc()</span>
<span class="sd">            ...     .annotate_variants_expr(&#39;va.info.AC = va.qc.AC&#39;)</span>
<span class="sd">            ...     .export_vcf(&#39;output/example.vcf.bgz&#39;))</span>

<span class="sd">        :param str output: Path of .vcf file to write.</span>

<span class="sd">        :param append_to_header: Path of file to append to VCF header.</span>
<span class="sd">        :type append_to_header: str or None</span>

<span class="sd">        :param bool export_pp: If True, export linear-scaled probabilities (Hail&#39;s `pp` field on genotype) as the VCF PP FORMAT field.</span>

<span class="sd">        :param bool parallel: If True, return a set of VCF files (one per partition) rather than serially concatenating these files.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_jvdf</span><span class="o">.</span><span class="n">exportVCF</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">joption</span><span class="p">(</span><span class="n">append_to_header</span><span class="p">),</span> <span class="n">export_pp</span><span class="p">,</span> <span class="n">parallel</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
    <span class="nd">@convertVDS</span>
<div class="viewcode-block" id="VariantDataset.write"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.write">[docs]</a>    <span class="k">def</span> <span class="nf">write</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parquet_genotypes</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Write variant dataset as VDS file.</span>

<span class="sd">        **Examples**</span>

<span class="sd">        Import data from a VCF file and then write the data to a VDS file:</span>

<span class="sd">        &gt;&gt;&gt; vds.write(&quot;output/sample.vds&quot;)</span>

<span class="sd">        :param str output: Path of VDS file to write.</span>

<span class="sd">        :param bool overwrite: If True, overwrite any existing VDS file. Cannot be used to read from and write to the same path.</span>

<span class="sd">        :param bool parquet_genotypes: If True, store genotypes as Parquet rather than Hail&#39;s serialization.  The resulting VDS will be larger and slower in Hail but the genotypes will be accessible from other tools that support Parquet.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_generic_genotype</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_jvdf</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">overwrite</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_jvdf</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">overwrite</span><span class="p">,</span> <span class="n">parquet_genotypes</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
    <span class="nd">@requireTGenotype</span>
<div class="viewcode-block" id="VariantDataset.filter_alleles"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.filter_alleles">[docs]</a>    <span class="k">def</span> <span class="nf">filter_alleles</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">condition</span><span class="p">,</span> <span class="n">annotation</span><span class="o">=</span><span class="s1">&#39;va = va&#39;</span><span class="p">,</span> <span class="n">subset</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">keep</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                       <span class="n">filter_altered_genotypes</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">max_shift</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">keep_star</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Filter a user-defined set of alternate alleles for each variant.</span>
<span class="sd">        If all alternate alleles of a variant are filtered, the</span>
<span class="sd">        variant itself is filtered.  The condition expression is</span>
<span class="sd">        evaluated for each alternate allele, but not for</span>
<span class="sd">        the reference allele (i.e. ``aIndex`` will never be zero).</span>

<span class="sd">        .. include:: requireTGenotype.rst</span>

<span class="sd">        **Examples**</span>

<span class="sd">        To remove alternate alleles with zero allele count and</span>
<span class="sd">        update the alternate allele count annotation with the new</span>
<span class="sd">        indices:</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds.filter_alleles(&#39;va.info.AC[aIndex - 1] == 0&#39;,</span>
<span class="sd">        ...     annotation=&#39;va.info.AC = aIndices[1:].map(i =&gt; va.info.AC[i - 1])&#39;,</span>
<span class="sd">        ...     keep=False)</span>

<span class="sd">        Note that we skip the first element of ``aIndices`` because</span>
<span class="sd">        we are mapping between the old and new *allele* indices, not</span>
<span class="sd">        the *alternate allele* indices.</span>

<span class="sd">        **Notes**</span>

<span class="sd">        If ``filter_altered_genotypes`` is true, genotypes that contain filtered-out alleles are set to missing.</span>

<span class="sd">        :py:meth:`~hail.VariantDataset.filter_alleles` implements two algorithms for filtering alleles: subset and downcode. We will illustrate their</span>
<span class="sd">        behavior on the example genotype below when filtering the first alternate allele (allele 1) at a site with 1 reference</span>
<span class="sd">        allele and 2 alternate alleles.</span>

<span class="sd">        .. code-block:: text</span>

<span class="sd">          GT: 1/2</span>
<span class="sd">          GQ: 10</span>
<span class="sd">          AD: 0,50,35</span>

<span class="sd">          0 | 1000</span>
<span class="sd">          1 | 1000   10</span>
<span class="sd">          2 | 1000   0     20</span>
<span class="sd">            +-----------------</span>
<span class="sd">               0     1     2</span>

<span class="sd">        **Subset algorithm**</span>

<span class="sd">        The subset algorithm (the default, ``subset=True``) subsets the</span>
<span class="sd">        AD and PL arrays (i.e. removes entries corresponding to filtered alleles)</span>
<span class="sd">        and then sets GT to the genotype with the minimum PL.  Note</span>
<span class="sd">        that if the genotype changes (as in the example), the PLs</span>
<span class="sd">        are re-normalized (shifted) so that the most likely genotype has a PL of</span>
<span class="sd">        0.  Qualitatively, subsetting corresponds to the belief</span>
<span class="sd">        that the filtered alleles are not real so we should discard any</span>
<span class="sd">        probability mass associated with them.</span>

<span class="sd">        The subset algorithm would produce the following:</span>

<span class="sd">        .. code-block:: text</span>

<span class="sd">          GT: 1/1</span>
<span class="sd">          GQ: 980</span>
<span class="sd">          AD: 0,50</span>

<span class="sd">          0 | 980</span>
<span class="sd">          1 | 980    0</span>
<span class="sd">            +-----------</span>
<span class="sd">               0      1</span>

<span class="sd">        In summary:</span>

<span class="sd">        - GT: Set to most likely genotype based on the PLs ignoring the filtered allele(s).</span>
<span class="sd">        - AD: The filtered alleles&#39; columns are eliminated, e.g., filtering alleles 1 and 2 transforms ``25,5,10,20`` to ``25,20``.</span>
<span class="sd">        - DP: No change.</span>
<span class="sd">        - PL: The filtered alleles&#39; columns are eliminated and the remaining columns shifted so the minimum value is 0.</span>
<span class="sd">        - GQ: The second-lowest PL (after shifting).</span>

<span class="sd">        **Downcode algorithm**</span>

<span class="sd">        The downcode algorithm (``subset=False``) recodes occurances of filtered alleles</span>
<span class="sd">        to occurances of the reference allele (e.g. 1 -&gt; 0 in our example). So the depths of filtered alleles in the AD field</span>
<span class="sd">        are added to the depth of the reference allele. Where downcodeing filtered alleles merges distinct genotypes, the minimum PL is used (since PL is on a log scale, this roughly corresponds to adding probabilities). The PLs</span>
<span class="sd">        are then re-normalized (shifted) so that the most likely genotype has a PL of 0, and GT is set to this genotype.</span>
<span class="sd">        If an allele is filtered, this algorithm acts similarly to :py:meth:`~hail.VariantDataset.split_multi`.</span>

<span class="sd">        The downcoding algorithm would produce the following:</span>

<span class="sd">        .. code-block:: text</span>

<span class="sd">          GT: 0/1</span>
<span class="sd">          GQ: 10</span>
<span class="sd">          AD: 35,50</span>

<span class="sd">          0 | 20</span>
<span class="sd">          1 | 0    10</span>
<span class="sd">            +-----------</span>
<span class="sd">              0    1</span>

<span class="sd">        In summary:</span>

<span class="sd">        - GT: Downcode filtered alleles to reference.</span>
<span class="sd">        - AD: The filtered alleles&#39; columns are eliminated and their value is added to the reference, e.g., filtering alleles 1 and 2 transforms ``25,5,10,20`` to ``40,20``.</span>
<span class="sd">        - DP: No change.</span>
<span class="sd">        - PL: Downcode filtered alleles to reference, combine PLs using minimum for each overloaded genotype, and shift so the overall minimum PL is 0.</span>
<span class="sd">        - GQ: The second-lowest PL (after shifting).</span>

<span class="sd">        **Expression Variables**</span>

<span class="sd">        The following symbols are in scope for ``condition``:</span>

<span class="sd">        - ``v`` (*Variant*): :ref:`variant`</span>
<span class="sd">        - ``va``: variant annotations</span>
<span class="sd">        - ``aIndex`` (*Int*): the index of the allele being tested</span>

<span class="sd">        The following symbols are in scope for ``annotation``:</span>

<span class="sd">        - ``v`` (*Variant*): :ref:`variant`</span>
<span class="sd">        - ``va``: variant annotations</span>
<span class="sd">        - ``aIndices`` (*Array[Int]*): the array of old indices (such that ``aIndices[newIndex] = oldIndex`` and ``aIndices[0] = 0``)</span>

<span class="sd">        :param str condition: Filter expression involving v (variant), va (variant annotations), and aIndex (allele index)</span>

<span class="sd">        :param str annotation: Annotation modifying expression involving v (new variant), va (old variant annotations),</span>
<span class="sd">            and aIndices (maps from new to old indices)</span>

<span class="sd">        :param bool subset: If true, subsets PL and AD, otherwise downcodes the PL and AD.</span>
<span class="sd">            Genotype and GQ are set based on the resulting PLs.</span>

<span class="sd">        :param bool keep: If true, keep variants matching condition</span>

<span class="sd">        :param bool filter_altered_genotypes: If true, genotypes that contain filtered-out alleles are set to missing.</span>

<span class="sd">        :param int max_shift: maximum number of base pairs by which</span>
<span class="sd">            a split variant can move.  Affects memory usage, and will</span>
<span class="sd">            cause Hail to throw an error if a variant that moves further</span>
<span class="sd">            is encountered.</span>

<span class="sd">        :param bool keepStar: If true, keep variants where the only allele left is a ``*`` allele.</span>

<span class="sd">        :return: Filtered variant dataset.</span>
<span class="sd">        :rtype: :py:class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">jvds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvdf</span><span class="o">.</span><span class="n">filterAlleles</span><span class="p">(</span><span class="n">condition</span><span class="p">,</span> <span class="n">annotation</span><span class="p">,</span> <span class="n">filter_altered_genotypes</span><span class="p">,</span> <span class="n">keep</span><span class="p">,</span> <span class="n">subset</span><span class="p">,</span> <span class="n">max_shift</span><span class="p">,</span>
                                        <span class="n">keep_star</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">jvds</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.filter_genotypes"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.filter_genotypes">[docs]</a>    <span class="k">def</span> <span class="nf">filter_genotypes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">condition</span><span class="p">,</span> <span class="n">keep</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Filter genotypes based on expression.</span>

<span class="sd">        **Examples**</span>

<span class="sd">        Filter genotypes by allele balance dependent on genotype call:</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds.filter_genotypes(&#39;let ab = g.ad[1] / g.ad.sum() in &#39; +</span>
<span class="sd">        ...                      &#39;((g.isHomRef() &amp;&amp; ab &lt;= 0.1) || &#39; +</span>
<span class="sd">        ...                      &#39;(g.isHet() &amp;&amp; ab &gt;= 0.25 &amp;&amp; ab &lt;= 0.75) || &#39; +</span>
<span class="sd">        ...                      &#39;(g.isHomVar() &amp;&amp; ab &gt;= 0.9))&#39;)</span>

<span class="sd">        **Notes**</span>

<span class="sd">        ``condition`` is in genotype context so the following symbols are in scope:</span>

<span class="sd">        - ``s`` (*Sample*): :ref:`sample`</span>
<span class="sd">        - ``v`` (*Variant*): :ref:`variant`</span>
<span class="sd">        - ``sa``: sample annotations</span>
<span class="sd">        - ``va``: variant annotations</span>
<span class="sd">        - ``global``: global annotations</span>

<span class="sd">        For more information, see the documentation on `data representation, annotations &lt;overview.html#&gt;`_, and</span>
<span class="sd">        the `expression language &lt;exprlang.html&gt;`_.</span>

<span class="sd">        .. caution::</span>
<span class="sd">            When ``condition`` evaluates to missing, the genotype will be removed regardless of whether ``keep=True`` or ``keep=False``.</span>

<span class="sd">        :param condition: Expression for filter condition.</span>
<span class="sd">        :type condition: str</span>

<span class="sd">        :return: Filtered variant dataset.</span>
<span class="sd">        :rtype: :class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">jvds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvdf</span><span class="o">.</span><span class="n">filterGenotypes</span><span class="p">(</span><span class="n">condition</span><span class="p">,</span> <span class="n">keep</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">jvds</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
    <span class="nd">@requireTGenotype</span>
<div class="viewcode-block" id="VariantDataset.filter_multi"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.filter_multi">[docs]</a>    <span class="k">def</span> <span class="nf">filter_multi</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Filter out multi-allelic sites.</span>

<span class="sd">        .. include:: requireTGenotype.rst</span>

<span class="sd">        This method is much less computationally expensive than</span>
<span class="sd">        :py:meth:`.split_multi`, and can also be used to produce</span>
<span class="sd">        a variant dataset that can be used with methods that do not</span>
<span class="sd">        support multiallelic variants.</span>

<span class="sd">        :return: Dataset with no multiallelic sites, which can</span>
<span class="sd">            be used for biallelic-only methods.</span>
<span class="sd">        :rtype: :class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvdf</span><span class="o">.</span><span class="n">filterMulti</span><span class="p">())</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.drop_samples"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.drop_samples">[docs]</a>    <span class="k">def</span> <span class="nf">drop_samples</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Removes all samples from variant dataset.</span>

<span class="sd">        The variants, variant annotations, and global annnotations will remain,</span>
<span class="sd">        producing a sites-only variant dataset.</span>

<span class="sd">        :return: Sites-only variant dataset.</span>
<span class="sd">        :rtype: :py:class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">dropSamples</span><span class="p">())</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.filter_samples_expr"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.filter_samples_expr">[docs]</a>    <span class="k">def</span> <span class="nf">filter_samples_expr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">condition</span><span class="p">,</span> <span class="n">keep</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Filter samples based on expression.</span>

<span class="sd">        **Examples**</span>

<span class="sd">        Filter samples by phenotype (assumes sample annotation *sa.isCase* exists and is a Boolean variable):</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds.filter_samples_expr(&quot;sa.isCase&quot;)</span>

<span class="sd">        Remove samples with an ID that matches a regular expression:</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds.filter_samples_expr(&#39;&quot;^NA&quot; ~ s&#39; , keep=False)</span>

<span class="sd">        Filter samples from sample QC metrics and write output to a new variant dataset:</span>

<span class="sd">        &gt;&gt;&gt; (vds.sample_qc()</span>
<span class="sd">        ...     .filter_samples_expr(&#39;sa.qc.callRate &gt;= 0.99 &amp;&amp; sa.qc.dpMean &gt;= 10&#39;)</span>
<span class="sd">        ...     .write(&quot;output/filter_samples.vds&quot;))</span>

<span class="sd">        **Notes**</span>

<span class="sd">        ``condition`` is in sample context so the following symbols are in scope:</span>

<span class="sd">        - ``s`` (*Sample*): :ref:`sample`</span>
<span class="sd">        - ``sa``: sample annotations</span>
<span class="sd">        - ``global``: global annotations</span>
<span class="sd">        - ``gs`` (*Aggregable[Genotype]*): aggregable of :ref:`genotype` for sample ``s``</span>

<span class="sd">        For more information, see the documentation on `data representation, annotations &lt;overview.html#&gt;`_, and</span>
<span class="sd">        the `expression language &lt;exprlang.html&gt;`_.</span>

<span class="sd">        .. caution::</span>
<span class="sd">            When ``condition`` evaluates to missing, the sample will be removed regardless of whether ``keep=True`` or ``keep=False``.</span>


<span class="sd">        :param condition: Expression for filter condition.</span>
<span class="sd">        :type condition: str</span>

<span class="sd">        :return: Filtered variant dataset.</span>
<span class="sd">        :rtype: :py:class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">jvds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">filterSamplesExpr</span><span class="p">(</span><span class="n">condition</span><span class="p">,</span> <span class="n">keep</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">jvds</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.filter_samples_list"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.filter_samples_list">[docs]</a>    <span class="k">def</span> <span class="nf">filter_samples_list</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">samples</span><span class="p">,</span> <span class="n">keep</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Filter samples with a list of samples.</span>
<span class="sd">    </span>
<span class="sd">        **Examples**</span>
<span class="sd">    </span>
<span class="sd">        &gt;&gt;&gt; to_remove = [&#39;NA12878&#39;, &#39;NA12891&#39;, &#39;NA12892&#39;]</span>
<span class="sd">        &gt;&gt;&gt; vds_result = vds.filter_samples_list(to_remove, keep=False)</span>
<span class="sd">        </span>
<span class="sd">        Read list from a file:</span>
<span class="sd">        </span>
<span class="sd">        &gt;&gt;&gt; to_remove = [s.strip() for s in open(&#39;data/exclude_samples.txt&#39;)]</span>
<span class="sd">        &gt;&gt;&gt; vds_result = vds.filter_samples_list(to_remove, keep=False)</span>
<span class="sd">    </span>
<span class="sd">        :param samples: List of samples to keep or remove.</span>
<span class="sd">        :type samples: list of str</span>

<span class="sd">        :param bool keep: If true, keep samples in ``samples``, otherwise remove them.</span>
<span class="sd">    </span>
<span class="sd">        :return: Filtered variant dataset.</span>
<span class="sd">        :rtype: :py:class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;expected parameter &#39;samples&#39; to be type list, but found </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="nb">type</span><span class="p">(</span><span class="n">samples</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">unicode</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;expected elements in &#39;samples&#39; to be type str, but found </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="nb">type</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">filterSamplesList</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">keep</span><span class="p">))</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.drop_variants"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.drop_variants">[docs]</a>    <span class="k">def</span> <span class="nf">drop_variants</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Discard all variants, variant annotations and genotypes.</span>

<span class="sd">        Samples, sample annotations and global annotations are retained. This</span>
<span class="sd">        is the same as :func:`filter_variants_expr(&#39;false&#39;) &lt;hail.VariantDataset.filter_variants_expr&gt;`, but much faster.</span>

<span class="sd">        **Examples**</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds.drop_variants()</span>

<span class="sd">        :return: Samples-only variant dataset.</span>
<span class="sd">        :rtype: :py:class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">dropVariants</span><span class="p">())</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.filter_variants_expr"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.filter_variants_expr">[docs]</a>    <span class="k">def</span> <span class="nf">filter_variants_expr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">condition</span><span class="p">,</span> <span class="n">keep</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Filter variants based on expression.</span>

<span class="sd">        **Examples**</span>

<span class="sd">        Keep variants in the gene CHD8 (assumes the variant annotation ``va.gene`` exists):</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds.filter_variants_expr(&#39;va.gene == &quot;CHD8&quot;&#39;)</span>


<span class="sd">        Remove all variants on chromosome 1:</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds.filter_variants_expr(&#39;v.contig == &quot;1&quot;&#39;, keep=False)</span>

<span class="sd">        .. caution::</span>

<span class="sd">           The double quotes on ``&quot;1&quot;`` are necessary because ``v.contig`` is of type String.</span>

<span class="sd">        **Notes**</span>

<span class="sd">        The following symbols are in scope for ``condition``:</span>

<span class="sd">        - ``v`` (*Variant*): :ref:`variant`</span>
<span class="sd">        - ``va``: variant annotations</span>
<span class="sd">        - ``global``: global annotations</span>
<span class="sd">        - ``gs`` (*Aggregable[Genotype]*): aggregable of :ref:`genotype` for variant ``v``</span>

<span class="sd">        For more information, see the `Overview &lt;overview.html#&gt;`_ and the `Expression Language &lt;exprlang.html&gt;`_.</span>

<span class="sd">        .. caution::</span>
<span class="sd">           When ``condition`` evaluates to missing, the variant will be removed regardless of whether ``keep=True`` or ``keep=False``.</span>

<span class="sd">        :param condition: Expression for filter condition.</span>
<span class="sd">        :type condition: str</span>

<span class="sd">        :return: Filtered variant dataset.</span>
<span class="sd">        :rtype: :py:class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">jvds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">filterVariantsExpr</span><span class="p">(</span><span class="n">condition</span><span class="p">,</span> <span class="n">keep</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">jvds</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.filter_variants_intervals"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.filter_variants_intervals">[docs]</a>    <span class="k">def</span> <span class="nf">filter_variants_intervals</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">intervals</span><span class="p">,</span> <span class="n">keep</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Filter variants with an interval or interval tree.</span>

<span class="sd">        **Examples**</span>

<span class="sd">        &gt;&gt;&gt; from hail.representation import *</span>
<span class="sd">        &gt;&gt;&gt; vds_result = vds.filter_variants_intervals(IntervalTree.read(&#39;data/intervals.txt&#39;))</span>
<span class="sd">        &gt;&gt;&gt; vds_result = vds.filter_variants_intervals(IntervalTree.parse_all([&#39;1:50M-75M&#39;, &#39;2:START-400000&#39;,&#39;3-22&#39;]))</span>
<span class="sd">        &gt;&gt;&gt; vds_result = vds.filter_variants_intervals(Interval(Locus(&#39;17&#39;, 38449840), Locus(&#39;17&#39;, 38530994)))</span>
<span class="sd">        &gt;&gt;&gt; vds_result = vds.filter_variants_intervals(Interval.parse(&#39;17:38449840-38530994&#39;))</span>

<span class="sd">        This method takes an argument either of :class:`.Interval` or :class:`.IntervalTree`.</span>

<span class="sd">        Based on the ``keep`` argument, this method will either restrict to variants in the</span>
<span class="sd">        supplied interval range, or remove all variants in that range.  Note that intervals</span>
<span class="sd">        are left-inclusive, and right-exclusive.  The below interval includes the locus</span>
<span class="sd">        ``15:100000`` but not ``15:101000``.</span>

<span class="sd">        &gt;&gt;&gt; interval = Interval.parse(&#39;15:100000-101000&#39;)</span>

<span class="sd">        To supply a file containing intervals, use :py:meth:`.IntervalTree.read`:</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds.filter_variants_intervals(IntervalTree.read(&#39;data/intervals.txt&#39;))</span>

<span class="sd">        This method performs predicate pushdown when ``keep`` is ``True``, meaning that data shards</span>
<span class="sd">        that don&#39;t overlap any supplied interval will not be loaded at all.  This property</span>
<span class="sd">        enables ``filter_variants_intervals`` to be used for reasonably low-latency queries of one</span>
<span class="sd">        or more variants, even on large variant datasets:</span>

<span class="sd">        &gt;&gt;&gt;  # We are interested in the variant 15:100203:A:T</span>
<span class="sd">        &gt;&gt;&gt; vds_filtered = vds.filter_variants_expr(&#39;v.contig == &quot;15&quot; &amp;&amp; v.start == 100203&#39;)  # slow</span>
<span class="sd">        &gt;&gt;&gt; vds_filtered = vds.filter_variants_intervals(Interval.parse(&#39;15:100203-100204&#39;))  # very fast</span>

<span class="sd">        :param intervals: interval or interval tree object</span>
<span class="sd">        :type intervals: s:class:`.Interval` or :class:`.IntervalTree`</span>

<span class="sd">        :return: Filtered variant dataset.</span>
<span class="sd">        :rtype: :py:class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">intervals</span><span class="p">,</span> <span class="n">Interval</span><span class="p">):</span>
            <span class="n">intervals</span> <span class="o">=</span> <span class="n">IntervalTree</span><span class="p">([</span><span class="n">intervals</span><span class="p">])</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">intervals</span><span class="p">,</span> <span class="n">IntervalTree</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;argument &#39;intervals&#39; must be of type Interval or IntervalTree, but found &#39;</span><span class="si">%s</span><span class="s2">&#39;&quot;</span> <span class="o">%</span>
                            <span class="nb">type</span><span class="p">(</span><span class="n">intervals</span><span class="p">))</span>

        <span class="n">jvds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">filterIntervals</span><span class="p">(</span><span class="n">intervals</span><span class="o">.</span><span class="n">_jrep</span><span class="p">,</span> <span class="n">keep</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">jvds</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.filter_variants_list"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.filter_variants_list">[docs]</a>    <span class="k">def</span> <span class="nf">filter_variants_list</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variants</span><span class="p">,</span> <span class="n">keep</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Filter variants with a list of variants.</span>

<span class="sd">        **Examples**</span>

<span class="sd">        Filter VDS down to a list of variants:</span>

<span class="sd">        &gt;&gt;&gt; vds.filter_variants_list([Variant.parse(&#39;20:10626633:G:GC&#39;), Variant.parse(&#39;20:10019093:A:G&#39;)], keep=True)</span>

<span class="sd">        :param variants: List of variants to keep or remove.</span>
<span class="sd">        :type variants: list of :py:class:`~hail.representation.Variant`</span>

<span class="sd">        :param bool keep: If true, keep variants in ``variants``, otherwise remove them.</span>

<span class="sd">        :return: Filtered variant dataset.</span>
<span class="sd">        :rtype: :py:class:`.VariantDataset`</span>
<span class="sd">        </span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">filterVariantsList</span><span class="p">(</span>
                <span class="p">[</span><span class="n">TVariant</span><span class="p">()</span><span class="o">.</span><span class="n">_convert_to_j</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">variants</span><span class="p">],</span> <span class="n">keep</span><span class="p">))</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.filter_variants_kt"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.filter_variants_kt">[docs]</a>    <span class="k">def</span> <span class="nf">filter_variants_kt</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">kt</span><span class="p">,</span> <span class="n">keep</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Filter variants with a Variant keyed key table.</span>

<span class="sd">        **Example**</span>

<span class="sd">        Filter variants of a VDS to those appearing in the Variant column of a TSV file:</span>

<span class="sd">        &gt;&gt;&gt; kt = hc.import_keytable(&#39;data/sample_variants.txt&#39;, key=&#39;Variant&#39;, config=TextTableConfig(impute=True))</span>
<span class="sd">        &gt;&gt;&gt; filtered_vds = vds.filter_variants_kt(kt, keep=True)</span>

<span class="sd">        :param kt: Keep or remove ``kt`` keys.</span>
<span class="sd">        :type kt: :py:class:`.KeyTable`</span>

<span class="sd">        :param bool keep: If true, keep variants which appear as keys</span>
<span class="sd">          in ``kt``, otherwise remove them.</span>

<span class="sd">        :return: Filtered variant dataset.</span>
<span class="sd">        :rtype: :py:class:`.VariantDataset`</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">filterVariantsKT</span><span class="p">(</span><span class="n">kt</span><span class="o">.</span><span class="n">_jkt</span><span class="p">,</span> <span class="n">keep</span><span class="p">))</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">globals</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Return global annotations as a Python object.</span>

<span class="sd">        :return: Dataset global annotations.</span>
<span class="sd">        :rtype: :py:class:`~hail.representation.Struct`</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_globals</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_globals</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_schema</span><span class="o">.</span><span class="n">_convert_to_py</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">globalAnnotation</span><span class="p">())</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_globals</span>

    <span class="nd">@handle_py4j</span>
    <span class="nd">@requireTGenotype</span>
<div class="viewcode-block" id="VariantDataset.grm"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.grm">[docs]</a>    <span class="k">def</span> <span class="nf">grm</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Compute the Genetic Relatedness Matrix (GRM).</span>

<span class="sd">        .. include:: requireTGenotype.rst</span>

<span class="sd">        **Examples**</span>
<span class="sd">        </span>
<span class="sd">        &gt;&gt;&gt; km = vds.grm()</span>
<span class="sd">        </span>
<span class="sd">        **Notes**</span>
<span class="sd">        </span>
<span class="sd">        The genetic relationship matrix (GRM) :math:`G` encodes genetic correlation between each pair of samples. It is defined by :math:`G = MM^T` where :math:`M` is a standardized version of the genotype matrix, computed as follows. Let :math:`C` be the :math:`n \\times m` matrix of raw genotypes in the variant dataset, with rows indexed by :math:`n` samples and columns indexed by :math:`m` bialellic autosomal variants; :math:`C_{ij}` is the number of alternate alleles of variant :math:`j` carried by sample :math:`i`, which can be 0, 1, 2, or missing. For each variant :math:`j`, the sample alternate allele frequency :math:`p_j` is computed as half the mean of the non-missing entries of column :math:`j`. Entries of :math:`M` are then mean-centered and variance-normalized as</span>

<span class="sd">        .. math::</span>

<span class="sd">          M_{ij} = \\frac{C_{ij}-2p_j}{\sqrt{2p_j(1-p_j)m}},</span>

<span class="sd">        with :math:`M_{ij} = 0` for :math:`C_{ij}` missing (i.e. mean genotype imputation). This scaling normalizes genotype variances to a common value :math:`1/m` for variants in Hardy-Weinberg equilibrium and is further motivated in the paper `Patterson, Price and Reich, 2006 &lt;http://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.0020190&gt;`_. (The resulting amplification of signal from the low end of the allele frequency spectrum will also introduce noise for rare variants; common practice is to filter out variants with minor allele frequency below some cutoff.)  The factor :math:`1/m` gives each sample row approximately unit total variance (assuming linkage equilibrium) so that the diagonal entries of the GRM are approximately 1. Equivalently,</span>
<span class="sd">        </span>
<span class="sd">        .. math::</span>

<span class="sd">          G_{ik} = \\frac{1}{m} \\sum_{j=1}^m \\frac{(C_{ij}-2p_j)(C_{kj}-2p_j)}{2 p_j (1-p_j)}  </span>
<span class="sd">                </span>
<span class="sd">        :return: Genetic Relatedness Matrix for all samples.</span>
<span class="sd">        :rtype: :py:class:`KinshipMatrix`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">jkm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvdf</span><span class="o">.</span><span class="n">grm</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">KinshipMatrix</span><span class="p">(</span><span class="n">jkm</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
    <span class="nd">@requireTGenotype</span>
<div class="viewcode-block" id="VariantDataset.hardcalls"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.hardcalls">[docs]</a>    <span class="k">def</span> <span class="nf">hardcalls</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Drop all genotype fields except the GT field.</span>

<span class="sd">        .. include:: requireTGenotype.rst</span>

<span class="sd">        A hard-called variant dataset is about two orders of magnitude</span>
<span class="sd">        smaller than a standard sequencing dataset. Use this</span>
<span class="sd">        method to create a smaller, faster</span>
<span class="sd">        representation for downstream processing that only</span>
<span class="sd">        requires the GT field.</span>

<span class="sd">        :return: Variant dataset with no genotype metadata.</span>
<span class="sd">        :rtype: :py:class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvdf</span><span class="o">.</span><span class="n">hardCalls</span><span class="p">())</span></div>

    <span class="nd">@handle_py4j</span>
    <span class="nd">@requireTGenotype</span>
<div class="viewcode-block" id="VariantDataset.ibd"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.ibd">[docs]</a>    <span class="k">def</span> <span class="nf">ibd</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">maf</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bounded</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Compute matrix of identity-by-descent estimations.</span>

<span class="sd">        .. include:: requireTGenotype.rst</span>

<span class="sd">        **Examples**</span>

<span class="sd">        To calculate a full IBD matrix, using minor allele frequencies computed</span>
<span class="sd">        from the variant dataset itself:</span>

<span class="sd">        &gt;&gt;&gt; vds.ibd()</span>

<span class="sd">        To calculate an IBD matrix containing only pairs of samples with</span>
<span class="sd">        ``PI_HAT`` in [0.2, 0.9], using minor allele frequencies stored in</span>
<span class="sd">        ``va.panel_maf``:</span>

<span class="sd">        &gt;&gt;&gt; vds.ibd(maf=&#39;va.panel_maf&#39;, min=0.2, max=0.9)</span>

<span class="sd">        **Notes**</span>

<span class="sd">        The implementation is based on the IBD algorithm described in the `PLINK</span>
<span class="sd">        paper &lt;http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1950838&gt;`_.</span>

<span class="sd">        :py:meth:`~hail.VariantDataset.ibd` requires the dataset to be</span>
<span class="sd">        bi-allelic (otherwise run :py:meth:`~hail.VariantDataset.split_multi` or otherwise run :py:meth:`~hail.VariantDataset.filter_multi`)</span>
<span class="sd">        and does not perform LD pruning. Linkage disequilibrium may bias the</span>
<span class="sd">        result so consider filtering variants first.</span>

<span class="sd">        The resulting :py:class:`.KeyTable` entries have the type: *{ i: String,</span>
<span class="sd">        j: String, ibd: { Z0: Double, Z1: Double, Z2: Double, PI_HAT: Double },</span>
<span class="sd">        ibs0: Long, ibs1: Long, ibs2: Long }*. The key list is: `*i: String, j:</span>
<span class="sd">        String*`.</span>

<span class="sd">        Conceptually, the output is a symmetric, sample-by-sample matrix. The</span>
<span class="sd">        output key table has the following form</span>

<span class="sd">        .. code-block:: text</span>

<span class="sd">            i		j	ibd.Z0	ibd.Z1	ibd.Z2	ibd.PI_HAT ibs0	ibs1	ibs2</span>
<span class="sd">            sample1	sample2	1.0000	0.0000	0.0000	0.0000 ...</span>
<span class="sd">            sample1	sample3	1.0000	0.0000	0.0000	0.0000 ...</span>
<span class="sd">            sample1	sample4	0.6807	0.0000	0.3193	0.3193 ...</span>
<span class="sd">            sample1	sample5	0.1966	0.0000	0.8034	0.8034 ...</span>

<span class="sd">        :param maf: Expression for the minor allele frequency.</span>
<span class="sd">        :type maf: str or None</span>

<span class="sd">        :param bool bounded: Forces the estimations for Z0, Z1, Z2,</span>
<span class="sd">            and PI_HAT to take on biologically meaningful values</span>
<span class="sd">            (in the range [0,1]).</span>

<span class="sd">        :param min: Sample pairs with a PI_HAT below this value will</span>
<span class="sd">            not be included in the output. Must be in [0,1].</span>
<span class="sd">        :type min: float or None</span>

<span class="sd">        :param max: Sample pairs with a PI_HAT above this value will</span>
<span class="sd">            not be included in the output. Must be in [0,1].</span>
<span class="sd">        :type max: float or None</span>

<span class="sd">        :return: A :py:class:`.KeyTable` mapping pairs of samples to their IBD</span>
<span class="sd">            statistics</span>

<span class="sd">        :rtype: :py:class:`.KeyTable`</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">KeyTable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvdf</span><span class="o">.</span><span class="n">ibd</span><span class="p">(</span><span class="n">joption</span><span class="p">(</span><span class="n">maf</span><span class="p">),</span> <span class="n">bounded</span><span class="p">,</span> <span class="n">joption</span><span class="p">(</span><span class="nb">min</span><span class="p">),</span> <span class="n">joption</span><span class="p">(</span><span class="nb">max</span><span class="p">)))</span></div>

    <span class="nd">@handle_py4j</span>
    <span class="nd">@requireTGenotype</span>
<div class="viewcode-block" id="VariantDataset.ibd_prune"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.ibd_prune">[docs]</a>    <span class="k">def</span> <span class="nf">ibd_prune</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">tiebreaking_expr</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">maf</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bounded</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Prune samples from the :py:class:`.VariantDataset` based on :py:meth:`~hail.VariantDataset.ibd` PI_HAT measures of relatedness.</span>

<span class="sd">        .. include:: requireTGenotype.rst</span>

<span class="sd">        **Examples**</span>

<span class="sd">        Prune samples so that no two have a PI_HAT value greater than or equal to 0.5:</span>

<span class="sd">        &gt;&gt;&gt; pruned_vds = vds.ibd_prune(0.5)</span>

<span class="sd">        **Notes**</span>

<span class="sd">        The variant dataset returned may change in near future as a result of algorithmic improvements. The current algorithm is very efficient on datasets with many small</span>
<span class="sd">        families, less so on datasets with large families. Currently, the algorithm works by deleting the person from each family who has the highest number of relatives,</span>
<span class="sd">        and iterating until no two people have a PI_HAT value greater than that specified. If two people within a family have the same number of relatives, the tiebreaking_expr</span>
<span class="sd">        given will be used to determine which sample gets deleted. </span>
<span class="sd">        </span>
<span class="sd">        The tiebreaking_expr namespace has the following variables available:</span>
<span class="sd">        </span>
<span class="sd">        - ``s1``: The first sample id.</span>
<span class="sd">        - ``sa1``: The annotations associated with s1.</span>
<span class="sd">        - ``s2``: The second sample id. </span>
<span class="sd">        - ``sa2``: The annotations associated with s2. </span>
<span class="sd">        </span>
<span class="sd">        The tiebreaking_expr returns an integer expressing the preference for one sample over the other. Any negative integer expresses a preference for keeping ``s1``. Any positive integer expresses a preference for keeping ``s2``. A zero expresses no preference. This function must induce a `preorder &lt;https://en.wikipedia.org/wiki/Preorder&gt;`_ on the samples, in particular:</span>

<span class="sd">        - ``tiebreaking_expr(sample1, sample2)`` must equal ``-1 * tie breaking_expr(sample2, sample1)``, which evokes the common sense understanding that if ``x &lt; y`` then `y &gt; x``.</span>
<span class="sd">        - ``tiebreaking_expr(sample1, sample1)`` must equal 0, i.e. ``x = x``</span>
<span class="sd">        - if sample1 is preferred to sample2 and sample2 is preferred to sample3, then sample1 must also be preferred to sample3</span>

<span class="sd">        The last requirement is only important if you have three related samples with the same number of relatives and all three are related to one another. In cases like this one, it is important that either:</span>

<span class="sd">        - one of the three is preferred to **both** other ones, or</span>
<span class="sd">        - there is no preference among the three samples </span>

<span class="sd">        :param threshold: The desired maximum PI_HAT value between any pair of samples.</span>
<span class="sd">        :param tiebreaking_expr: Expression used to choose between two samples with the same number of relatives. </span>
<span class="sd">        :param maf: Expression for the minor allele frequency.</span>
<span class="sd">        :param bounded: Forces the estimations for Z0, Z1, Z2, and PI_HAT to take on biologically meaningful values (in the range [0,1]).</span>

<span class="sd">        :return: A :py:class:`.VariantDataset` containing no samples with a PI_HAT greater than threshold.</span>
<span class="sd">        :rtype: :py:class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvdf</span><span class="o">.</span><span class="n">ibdPrune</span><span class="p">(</span><span class="n">threshold</span><span class="p">,</span> <span class="n">joption</span><span class="p">(</span><span class="n">tiebreaking_expr</span><span class="p">),</span> <span class="n">joption</span><span class="p">(</span><span class="n">maf</span><span class="p">),</span> <span class="n">bounded</span><span class="p">))</span></div>

    <span class="nd">@handle_py4j</span>
    <span class="nd">@requireTGenotype</span>
<div class="viewcode-block" id="VariantDataset.impute_sex"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.impute_sex">[docs]</a>    <span class="k">def</span> <span class="nf">impute_sex</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">maf_threshold</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">include_par</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">female_threshold</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">male_threshold</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">pop_freq</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Impute sex of samples by calculating inbreeding coefficient on the</span>
<span class="sd">        X chromosome.</span>

<span class="sd">        .. include:: requireTGenotype.rst</span>

<span class="sd">        **Examples**</span>

<span class="sd">        Remove samples where imputed sex does not equal reported sex:</span>

<span class="sd">        &gt;&gt;&gt; imputed_sex_vds = (vds.impute_sex()</span>
<span class="sd">        ...     .annotate_samples_expr(&#39;sa.sexcheck = sa.pheno.isFemale == sa.imputesex.isFemale&#39;)</span>
<span class="sd">        ...     .filter_samples_expr(&#39;sa.sexcheck || isMissing(sa.sexcheck)&#39;))</span>

<span class="sd">        **Notes**</span>

<span class="sd">        We have used the same implementation as `PLINK v1.7 &lt;http://pngu.mgh.harvard.edu/~purcell/plink/summary.shtml#sexcheck&gt;`_.</span>

<span class="sd">        1. X chromosome variants are selected from the VDS: ``v.contig == &quot;X&quot; || v.contig == &quot;23&quot;``</span>
<span class="sd">        2. Variants with a minor allele frequency less than the threshold given by ``maf-threshold`` are removed</span>
<span class="sd">        3. Variants in the pseudoautosomal region `(X:60001-2699520) || (X:154931044-155260560)` are included if the ``include_par`` optional parameter is set to true.</span>
<span class="sd">        4. The minor allele frequency (maf) per variant is calculated.</span>
<span class="sd">        5. For each variant and sample with a non-missing genotype call, :math:`E`, the expected number of homozygotes (from population MAF), is computed as :math:`1.0 - (2.0*maf*(1.0-maf))`.</span>
<span class="sd">        6. For each variant and sample with a non-missing genotype call, :math:`O`, the observed number of homozygotes, is computed as `0 = heterozygote; 1 = homozygote`</span>
<span class="sd">        7. For each variant and sample with a non-missing genotype call, :math:`N` is incremented by 1</span>
<span class="sd">        8. For each sample, :math:`E`, :math:`O`, and :math:`N` are combined across variants</span>
<span class="sd">        9. :math:`F` is calculated by :math:`(O - E) / (N - E)`</span>
<span class="sd">        10. A sex is assigned to each sample with the following criteria: `F &lt; 0.2 =&gt; Female; F &gt; 0.8 =&gt; Male`. Use ``female-threshold`` and ``male-threshold`` to change this behavior.</span>

<span class="sd">        **Annotations**</span>

<span class="sd">        The below annotations can be accessed with ``sa.imputesex``.</span>

<span class="sd">        - **isFemale** (*Boolean*) -- True if the imputed sex is female, false if male, missing if undetermined</span>
<span class="sd">        - **Fstat** (*Double*) -- Inbreeding coefficient</span>
<span class="sd">        - **nTotal** (*Long*) -- Total number of variants considered</span>
<span class="sd">        - **nCalled**  (*Long*) -- Number of variants with a genotype call</span>
<span class="sd">        - **expectedHoms** (*Double*) -- Expected number of homozygotes</span>
<span class="sd">        - **observedHoms** (*Long*) -- Observed number of homozygotes</span>


<span class="sd">        :param float maf_threshold: Minimum minor allele frequency threshold.</span>

<span class="sd">        :param bool include_par: Include pseudoautosomal regions.</span>

<span class="sd">        :param float female_threshold: Samples are called females if F &lt; femaleThreshold</span>

<span class="sd">        :param float male_threshold: Samples are called males if F &gt; maleThreshold</span>

<span class="sd">        :param str pop_freq: Variant annotation for estimate of MAF.</span>
<span class="sd">            If None, MAF will be computed.</span>

<span class="sd">        :return: Annotated dataset.</span>
<span class="sd">        :rtype: :py:class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">jvds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvdf</span><span class="o">.</span><span class="n">imputeSex</span><span class="p">(</span><span class="n">maf_threshold</span><span class="p">,</span> <span class="n">include_par</span><span class="p">,</span> <span class="n">female_threshold</span><span class="p">,</span> <span class="n">male_threshold</span><span class="p">,</span> <span class="n">joption</span><span class="p">(</span><span class="n">pop_freq</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">jvds</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.join"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.join">[docs]</a>    <span class="k">def</span> <span class="nf">join</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">right</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Join two variant datasets.</span>

<span class="sd">        **Notes**</span>

<span class="sd">        This method performs an inner join on variants,</span>
<span class="sd">        concatenates samples, and takes variant and</span>
<span class="sd">        global annotations from the left dataset (self).</span>

<span class="sd">        The datasets must have distinct samples, the same sample schema, and the same split status (both split or both multi-allelic).</span>

<span class="sd">        :param right: right-hand variant dataset</span>
<span class="sd">        :type right: :py:class:`.VariantDataset`</span>

<span class="sd">        :return: Joined variant dataset</span>
<span class="sd">        :rtype: :py:class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">right</span><span class="o">.</span><span class="n">_jvds</span><span class="p">))</span></div>

    <span class="nd">@handle_py4j</span>
    <span class="nd">@requireTGenotype</span>
<div class="viewcode-block" id="VariantDataset.ld_prune"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.ld_prune">[docs]</a>    <span class="k">def</span> <span class="nf">ld_prune</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">r2</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">window</span><span class="o">=</span><span class="mi">1000000</span><span class="p">,</span> <span class="n">memory_per_core</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">num_cores</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Prune variants in linkage disequilibrium (LD).</span>

<span class="sd">        .. include:: requireTGenotype.rst</span>

<span class="sd">        Requires :py:class:`~hail.VariantDataset.was_split` equals True.</span>

<span class="sd">        **Examples**</span>

<span class="sd">        Export the set of common LD pruned variants to a file:</span>

<span class="sd">        &gt;&gt;&gt; vds_result = (vds.variant_qc()</span>
<span class="sd">        ...                  .filter_variants_expr(&quot;va.qc.AF &gt;= 0.05 &amp;&amp; va.qc.AF &lt;= 0.95&quot;)</span>
<span class="sd">        ...                  .ld_prune()</span>
<span class="sd">        ...                  .export_variants(&quot;output/ldpruned.variants&quot;, &quot;v&quot;))</span>

<span class="sd">        **Notes**</span>

<span class="sd">        Variants are pruned in each contig from smallest to largest start position. The LD pruning algorithm is as follows:</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            pruned_set = []</span>
<span class="sd">            for v1 in contig:</span>
<span class="sd">                keep = True</span>
<span class="sd">                for v2 in pruned_set:</span>
<span class="sd">                    if ((v1.position - v2.position) &lt;= window and correlation(v1, v2) &gt;= r2):</span>
<span class="sd">                        keep = False</span>
<span class="sd">                if keep:</span>
<span class="sd">                    pruned_set.append(v1)</span>

<span class="sd">        The parameter ``window`` defines the maximum distance in base pairs between two variants to check whether</span>
<span class="sd">        the variants are independent (:math:`R^2` &lt; ``r2``) where ``r2`` is the maximum :math:`R^2` allowed.</span>
<span class="sd">        :math:`R^2` is defined as the square of `Pearson&#39;s correlation coefficient &lt;https://en.wikipedia.org/wiki/Pearson_correlation_coefficient&gt;`_</span>
<span class="sd">        :math:`{\\rho}_{x,y}` between the two genotype vectors :math:`{\\mathbf{x}}` and :math:`{\\mathbf{y}}`.</span>

<span class="sd">        .. math::</span>

<span class="sd">            {\\rho}_{x,y} = \\frac{\\mathrm{Cov}(X,Y)}{\\sigma_X \\sigma_Y}</span>


<span class="sd">        :py:meth:`.ld_prune` with default arguments is equivalent to ``plink --indep-pairwise 1000kb 1 0.2``.</span>
<span class="sd">        The list of pruned variants returned by Hail and PLINK will differ because Hail mean-imputes missing values and tests pairs of variants in a different order than PLINK.</span>

<span class="sd">        Be sure to provide enough disk space per worker because :py:meth:`.ld_prune` `persists &lt;http://spark.apache.org/docs/latest/programming-guide.html#rdd-persistence&gt;`_ up to 3 copies of the data to both memory and disk.</span>
<span class="sd">        The amount of disk space required will depend on the size and minor allele frequency of the input data and the prune parameters ``r2`` and ``window``. The number of bytes stored in memory per variant is about ``nSamples / 4 + 50``.</span>

<span class="sd">        .. warning::</span>

<span class="sd">            The variants in the pruned set are not guaranteed to be identical each time :py:meth:`.ld_prune` is run. We recommend running :py:meth:`.ld_prune` once and exporting the list of LD pruned variants using</span>
<span class="sd">            :py:meth:`.export_variants` for future use.</span>


<span class="sd">        :param float r2: Maximum :math:`R^2` threshold between two variants in the pruned set within a given window.</span>

<span class="sd">        :param int window: Width of window in base-pairs for computing pair-wise :math:`R^2` values.</span>

<span class="sd">        :param float memory_per_core: Total amount of memory available for each core in MB. If unsure, use the default value.</span>

<span class="sd">        :param int num_cores: The number of cores available. Equivalent to the total number of workers times the number of cores per worker.</span>

<span class="sd">        :return: Variant dataset filtered to those variants which remain after LD pruning.</span>

<span class="sd">        :rtype: VariantDataset</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">memory_per_core</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">memory_per_core</span> <span class="o">*</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span><span class="p">)</span>
        <span class="n">jvds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvdf</span><span class="o">.</span><span class="n">ldPrune</span><span class="p">(</span><span class="n">r2</span><span class="p">,</span> <span class="n">window</span><span class="p">,</span> <span class="n">num_cores</span><span class="p">,</span> <span class="n">memory_per_core</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">jvds</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
    <span class="nd">@requireTGenotype</span>
<div class="viewcode-block" id="VariantDataset.linreg"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.linreg">[docs]</a>    <span class="k">def</span> <span class="nf">linreg</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">covariates</span><span class="o">=</span><span class="p">[],</span> <span class="n">root</span><span class="o">=</span><span class="s1">&#39;va.linreg&#39;</span><span class="p">,</span> <span class="n">use_dosages</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">min_ac</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">min_af</span><span class="o">=</span><span class="mf">0.0</span><span class="p">):</span>
        <span class="sd">r&quot;&quot;&quot;Test each variant for association using linear regression.</span>

<span class="sd">        .. include:: requireTGenotype.rst</span>

<span class="sd">        **Examples**</span>

<span class="sd">        Run linear regression per variant using a phenotype and two covariates stored in sample annotations:</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds.linreg(&#39;sa.pheno.height&#39;, covariates=[&#39;sa.pheno.age&#39;, &#39;sa.pheno.isFemale&#39;])</span>

<span class="sd">        **Notes**</span>

<span class="sd">        The :py:meth:`.linreg` command computes, for each variant, statistics of</span>
<span class="sd">        the :math:`t`-test for the genotype coefficient of the linear function</span>
<span class="sd">        of best fit from sample genotype and covariates to quantitative</span>
<span class="sd">        phenotype or case-control status. Hail only includes samples for which</span>
<span class="sd">        phenotype and all covariates are defined. For each variant, missing genotypes</span>
<span class="sd">        as the mean of called genotypes.</span>

<span class="sd">        By default, genotypes values are given by hard call genotypes (``g.gt``).</span>
<span class="sd">        If ``use_dosages=True``, then genotype values are given by dosage genotypes, defined by</span>
<span class="sd">        :math:`\mathrm{P}(\mathrm{Het}) + 2 \cdot \mathrm{P}(\mathrm{HomVar})`. For any variant, if ``Variant.is_dosage``</span>
<span class="sd">        is false, then :math:`\mathrm{P}(\mathrm{Het})` and :math:`\mathrm{P}(\mathrm{HomVar})` are</span>
<span class="sd">        calculated by normalizing the PL likelihoods (converted from the Phred-scale) to sum to 1.</span>

<span class="sd">        Assuming there are sample annotations ``sa.pheno.height``,</span>
<span class="sd">        ``sa.pheno.age``, ``sa.pheno.isFemale``, and ``sa.cov.PC1``, the command:</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds.linreg(&#39;sa.pheno.height&#39;, covariates=[&#39;sa.pheno.age&#39;, &#39;sa.pheno.isFemale&#39;, &#39;sa.cov.PC1&#39;])</span>

<span class="sd">        considers a model of the form</span>

<span class="sd">        .. math::</span>

<span class="sd">            \mathrm{height} = \beta_0 + \beta_1 \, \mathrm{gt} + \beta_2 \, \mathrm{age} + \beta_3 \, \mathrm{isFemale} + \beta_4 \, \mathrm{PC1} + \varepsilon, \quad \varepsilon \sim \mathrm{N}(0, \sigma^2)</span>

<span class="sd">        where the genotype :math:`\mathrm{gt}` is coded as :math:`0` for HomRef, :math:`1` for</span>
<span class="sd">        Het, and :math:`2` for HomVar, and the Boolean covariate :math:`\mathrm{isFemale}`</span>
<span class="sd">        is coded as :math:`1` for true (female) and :math:`0` for false (male). The null</span>
<span class="sd">        model sets :math:`\beta_1 = 0`.</span>

<span class="sd">        :py:meth:`.linreg` skips variants that don&#39;t vary across the included samples,</span>
<span class="sd">        such as when all genotypes are homozygous reference. One can further</span>
<span class="sd">        restrict computation to those variants with at least :math:`k` observed</span>
<span class="sd">        alternate alleles (AC) or alternate allele frequency (AF) at least</span>
<span class="sd">        :math:`p` in the included samples using the options ``minac=k`` or</span>
<span class="sd">        ``minaf=p``, respectively. Unlike the :py:meth:`.filter_variants_expr`</span>
<span class="sd">        command, these filters do not remove variants from the underlying</span>
<span class="sd">        variant dataset. Adding both filters is equivalent to applying the more</span>
<span class="sd">        stringent of the two, as AF equals AC over twice the number of included</span>
<span class="sd">        samples.</span>

<span class="sd">        Phenotype and covariate sample annotations may also be specified using `programmatic expressions &lt;exprlang.html&gt;`_ without identifiers, such as:</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds.linreg(&#39;if (sa.pheno.isFemale) sa.pheno.age else (2 * sa.pheno.age + 10)&#39;, covariates=[])</span>

<span class="sd">        For Boolean covariate types, true is coded as 1 and false as 0. In particular, for the sample annotation ``sa.fam.isCase`` added by importing a FAM file with case-control phenotype, case is 1 and control is 0.</span>

<span class="sd">        The standard least-squares linear regression model is derived in Section</span>
<span class="sd">        3.2 of `The Elements of Statistical Learning, 2nd Edition</span>
<span class="sd">        &lt;http://statweb.stanford.edu/~tibs/ElemStatLearn/printings/ESLII_print10.pdf&gt;`_. See</span>
<span class="sd">        equation 3.12 for the t-statistic which follows the t-distribution with</span>
<span class="sd">        :math:`n - k - 2` degrees of freedom, under the null hypothesis of no</span>
<span class="sd">        effect, with :math:`n` samples and :math:`k` covariates in addition to</span>
<span class="sd">        genotype and intercept.</span>

<span class="sd">        **Annotations**</span>

<span class="sd">        With the default root, the following four variant annotations are added.</span>

<span class="sd">        - **va.linreg.beta** (*Double*) -- fit genotype coefficient, :math:`\hat\beta_1`</span>
<span class="sd">        - **va.linreg.se** (*Double*) -- estimated standard error, :math:`\widehat{\mathrm{se}}`</span>
<span class="sd">        - **va.linreg.tstat** (*Double*) -- :math:`t`-statistic, equal to :math:`\hat\beta_1 / \widehat{\mathrm{se}}`</span>
<span class="sd">        - **va.linreg.pval** (*Double*) -- :math:`p`-value</span>

<span class="sd">        :param str y: Response expression</span>

<span class="sd">        :param covariates: list of covariate expressions</span>
<span class="sd">        :type covariates: list of str</span>

<span class="sd">        :param str root: Variant annotation path to store result of linear regression.</span>

<span class="sd">        :param bool use_dosages: If true, use dosage genotypes rather than hard call genotypes.</span>

<span class="sd">        :param int min_ac: Minimum alternate allele count.</span>

<span class="sd">        :param float min_af: Minimum alternate allele frequency.</span>

<span class="sd">        :return: Variant dataset with linear regression variant annotations.</span>
<span class="sd">        :rtype: :py:class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">jvds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvdf</span><span class="o">.</span><span class="n">linreg</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">jarray</span><span class="p">(</span><span class="n">Env</span><span class="o">.</span><span class="n">jvm</span><span class="p">()</span><span class="o">.</span><span class="n">java</span><span class="o">.</span><span class="n">lang</span><span class="o">.</span><span class="n">String</span><span class="p">,</span> <span class="n">covariates</span><span class="p">),</span> <span class="n">root</span><span class="p">,</span> <span class="n">use_dosages</span><span class="p">,</span> <span class="n">min_ac</span><span class="p">,</span> <span class="n">min_af</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">jvds</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
    <span class="nd">@requireTGenotype</span>
<div class="viewcode-block" id="VariantDataset.linreg_multi_pheno"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.linreg_multi_pheno">[docs]</a>    <span class="k">def</span> <span class="nf">linreg_multi_pheno</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">covariates</span><span class="o">=</span><span class="p">[],</span> <span class="n">root</span><span class="o">=</span><span class="s1">&#39;va.linreg&#39;</span><span class="p">,</span> <span class="n">use_dosages</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">min_ac</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">min_af</span><span class="o">=</span><span class="mf">0.0</span><span class="p">):</span>
        <span class="sd">r&quot;&quot;&quot;Test each variant for association with multiple phenotypes using linear regression.</span>

<span class="sd">        This method runs linear regression for multiple phenotypes more efficiently</span>
<span class="sd">        than looping over :py:meth:`.linreg`.</span>

<span class="sd">        .. warning::</span>

<span class="sd">            :py:meth:`.linreg_multi_pheno` uses the same set of samples for each phenotype,</span>
<span class="sd">            namely the set of samples for which **all** phenotypes and covariates are defined.</span>

<span class="sd">        **Annotations**</span>

<span class="sd">        With the default root, the following four variant annotations are added.</span>
<span class="sd">        The indexing of these annotations corresponds to that of ``y``.</span>

<span class="sd">        - **va.linreg.beta** (*Array[Double]*) -- array of fit genotype coefficients, :math:`\hat\beta_1`</span>
<span class="sd">        - **va.linreg.se** (*Array[Double]*) -- array of estimated standard errors, :math:`\widehat{\mathrm{se}}`</span>
<span class="sd">        - **va.linreg.tstat** (*Array[Double]*) -- array of :math:`t`-statistics, equal to :math:`\hat\beta_1 / \widehat{\mathrm{se}}`</span>
<span class="sd">        - **va.linreg.pval** (*Array[Double]*) -- array of :math:`p`-values</span>

<span class="sd">        :param ys: list of one or more response expressions.</span>
<span class="sd">        :type covariates: list of str</span>

<span class="sd">        :param covariates: list of covariate expressions.</span>
<span class="sd">        :type covariates: list of str</span>

<span class="sd">        :param str root: Variant annotation path to store result of linear regression.</span>

<span class="sd">        :param bool use_dosages: If true, use dosage genotypes rather than hard call genotypes.</span>

<span class="sd">        :param int min_ac: Minimum alternate allele count.</span>

<span class="sd">        :param float min_af: Minimum alternate allele frequency.</span>

<span class="sd">        :return: Variant dataset with linear regression variant annotations.</span>
<span class="sd">        :rtype: :py:class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">jvds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvdf</span><span class="o">.</span><span class="n">linregMultiPheno</span><span class="p">(</span><span class="n">jarray</span><span class="p">(</span><span class="n">Env</span><span class="o">.</span><span class="n">jvm</span><span class="p">()</span><span class="o">.</span><span class="n">java</span><span class="o">.</span><span class="n">lang</span><span class="o">.</span><span class="n">String</span><span class="p">,</span> <span class="n">ys</span><span class="p">),</span>
                                           <span class="n">jarray</span><span class="p">(</span><span class="n">Env</span><span class="o">.</span><span class="n">jvm</span><span class="p">()</span><span class="o">.</span><span class="n">java</span><span class="o">.</span><span class="n">lang</span><span class="o">.</span><span class="n">String</span><span class="p">,</span> <span class="n">covariates</span><span class="p">),</span> <span class="n">root</span><span class="p">,</span> <span class="n">use_dosages</span><span class="p">,</span> <span class="n">min_ac</span><span class="p">,</span>
                                           <span class="n">min_af</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">jvds</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
    <span class="nd">@requireTGenotype</span>
<div class="viewcode-block" id="VariantDataset.lmmreg"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.lmmreg">[docs]</a>    <span class="k">def</span> <span class="nf">lmmreg</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">kinshipMatrix</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">covariates</span><span class="o">=</span><span class="p">[],</span> <span class="n">global_root</span><span class="o">=</span><span class="s2">&quot;global.lmmreg&quot;</span><span class="p">,</span> <span class="n">va_root</span><span class="o">=</span><span class="s2">&quot;va.lmmreg&quot;</span><span class="p">,</span>
               <span class="n">run_assoc</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">use_ml</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sparsity_threshold</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Use a kinship-based linear mixed model to estimate the genetic component of phenotypic variance (narrow-sense heritability) and optionally test each variant for association.</span>

<span class="sd">        .. include:: requireTGenotype.rst</span>

<span class="sd">        **Examples**</span>

<span class="sd">        Suppose the variant dataset saved at *data/example_lmmreg.vds* has a Boolean variant annotation ``va.useInKinship`` and numeric or Boolean sample annotations ``sa.pheno``, ``sa.cov1``, ``sa.cov2``. Then the :py:meth:`.lmmreg` function in</span>

<span class="sd">        &gt;&gt;&gt; assoc_vds = hc.read(&quot;data/example_lmmreg.vds&quot;)</span>
<span class="sd">        &gt;&gt;&gt; kinship_matrix = assoc_vds.filter_variants_expr(&#39;va.useInKinship&#39;).rrm()</span>
<span class="sd">        &gt;&gt;&gt; lmm_vds = assoc_vds.lmmreg(kinship_matrix, &#39;sa.pheno&#39;, [&#39;sa.cov1&#39;, &#39;sa.cov2&#39;])</span>

<span class="sd">        will execute the following four steps in order:</span>

<span class="sd">        1) filter to samples in given kinship matrix to those for which ``sa.pheno``, ``sa.cov``, and ``sa.cov2`` are all defined</span>
<span class="sd">        2) compute the eigendecomposition :math:`K = USU^T` of the kinship matrix</span>
<span class="sd">        3) fit covariate coefficients and variance parameters in the sample-covariates-only (global) model using restricted maximum likelihood (`REML &lt;https://en.wikipedia.org/wiki/Restricted_maximum_likelihood&gt;`_), storing results in global annotations under ``global.lmmreg``</span>
<span class="sd">        4) test each variant for association, storing results under ``va.lmmreg`` in variant annotations</span>

<span class="sd">        This plan can be modified as follows:</span>

<span class="sd">        - Set ``run_assoc=False`` to not test any variants for association, i.e. skip Step 5.</span>
<span class="sd">        - Set ``use_ml=True`` to use maximum likelihood instead of REML in Steps 4 and 5.</span>
<span class="sd">        - Set the ``delta`` argument to manually set the value of :math:`\delta` rather that fitting :math:`\delta` in Step 4.</span>
<span class="sd">        - Set the ``global_root`` argument to change the global annotation root in Step 4.</span>
<span class="sd">        - Set the ``va_root`` argument to change the variant annotation root in Step 5.</span>

<span class="sd">        :py:meth:`.lmmreg` adds eight global annotations in Step 4; the last three are omitted if :math:`\delta` is set rather than fit.</span>

<span class="sd">        +------------------------------------+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="sd">        | Annotation                         | Type                 | Value                                                                                                                                                |</span>
<span class="sd">        +====================================+======================+======================================================================================================================================================+</span>
<span class="sd">        | ``global.lmmreg.useML``            | Boolean              | true if fit by ML, false if fit by REML                                                                                                              |</span>
<span class="sd">        +------------------------------------+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="sd">        | ``global.lmmreg.beta``             | Dict[String, Double] | map from *intercept* and the given ``covariates`` expressions to the corresponding fit :math:`\\beta` coefficients                                    |</span>
<span class="sd">        +------------------------------------+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="sd">        | ``global.lmmreg.sigmaG2``          | Double               | fit coefficient of genetic variance, :math:`\\hat{\sigma}_g^2`                                                                                        |</span>
<span class="sd">        +------------------------------------+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="sd">        | ``global.lmmreg.sigmaE2``          | Double               | fit coefficient of environmental variance :math:`\\hat{\sigma}_e^2`                                                                                   |</span>
<span class="sd">        +------------------------------------+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="sd">        | ``global.lmmreg.delta``            | Double               | fit ratio of variance component coefficients, :math:`\\hat{\delta}`                                                                                   |</span>
<span class="sd">        +------------------------------------+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="sd">        | ``global.lmmreg.h2``               | Double               | fit narrow-sense heritability, :math:`\\hat{h}^2`                                                                                                     |</span>
<span class="sd">        +------------------------------------+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="sd">        | ``global.lmmreg.evals``            | Array[Double]        | eigenvalues of the kinship matrix in descending order                                                                                                |</span>
<span class="sd">        +------------------------------------+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="sd">        | ``global.lmmreg.fit.logDeltaGrid`` | Array[Double]        | values of :math:`\\mathit{ln}(\delta)` used in the grid search                                                                                        |</span>
<span class="sd">        +------------------------------------+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="sd">        | ``global.lmmreg.fit.logLkhdVals``  | Array[Double]        | (restricted) log likelihood of :math:`y` given :math:`X` and :math:`\\mathit{ln}(\delta)` at the (RE)ML fit of :math:`\\beta` and :math:`\sigma_g^2`   |</span>
<span class="sd">        +------------------------------------+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="sd">        | ``global.lmmreg.fit.maxLogLkhd``   | Double               | (restricted) maximum log likelihood corresponding to the fit delta                                                                                   |</span>
<span class="sd">        +------------------------------------+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------+</span>

<span class="sd">        These global annotations are also added to ``hail.log``, with the ranked evals and :math:`\delta` grid with values in .tsv tabular form.  Use ``grep &#39;lmmreg:&#39; hail.log`` to find the lines just above each table.</span>

<span class="sd">        If Step 5 is performed, :py:meth:`.lmmreg` also adds four linear regression variant annotations.</span>

<span class="sd">        +------------------------+--------+-------------------------------------------------------------------------+</span>
<span class="sd">        | Annotation             | Type   | Value                                                                   |</span>
<span class="sd">        +========================+========+=========================================================================+</span>
<span class="sd">        | ``va.lmmreg.beta``     | Double | fit genotype coefficient, :math:`\hat\\beta_0`                           |</span>
<span class="sd">        +------------------------+--------+-------------------------------------------------------------------------+</span>
<span class="sd">        | ``va.lmmreg.sigmaG2``  | Double | fit coefficient of genetic variance component, :math:`\hat{\sigma}_g^2` |</span>
<span class="sd">        +------------------------+--------+-------------------------------------------------------------------------+</span>
<span class="sd">        | ``va.lmmreg.chi2``     | Double | :math:`\chi^2` statistic of the likelihood ratio test                   |</span>
<span class="sd">        +------------------------+--------+-------------------------------------------------------------------------+</span>
<span class="sd">        | ``va.lmmreg.pval``     | Double | :math:`p`-value                                                         |</span>
<span class="sd">        +------------------------+--------+-------------------------------------------------------------------------+</span>

<span class="sd">        Those variants that don&#39;t vary across the included samples (e.g., all genotypes are HomRef) will have missing annotations.</span>

<span class="sd">        The simplest way to export all resulting annotations is:</span>

<span class="sd">        &gt;&gt;&gt; lmm_vds.export_variants(&#39;output/lmmreg.tsv.bgz&#39;, &#39;variant = v, va.lmmreg.*&#39;)</span>
<span class="sd">        &gt;&gt;&gt; lmmreg_results = lmm_vds.globals[&#39;lmmreg&#39;]</span>

<span class="sd">        **Performance**</span>

<span class="sd">        Hail&#39;s initial version of :py:meth:`.lmmreg` scales to well beyond 10k samples and to an essentially unbounded number of variants, making it particularly well-suited to modern sequencing studies and complementary to tools designed for SNP arrays. The first analysts to apply :py:meth:`.lmmreg` in research computed kinship from 262k common variants and tested 25 million non-rare variants on 8185 whole genomes in 32 minutes. As another example, starting from a VDS of the 1000 Genomes Project (consisting of 2535 whole genomes), :py:meth:`.lmmreg` computes a kinship matrix based on 100k common variants, fits coefficients and variance components in the sample-covariates-only model, runs a linear-mixed-model likelihood ratio test for all 15 million high-quality non-rare variants, and exports the results in 3m42s minutes. Here we used 42 preemptible workers (~680 cores) on 2k partitions at a compute cost of about 50 cents on Google cloud (see `Using Hail on the Google Cloud Platform &lt;http://discuss.hail.is/t/using-hail-on-the-google-cloud-platform/80&gt;`_).</span>

<span class="sd">        While :py:meth:`.lmmreg` computes the kinship matrix :math:`K` using distributed matrix multiplication (Step 2), the full `eigendecomposition &lt;https://en.wikipedia.org/wiki/Eigendecomposition_of_a_matrix&gt;`_ (Step 3) is currently run on a single core of master using the `LAPACK routine DSYEVD &lt;http://www.netlib.org/lapack/explore-html/d2/d8a/group__double_s_yeigen_ga694ddc6e5527b6223748e3462013d867.html&gt;`_, which we empirically find to be the most performant of the four available routines; laptop performance plots showing cubic complexity in :math:`n` are available `here &lt;https://github.com/hail-is/hail/pull/906&gt;`_. On Google cloud, eigendecomposition takes about 2 seconds for 2535 sampes and 1 minute for 8185 samples. If you see worse performance, check that LAPACK natives are being properly loaded (see &quot;BLAS and LAPACK&quot; in Getting Started).</span>

<span class="sd">        Given the eigendecomposition, fitting the global model (Step 4) takes on the order of a few seconds on master. Association testing (Step 5) is fully distributed by variant with per-variant time complexity that is completely independent of the number of sample covariates and dominated by multiplication of the genotype vector :math:`v` by the matrix of eigenvectors :math:`U^T` as described below, which we accelerate with a sparse representation of :math:`v`.  The matrix :math:`U^T` has size about :math:`8n^2` bytes and is currently broadcast to each Spark executor. For example, with 15k samples, storing :math:`U^T` consumes about 3.6GB of memory on a 16-core worker node with two 8-core executors. So for large :math:`n`, we recommend using a high-memory configuration such as ``highmem`` workers.</span>

<span class="sd">        **Linear mixed model**</span>

<span class="sd">        :py:meth:`.lmmreg` estimates the genetic proportion of residual phenotypic variance (narrow-sense heritability) under a kinship-based linear mixed model, and then optionally tests each variant for association using the likelihood ratio test. Inference is exact.</span>

<span class="sd">        We first describe the sample-covariates-only model used to estimate heritability, which we simply refer to as the *global model*. With :math:`n` samples and :math:`c` sample covariates, we define:</span>

<span class="sd">        - :math:`y = n \\times 1` vector of phenotypes</span>
<span class="sd">        - :math:`X = n \\times c` matrix of sample covariates and intercept column of ones</span>
<span class="sd">        - :math:`K = n \\times n` kinship matrix</span>
<span class="sd">        - :math:`I = n \\times n` identity matrix</span>
<span class="sd">        - :math:`\\beta = c \\times 1` vector of covariate coefficients</span>
<span class="sd">        - :math:`\sigma_g^2 =` coefficient of genetic variance component :math:`K`</span>
<span class="sd">        - :math:`\sigma_e^2 =` coefficient of environmental variance component :math:`I`</span>
<span class="sd">        - :math:`\delta = \\frac{\sigma_e^2}{\sigma_g^2} =` ratio of environmental and genetic variance component coefficients</span>
<span class="sd">        - :math:`h^2 = \\frac{\sigma_g^2}{\sigma_g^2 + \sigma_e^2} = \\frac{1}{1 + \delta} =` genetic proportion of residual phenotypic variance</span>

<span class="sd">        Under a linear mixed model, :math:`y` is sampled from the :math:`n`-dimensional `multivariate normal distribution &lt;https://en.wikipedia.org/wiki/Multivariate_normal_distribution&gt;`_ with mean :math:`X \\beta` and variance components that are scalar multiples of :math:`K` and :math:`I`:</span>

<span class="sd">        .. math::</span>

<span class="sd">          y \sim \mathrm{N}\\left(X\\beta, \sigma_g^2 K + \sigma_e^2 I\\right)</span>

<span class="sd">        Thus the model posits that the residuals :math:`y_i - X_{i,:}\\beta` and :math:`y_j - X_{j,:}\\beta` have covariance :math:`\sigma_g^2 K_{ij}` and approximate correlation :math:`h^2 K_{ij}`. Informally: phenotype residuals are correlated as the product of overall heritability and pairwise kinship. By contrast, standard (unmixed) linear regression is equivalent to fixing :math:`\sigma_2` (equivalently, :math:`h^2`) at 0 above, so that all phenotype residuals are independent.</span>

<span class="sd">        **Caution:** while it is tempting to interpret :math:`h^2` as the `narrow-sense heritability &lt;https://en.wikipedia.org/wiki/Heritability#Definition&gt;`_ of the phenotype alone, note that its value depends not only the phenotype and genetic data, but also on the choice of sample covariates.</span>

<span class="sd">        **Fitting the global model**</span>

<span class="sd">        The core algorithm is essentially a distributed implementation of the spectral approach taken in `FastLMM &lt;https://www.microsoft.com/en-us/research/project/fastlmm/&gt;`_. Let :math:`K = USU^T` be the `eigendecomposition &lt;https://en.wikipedia.org/wiki/Eigendecomposition_of_a_matrix#Real_symmetric_matrices&gt;`_ of the real symmetric matrix :math:`K`. That is:</span>

<span class="sd">        - :math:`U = n \\times n` orthonormal matrix whose columns are the eigenvectors of :math:`K`</span>
<span class="sd">        - :math:`S = n \\times n` diagonal matrix of eigenvalues of :math:`K` in descending order. :math:`S_{ii}` is the eigenvalue of eigenvector :math:`U_{:,i}`</span>
<span class="sd">        - :math:`U^T = n \\times n` orthonormal matrix, the transpose (and inverse) of :math:`U`</span>

<span class="sd">        A bit of matrix algebra on the multivariate normal density shows that the linear mixed model above is mathematically equivalent to the model</span>

<span class="sd">        .. math::</span>

<span class="sd">          U^Ty \\sim \mathrm{N}\\left(U^TX\\beta, \sigma_g^2 (S + \delta I)\\right)</span>

<span class="sd">        for which the covariance is diagonal (e.g., unmixed). That is, rotating the phenotype vector (:math:`y`) and covariate vectors (columns of :math:`X`) in :math:`\mathbb{R}^n` by :math:`U^T` transforms the model to one with independent residuals. For any particular value of :math:`\delta`, the restricted maximum likelihood (REML) solution for the latter model can be solved exactly in time complexity that is linear rather than cubic in :math:`n`.  In particular, having rotated, we can run a very efficient 1-dimensional optimization procedure over :math:`\delta` to find the REML estimate :math:`(\hat{\delta}, \\hat{\\beta}, \\hat{\sigma}_g^2)` of the triple :math:`(\delta, \\beta, \sigma_g^2)`, which in turn determines :math:`\\hat{\sigma}_e^2` and :math:`\\hat{h}^2`.</span>

<span class="sd">        We first compute the maximum log likelihood on a :math:`\delta`-grid that is uniform on the log scale, with :math:`\\mathit{ln}(\delta)` running from -10 to 10 by 0.01, corresponding to :math:`h^2` decreasing from 0.999999998 to 0.000000002. If :math:`h^2` is maximized at the lower boundary then standard linear regression would be more appropriate and Hail will exit; more generally, consider using standard linear regression when :math:`\\hat{h}^2` is very small. A maximum at the upper boundary is highly suspicious and will also cause Hail to exit, with the ``hail.log`` recording all values over the grid for further inspection.</span>

<span class="sd">        If the optimal grid point falls in the interior of the grid as expected, we then use `Brent&#39;s method &lt;https://en.wikipedia.org/wiki/Brent%27s_method&gt;`_ to find the precise location of the maximum over the same range, with initial guess given by the optimal grid point and a tolerance on :math:`\\mathit{ln}(\delta)` of 1e-6. If this location differs from the optimal grid point by more than .01, a warning will be displayed and logged, and one would be wise to investigate by plotting the values over the grid. Note that :math:`h^2` is related to :math:`\\mathit{ln}(\delta)` through the `sigmoid function &lt;https://en.wikipedia.org/wiki/Sigmoid_function&gt;`_. Hence one can change variables to extract a high-resolution discretization of the likelihood function of :math:`h^2` over :math:`[0,1]` at the corresponding REML estimators for :math:`\\beta` and :math:`\sigma_g^2`.</span>

<span class="sd">        **Testing each variant for association**</span>

<span class="sd">        Fixing a single variant, we define:</span>

<span class="sd">        - :math:`v = n \\times 1` vector of genotypes, with missing genotypes imputed as the mean of called genotypes</span>
<span class="sd">        - :math:`X_v = \\left[v | X \\right] = n \\times (1 + c)` matrix concatenating :math:`v` and :math:`X`</span>
<span class="sd">        - :math:`\\beta_v = (\\beta^0_v, \\beta^1_v, \\ldots, \\beta^c_v) = (1 + c) \\times 1` vector of covariate coefficients</span>

<span class="sd">        Fixing :math:`\delta` at the global REML estimate :math:`\\hat{\delta}`, we find the REML estimate :math:`(\\hat{\\beta}_v, \\hat{\sigma}_{g,v}^2)` via rotation of the model</span>

<span class="sd">        .. math::</span>

<span class="sd">          y \\sim \\mathrm{N}\\left(X_v\\beta_v, \sigma_{g,v}^2 (K + \\hat{\delta} I)\\right)</span>

<span class="sd">        Note that the only new rotation to compute here is :math:`U^T v`.</span>

<span class="sd">        To test the null hypothesis that the genotype coefficient :math:`\\beta^0_v` is zero, we consider the restricted model with parameters :math:`((0, \\beta^1_v, \ldots, \\beta^c_v), \sigma_{g,v}^2)` within the full model with parameters :math:`(\\beta^0_v, \\beta^1_v, \\ldots, \\beta^c_v), \sigma_{g_v}^2)`, with :math:`\delta` fixed at :math:`\\hat\delta` in both. The latter fit is simply that of the global model, :math:`((0, \\hat{\\beta}^1, \\ldots, \\hat{\\beta}^c), \\hat{\sigma}_g^2)`. The likelihood ratio test statistic is given by</span>

<span class="sd">        .. math::</span>

<span class="sd">          \chi^2 = n \\, \\mathit{ln}\left(\\frac{\hat{\sigma}^2_g}{\\hat{\sigma}_{g,v}^2}\\right)</span>

<span class="sd">        and follows a chi-squared distribution with one degree of freedom. Here the ratio :math:`\\hat{\sigma}^2_g / \\hat{\sigma}_{g,v}^2` captures the degree to which adding the variant :math:`v` to the global model reduces the residual phenotypic variance.</span>

<span class="sd">        **Kinship Matrix**</span>

<span class="sd">        FastLMM uses the Realized Relationship Matrix (RRM) for kinship. This can be computed with :py:meth:`~hail.VariantDataset.rrm`. However, any instance of :py:class:`KinshipMatrix` may be used, so long as ``sample_list`` contains the complete samples of the caller variant dataset in the same order.</span>

<span class="sd">        **Further background**</span>

<span class="sd">        For the history and mathematics of linear mixed models in genetics, including `FastLMM &lt;https://www.microsoft.com/en-us/research/project/fastlmm/&gt;`_, see `Christoph Lippert&#39;s PhD thesis &lt;https://publikationen.uni-tuebingen.de/xmlui/bitstream/handle/10900/50003/pdf/thesis_komplett.pdf&gt;`_. For an investigation of various approaches to defining kinship, see `Comparison of Methods to Account for Relatedness in Genome-Wide Association Studies with Family-Based Data &lt;http://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1004445&gt;`_.</span>

<span class="sd">        :param kinshipMatrix: Kinship matrix to be used.</span>
<span class="sd">        :type kinshipMatrix: :class:`KinshipMatrix`</span>

<span class="sd">        :param str y: Response sample annotation.</span>

<span class="sd">        :param covariates: List of covariate sample annotations.</span>
<span class="sd">        :type covariates: list of str</span>

<span class="sd">        :param str global_root: Global annotation root, a period-delimited path starting with `global`.</span>

<span class="sd">        :param str va_root: Variant annotation root, a period-delimited path starting with `va`.</span>

<span class="sd">        :param bool run_assoc: If True, run association testing in addition to fitting the global model.</span>

<span class="sd">        :param bool use_ml: Use ML instead of REML throughout.</span>

<span class="sd">        :param delta: Fixed delta value to use in the global model, overrides fitting delta.</span>
<span class="sd">        :type delta: float or None</span>

<span class="sd">        :param float sparsity_threshold: AF threshold above which to use dense genotype vectors in rotation (advanced).</span>

<span class="sd">        :return: Variant dataset with linear mixed regression annotations.</span>
<span class="sd">        :rtype: :py:class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">jvds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvdf</span><span class="o">.</span><span class="n">lmmreg</span><span class="p">(</span><span class="n">kinshipMatrix</span><span class="o">.</span><span class="n">_jkm</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">jarray</span><span class="p">(</span><span class="n">Env</span><span class="o">.</span><span class="n">jvm</span><span class="p">()</span><span class="o">.</span><span class="n">java</span><span class="o">.</span><span class="n">lang</span><span class="o">.</span><span class="n">String</span><span class="p">,</span> <span class="n">covariates</span><span class="p">),</span>
                                 <span class="n">use_ml</span><span class="p">,</span> <span class="n">global_root</span><span class="p">,</span> <span class="n">va_root</span><span class="p">,</span> <span class="n">run_assoc</span><span class="p">,</span>
                                 <span class="n">joption</span><span class="p">(</span><span class="n">delta</span><span class="p">),</span> <span class="n">sparsity_threshold</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">jvds</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
    <span class="nd">@requireTGenotype</span>
<div class="viewcode-block" id="VariantDataset.logreg"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.logreg">[docs]</a>    <span class="k">def</span> <span class="nf">logreg</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">covariates</span><span class="o">=</span><span class="p">[],</span> <span class="n">root</span><span class="o">=</span><span class="s1">&#39;va.logreg&#39;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Test each variant for association using logistic regression.</span>

<span class="sd">        .. include:: requireTGenotype.rst</span>

<span class="sd">        **Examples**</span>

<span class="sd">        Run the logistic regression Wald test per variant using a phenotype and two covariates stored in sample annotations:</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds.logreg(&#39;wald&#39;, &#39;sa.pheno.isCase&#39;, covariates=[&#39;sa.pheno.age&#39;, &#39;sa.pheno.isFemale&#39;])</span>

<span class="sd">        **Notes**</span>

<span class="sd">        The :py:meth:`~hail.VariantDataset.logreg` command performs,</span>
<span class="sd">        for each variant, a significance test of the genotype in</span>
<span class="sd">        predicting a binary (case-control) phenotype based on the</span>
<span class="sd">        logistic regression model. Hail supports the Wald test (&#39;wald&#39;),</span>
<span class="sd">        likelihood ratio test (&#39;lrt&#39;), Rao score test (&#39;score&#39;), and Firth test (&#39;firth&#39;). Hail only</span>
<span class="sd">        includes samples for which the phenotype and all covariates are</span>
<span class="sd">        defined. For each variant, Hail imputes missing genotypes as</span>
<span class="sd">        the mean of called genotypes.</span>

<span class="sd">        The example above considers a model of the form</span>

<span class="sd">        .. math::</span>

<span class="sd">          \mathrm{Prob}(\mathrm{isCase}) = \mathrm{sigmoid}(\\beta_0 + \\beta_1 \, \mathrm{gt} + \\beta_2 \, \mathrm{age} + \\beta_3 \, \mathrm{isFemale} + \\varepsilon), \quad \\varepsilon \sim \mathrm{N}(0, \sigma^2)</span>

<span class="sd">        where :math:`\mathrm{sigmoid}` is the `sigmoid</span>
<span class="sd">        function &lt;https://en.wikipedia.org/wiki/Sigmoid_function&gt;`_, the</span>
<span class="sd">        genotype :math:`\mathrm{gt}` is coded as 0 for HomRef, 1 for</span>
<span class="sd">        Het, and 2 for HomVar, and the Boolean covariate</span>
<span class="sd">        :math:`\mathrm{isFemale}` is coded as 1 for true (female) and</span>
<span class="sd">        0 for false (male). The null model sets :math:`\\beta_1 = 0`.</span>

<span class="sd">        The resulting variant annotations depend on the test statistic</span>
<span class="sd">        as shown in the tables below.</span>

<span class="sd">        ========== =================== ====== =====</span>
<span class="sd">        Test       Annotation          Type   Value</span>
<span class="sd">        ========== =================== ====== =====</span>
<span class="sd">        Wald       ``va.logreg.beta``  Double fit genotype coefficient, :math:`\hat\\beta_1`</span>
<span class="sd">        Wald       ``va.logreg.se``    Double estimated standard error, :math:`\widehat{\mathrm{se}}`</span>
<span class="sd">        Wald       ``va.logreg.zstat`` Double Wald :math:`z`-statistic, equal to :math:`\hat\\beta_1 / \widehat{\mathrm{se}}`</span>
<span class="sd">        Wald       ``va.logreg.pval``  Double Wald p-value testing :math:`\\beta_1 = 0`</span>
<span class="sd">        LRT, Firth ``va.logreg.beta``  Double fit genotype coefficient, :math:`\hat\\beta_1`</span>
<span class="sd">        LRT, Firth ``va.logreg.chi2``  Double deviance statistic</span>
<span class="sd">        LRT, Firth ``va.logreg.pval``  Double LRT / Firth p-value testing :math:`\\beta_1 = 0`</span>
<span class="sd">        Score      ``va.logreg.chi2``  Double score statistic</span>
<span class="sd">        Score      ``va.logreg.pval``  Double score p-value testing :math:`\\beta_1 = 0`</span>
<span class="sd">        ========== =================== ====== =====</span>

<span class="sd">        For the Wald and likelihood ratio tests, Hail fits the logistic model for each variant using Newton iteration and only emits the above annotations when the maximum likelihood estimate of the coefficients converges. The Firth test uses a modified form of Newton iteration. To help diagnose convergence issues, Hail also emits three variant annotations which summarize the iterative fitting process:</span>

<span class="sd">        ================ =========================== ======= =====</span>
<span class="sd">        Test             Annotation                  Type    Value</span>
<span class="sd">        ================ =========================== ======= =====</span>
<span class="sd">        Wald, LRT, Firth ``va.logreg.fit.nIter``     Int     number of iterations until convergence, explosion, or reaching the max (25 for Wald, LRT; 100 for Firth)</span>
<span class="sd">        Wald, LRT, Firth ``va.logreg.fit.converged`` Boolean true if iteration converged</span>
<span class="sd">        Wald, LRT, Firth ``va.logreg.fit.exploded``  Boolean true if iteration exploded</span>
<span class="sd">        ================ =========================== ======= =====</span>

<span class="sd">        We consider iteration to have converged when every coordinate of :math:`\\beta` changes by less than :math:`10^{-6}`. For Wald and LRT, up to 25 iterations are attempted; in testing we find 4 or 5 iterations nearly always suffice. Convergence may also fail due to explosion, which refers to low-level numerical linear algebra exceptions caused by manipulating ill-conditioned matrices. Explosion may result from (nearly) linearly dependent covariates or complete `separation &lt;https://en.wikipedia.org/wiki/Separation_(statistics)&gt;`_.</span>

<span class="sd">        A more common situation in genetics is quasi-complete seperation, e.g. variants that are observed only in cases (or controls). Such variants inevitably arise when testing millions of variants with very low minor allele count. The maximum likelihood estimate of :math:`\\beta` under logistic regression is then undefined but convergence may still occur after a large number of iterations due to a very flat likelihood surface. In testing, we find that such variants produce a secondary bump from 10 to 15 iterations in the histogram of number of iterations per variant. We also find that this faux convergence produces large standard errors and large (insignificant) p-values. To not miss such variants, consider using Firth logistic regression, linear regression, or group-based tests.</span>

<span class="sd">        Here&#39;s a concrete illustration of quasi-complete seperation in R. Suppose we have 2010 samples distributed as follows for a particular variant:</span>

<span class="sd">        ======= ====== === ======</span>
<span class="sd">        Status  HomRef Het HomVar</span>
<span class="sd">        ======= ====== === ======</span>
<span class="sd">        Case    1000   10  0</span>
<span class="sd">        Control 1000   0   0</span>
<span class="sd">        ======= ====== === ======</span>

<span class="sd">        The following R code fits the (standard) logistic, Firth logistic, and linear regression models to this data, where ``x`` is genotype, ``y`` is phenotype, and ``logistf`` is from the logistf package:</span>

<span class="sd">        .. code-block:: R</span>

<span class="sd">            x &lt;- c(rep(0,1000), rep(1,1000), rep(1,10)</span>
<span class="sd">            y &lt;- c(rep(0,1000), rep(0,1000), rep(1,10))</span>
<span class="sd">            logfit &lt;- glm(y ~ x, family=binomial())</span>
<span class="sd">            firthfit &lt;- logistf(y ~ x)</span>
<span class="sd">            linfit &lt;- lm(y ~ x)</span>

<span class="sd">        The resulting p-values for the genotype coefficient are 0.991, 0.00085, and 0.0016, respectively. The erroneous value 0.991 is due to quasi-complete separation. Moving one of the 10 hets from case to control eliminates this quasi-complete separation; the p-values from R are then 0.0373, 0.0111, and 0.0116, respectively, as expected for a less significant association.</span>

<span class="sd">        The Firth test reduces bias from small counts and resolves the issue of separation by penalizing maximum likelihood estimation by the `Jeffrey&#39;s invariant prior &lt;https://en.wikipedia.org/wiki/Jeffreys_prior&gt;`_. This test is slower, as both the null and full model must be fit per variant, and convergence of the modified Newton method is linear rather than quadratic. For Firth, 100 iterations are attempted for the null model and, if that is successful, for the full model as well. In testing we find 20 iterations nearly always suffices. If the null model fails to converge, then the ``sa.lmmreg.fit`` annotations reflect the null model; otherwise, they reflect the full model.</span>

<span class="sd">        See `Recommended joint and meta-analysis strategies for case-control association testing of single low-count variants &lt;http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4049324/&gt;`_ for an empirical comparison of the logistic Wald, LRT, score, and Firth tests. The theoretical foundations of the Wald, likelihood ratio, and score tests may be found in Chapter 3 of Gesine Reinert&#39;s notes `Statistical Theory &lt;http://www.stats.ox.ac.uk/~reinert/stattheory/theoryshort09.pdf&gt;`_.  Firth introduced his approach in `Bias reduction of maximum likelihood estimates, 1993 &lt;http://www2.stat.duke.edu/~scs/Courses/Stat376/Papers/GibbsFieldEst/BiasReductionMLE.pdf&gt;`_. Heinze and Schemper further analyze Firth&#39;s approach in `A solution to the problem of separation in logistic regression, 2002 &lt;https://cemsiis.meduniwien.ac.at/fileadmin/msi_akim/CeMSIIS/KB/volltexte/Heinze_Schemper_2002_Statistics_in_Medicine.pdf&gt;`_.</span>

<span class="sd">        Phenotype and covariate sample annotations may also be specified using `programmatic expressions &lt;exprlang.html&gt;`_ without identifiers, such as:</span>

<span class="sd">        .. code-block:: text</span>

<span class="sd">            if (sa.isFemale) sa.cov.age else (2 * sa.cov.age + 10)</span>

<span class="sd">        For Boolean covariate types, true is coded as 1 and false as 0. In particular, for the sample annotation ``sa.fam.isCase`` added by importing a FAM file with case-control phenotype, case is 1 and control is 0.</span>

<span class="sd">        Hail&#39;s logistic regression tests correspond to the ``b.wald``, ``b.lrt``, and ``b.score`` tests in `EPACTS &lt;http://genome.sph.umich.edu/wiki/EPACTS#Single_Variant_Tests&gt;`_. For each variant, Hail imputes missing genotypes as the mean of called genotypes, whereas EPACTS subsets to those samples with called genotypes. Hence, Hail and EPACTS results will currently only agree for variants with no missing genotypes.</span>

<span class="sd">        :param str test: Statistical test, one of: &#39;wald&#39;, &#39;lrt&#39;, &#39;score&#39;, or &#39;firth&#39;.</span>

<span class="sd">        :param str y: Response expression.  Must evaluate to Boolean or</span>
<span class="sd">            numeric with all values 0 or 1.</span>

<span class="sd">        :param covariates: list of covariate expressions</span>
<span class="sd">        :type covariates: list of str</span>

<span class="sd">        :param str root: Variant annotation path to store result of linear regression.</span>

<span class="sd">        :return: Variant dataset with logistic regression variant annotations.</span>
<span class="sd">        :rtype: :py:class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">jvds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvdf</span><span class="o">.</span><span class="n">logreg</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">jarray</span><span class="p">(</span><span class="n">Env</span><span class="o">.</span><span class="n">jvm</span><span class="p">()</span><span class="o">.</span><span class="n">java</span><span class="o">.</span><span class="n">lang</span><span class="o">.</span><span class="n">String</span><span class="p">,</span> <span class="n">covariates</span><span class="p">),</span> <span class="n">root</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">jvds</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
    <span class="nd">@requireTGenotype</span>
<div class="viewcode-block" id="VariantDataset.mendel_errors"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.mendel_errors">[docs]</a>    <span class="k">def</span> <span class="nf">mendel_errors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">fam</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Find Mendel errors; count per variant, individual and nuclear</span>
<span class="sd">        family.</span>

<span class="sd">        .. include:: requireTGenotype.rst</span>

<span class="sd">        **Examples**</span>

<span class="sd">        Find all violations of Mendelian inheritance in each (dad,</span>
<span class="sd">        mom, kid) trio in *trios.fam* and save results to files with root ``mydata``:</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds.mendel_errors(&#39;output/genomes&#39;, &#39;data/trios.fam&#39;)</span>

<span class="sd">        **Notes**</span>

<span class="sd">        The code above outputs four TSV files according to the `PLINK mendel</span>
<span class="sd">        formats &lt;https://www.cog-genomics.org/plink2/formats#mendel&gt;`_:</span>

<span class="sd">        - ``mydata.mendel`` -- all mendel errors: FID KID CHR SNP CODE ERROR</span>
<span class="sd">        - ``mydata.fmendel`` -- error count per nuclear family: FID PAT MAT CHLD N NSNP</span>
<span class="sd">        - ``mydata.imendel`` -- error count per individual: FID IID N NSNP</span>
<span class="sd">        - ``mydata.lmendel`` -- error count per variant: CHR SNP N</span>

<span class="sd">        **FID**, **KID**, **PAT**, **MAT**, and **IID** refer to family, kid,</span>
<span class="sd">        dad, mom, and individual ID, respectively, with missing values set to</span>
<span class="sd">        ``0``.</span>

<span class="sd">        SNP denotes the variant identifier ``chr:pos:ref:alt``.</span>

<span class="sd">        N counts all errors, while NSNP only counts SNP errors (NSNP is not in Plink).</span>

<span class="sd">        CHLD is the number of children in a nuclear family.</span>

<span class="sd">        The CODE of each Mendel error is determined by the table below,</span>
<span class="sd">        extending the `Plink</span>
<span class="sd">        classification &lt;https://www.cog-genomics.org/plink2/basic_stats#mendel&gt;`_.</span>

<span class="sd">        Those individuals implicated by each code are in bold.</span>

<span class="sd">        The copy state of a locus with respect to a trio is defined as follows,</span>
<span class="sd">        where PAR is the `pseudoautosomal region &lt;https://en.wikipedia.org/wiki/Pseudoautosomal_region&gt;`_ (PAR).</span>

<span class="sd">        - HemiX -- in non-PAR of X, male child</span>
<span class="sd">        - HemiY -- in non-PAR of Y, male child</span>
<span class="sd">        - Auto -- otherwise (in autosome or PAR, or female child)</span>

<span class="sd">        Any refers to :math:`\{ HomRef, Het, HomVar, NoCall \}` and ! denotes complement in this set.</span>

<span class="sd">        +--------+------------+------------+----------+------------------+</span>
<span class="sd">        |Code    | Dad        | Mom        |     Kid  |   Copy State     |</span>
<span class="sd">        +========+============+============+==========+==================+</span>
<span class="sd">        |    1   | HomVar     | HomVar     | Het      | Auto             |</span>
<span class="sd">        +--------+------------+------------+----------+------------------+</span>
<span class="sd">        |    2   | HomRef     | HomRef     | Het      | Auto             |</span>
<span class="sd">        +--------+------------+------------+----------+------------------+</span>
<span class="sd">        |    3   | HomRef     |  ! HomRef  |  HomVar  | Auto             |</span>
<span class="sd">        +--------+------------+------------+----------+------------------+</span>
<span class="sd">        |    4   |  ! HomRef  | HomRef     |  HomVar  | Auto             |</span>
<span class="sd">        +--------+------------+------------+----------+------------------+</span>
<span class="sd">        |    5   | HomRef     | HomRef     |  HomVar  | Auto             |</span>
<span class="sd">        +--------+------------+------------+----------+------------------+</span>
<span class="sd">        |    6   | HomVar     |  ! HomVar  |  HomRef  | Auto             |</span>
<span class="sd">        +--------+------------+------------+----------+------------------+</span>
<span class="sd">        |    7   |  ! HomVar  | HomVar     |  HomRef  | Auto             |</span>
<span class="sd">        +--------+------------+------------+----------+------------------+</span>
<span class="sd">        |    8   | HomVar     | HomVar     |  HomRef  | Auto             |</span>
<span class="sd">        +--------+------------+------------+----------+------------------+</span>
<span class="sd">        |    9   | Any        | HomVar     |  HomRef  | HemiX            |</span>
<span class="sd">        +--------+------------+------------+----------+------------------+</span>
<span class="sd">        |   10   | Any        | HomRef     |  HomVar  | HemiX            |</span>
<span class="sd">        +--------+------------+------------+----------+------------------+</span>
<span class="sd">        |   11   | HomVar     | Any        |  HomRef  | HemiY            |</span>
<span class="sd">        +--------+------------+------------+----------+------------------+</span>
<span class="sd">        |   12   | HomRef     | Any        |  HomVar  | HemiY            |</span>
<span class="sd">        +--------+------------+------------+----------+------------------+</span>

<span class="sd">        This method only considers children with two parents and a defined sex.</span>

<span class="sd">        PAR is currently defined with respect to reference</span>
<span class="sd">        `GRCh37 &lt;http://www.ncbi.nlm.nih.gov/projects/genome/assembly/grc/human/&gt;`_:</span>

<span class="sd">        - X: 60001 - 2699520, 154931044 - 155260560</span>
<span class="sd">        - Y: 10001 - 2649520, 59034050 - 59363566</span>

<span class="sd">        This method assumes all contigs apart from X and Y are fully autosomal;</span>
<span class="sd">        mitochondria, decoys, etc. are not given special treatment.</span>

<span class="sd">        :param str output: Output root filename.</span>

<span class="sd">        :param str fam: Path to .fam file.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_jvdf</span><span class="o">.</span><span class="n">mendelErrors</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">fam</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.min_rep"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.min_rep">[docs]</a>    <span class="k">def</span> <span class="nf">min_rep</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_shift</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gives minimal, left-aligned representation of alleles. Note that this can change the variant position.</span>

<span class="sd">        **Examples**</span>

<span class="sd">        1. Simple trimming of a multi-allelic site, no change in variant position</span>
<span class="sd">        `1:10000:TAA:TAA,AA` =&gt; `1:10000:TA:T,A`</span>

<span class="sd">        2. Trimming of a bi-allelic site leading to a change in position</span>
<span class="sd">        `1:10000:AATAA,AAGAA` =&gt; `1:10002:T:G`</span>

<span class="sd">        :param int max_shift: maximum number of base pairs by which</span>
<span class="sd">          a split variant can move.  Affects memory usage, and will</span>
<span class="sd">          cause Hail to throw an error if a variant that moves further</span>
<span class="sd">          is encountered.</span>

<span class="sd">        :rtype: :class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">jvds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">minRep</span><span class="p">(</span><span class="n">max_shift</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">jvds</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
    <span class="nd">@requireTGenotype</span>
<div class="viewcode-block" id="VariantDataset.pca"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.pca">[docs]</a>    <span class="k">def</span> <span class="nf">pca</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">loadings</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">eigenvalues</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">as_array</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Run Principal Component Analysis (PCA) on the matrix of genotypes.</span>

<span class="sd">        .. include:: requireTGenotype.rst</span>

<span class="sd">        **Examples**</span>

<span class="sd">        Compute the top 10 principal component scores, stored as sample annotations ``sa.scores.PC1``, ..., ``sa.scores.PC10`` of type Double:</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds.pca(&#39;sa.scores&#39;)</span>

<span class="sd">        Compute the top 5 principal component scores, loadings, and eigenvalues, stored as annotations ``sa.scores``, ``va.loadings``, and ``global.evals`` of type Array[Double]:</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds.pca(&#39;sa.scores&#39;, &#39;va.loadings&#39;, &#39;global.evals&#39;, 5, as_array=True)</span>

<span class="sd">        **Notes**</span>

<span class="sd">        Hail supports principal component analysis (PCA) of genotype data, a now-standard procedure `Patterson, Price and Reich, 2006 &lt;http://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.0020190&gt;`_. This method expects a variant dataset with biallelic autosomal variants. Scores are computed and stored as sample annotations of type Struct by default; variant loadings and eigenvalues can optionally be computed and stored in variant and global annotations, respectively.</span>

<span class="sd">        PCA is based on the singular value decomposition (SVD) of a standardized genotype matrix :math:`M`, computed as follows. An :math:`n \\times m` matrix :math:`C` records raw genotypes, with rows indexed by :math:`n` samples and columns indexed by :math:`m` bialellic autosomal variants; :math:`C_{ij}` is the number of alternate alleles of variant :math:`j` carried by sample :math:`i`, which can be 0, 1, 2, or missing. For each variant :math:`j`, the sample alternate allele frequency :math:`p_j` is computed as half the mean of the non-missing entries of column :math:`j`. Entries of :math:`M` are then mean-centered and variance-normalized as</span>

<span class="sd">        .. math::</span>

<span class="sd">          M_{ij} = \\frac{C_{ij}-2p_j}{\sqrt{2p_j(1-p_j)m}},</span>

<span class="sd">        with :math:`M_{ij} = 0` for :math:`C_{ij}` missing (i.e. mean genotype imputation). This scaling normalizes genotype variances to a common value :math:`1/m` for variants in Hardy-Weinberg equilibrium and is further motivated in the paper cited above. (The resulting amplification of signal from the low end of the allele frequency spectrum will also introduce noise for rare variants; common practice is to filter out variants with minor allele frequency below some cutoff.)  The factor :math:`1/m` gives each sample row approximately unit total variance (assuming linkage equilibrium) and yields the sample correlation or genetic relationship matrix (GRM) as simply :math:`MM^T`.</span>

<span class="sd">        PCA then computes the SVD</span>

<span class="sd">        .. math::</span>

<span class="sd">          M = USV^T</span>

<span class="sd">        where columns of :math:`U` are left singular vectors (orthonormal in :math:`\mathbb{R}^n`), columns of :math:`V` are right singular vectors (orthonormal in :math:`\mathbb{R}^m`), and :math:`S=\mathrm{diag}(s_1, s_2, \ldots)` with ordered singular values :math:`s_1 \ge s_2 \ge \cdots \ge 0`. Typically one computes only the first :math:`k` singular vectors and values, yielding the best rank :math:`k` approximation :math:`U_k S_k V_k^T` of :math:`M`; the truncations :math:`U_k`, :math:`S_k` and :math:`V_k` are :math:`n \\times k`, :math:`k \\times k` and :math:`m \\times k` respectively.</span>

<span class="sd">        From the perspective of the samples or rows of :math:`M` as data, :math:`V_k` contains the variant loadings for the first :math:`k` PCs while :math:`MV_k = U_k S_k` contains the first :math:`k` PC scores of each sample. The loadings represent a new basis of features while the scores represent the projected data on those features. The eigenvalues of the GRM :math:`MM^T` are the squares of the singular values :math:`s_1^2, s_2^2, \ldots`, which represent the variances carried by the respective PCs. By default, Hail only computes the loadings if the ``loadings`` parameter is specified.</span>

<span class="sd">        *Note:* In PLINK/GCTA the GRM is taken as the starting point and it is computed slightly differently with regard to missing data. Here the :math:`ij` entry of :math:`MM^T` is simply the dot product of rows :math:`i` and :math:`j` of :math:`M`; in terms of :math:`C` it is</span>

<span class="sd">        .. math::</span>

<span class="sd">          \\frac{1}{m}\sum_{l\in\mathcal{C}_i\cap\mathcal{C}_j}\\frac{(C_{il}-2p_l)(C_{jl} - 2p_l)}{2p_l(1-p_l)}</span>

<span class="sd">        where :math:`\mathcal{C}_i = \{l \mid C_{il} \\text{ is non-missing}\}`. In PLINK/GCTA the denominator :math:`m` is replaced with the number of terms in the sum :math:`\\lvert\mathcal{C}_i\cap\\mathcal{C}_j\\rvert`, i.e. the number of variants where both samples have non-missing genotypes. While this is arguably a better estimator of the true GRM (trading shrinkage for noise), it has the drawback that one loses the clean interpretation of the loadings and scores as features and projections.</span>

<span class="sd">        Separately, for the PCs PLINK/GCTA output the eigenvectors of the GRM; even ignoring the above discrepancy that means the left singular vectors :math:`U_k` instead of the component scores :math:`U_k S_k`. While this is just a matter of the scale on each PC, the scores have the advantage of representing true projections of the data onto features with the variance of a score reflecting the variance explained by the corresponding feature. (In PC bi-plots this amounts to a change in aspect ratio; for use of PCs as covariates in regression it is immaterial.)</span>

<span class="sd">        **Annotations**</span>

<span class="sd">        Given root ``scores=&#39;sa.scores&#39;`` and ``as_array=False``, :py:meth:`~hail.VariantDataset.pca` adds a Struct to sample annotations:</span>

<span class="sd">         - **sa.scores** (*Struct*) -- Struct of sample scores</span>

<span class="sd">        With ``k=3``, the Struct has three field:</span>

<span class="sd">         - **sa.scores.PC1** (*Double*) -- Score from first PC</span>

<span class="sd">         - **sa.scores.PC2** (*Double*) -- Score from second PC</span>

<span class="sd">         - **sa.scores.PC3** (*Double*) -- Score from third PC</span>

<span class="sd">        Analogous variant and global annotations of type Struct are added by specifying the ``loadings`` and ``eigenvalues`` arguments, respectively.</span>

<span class="sd">        Given roots ``scores=&#39;sa.scores&#39;``, ``loadings=&#39;va.loadings&#39;``, and ``eigenvalues=&#39;global.evals&#39;``, and ``as_array=True``, :py:meth:`~hail.VariantDataset.pca` adds the following annotations:</span>

<span class="sd">         - **sa.scores** (*Array[Double]*) -- Array of sample scores from the top k PCs</span>

<span class="sd">         - **va.loadings** (*Array[Double]*) -- Array of variant loadings in the top k PCs</span>

<span class="sd">         - **global.evals** (*Array[Double]*) -- Array of the top k eigenvalues</span>

<span class="sd">        :param str scores: Sample annotation path to store scores.</span>

<span class="sd">        :param loadings: Variant annotation path to store site loadings.</span>
<span class="sd">        :type loadings: str or None</span>

<span class="sd">        :param eigenvalues: Global annotation path to store eigenvalues.</span>
<span class="sd">        :type eigenvalues: str or None</span>

<span class="sd">        :param k: Number of principal components.</span>
<span class="sd">        :type k: int or None</span>

<span class="sd">        :param bool as_array: Store annotations as type Array rather than Struct</span>
<span class="sd">        :type k: bool or None</span>

<span class="sd">        :return: Dataset with new PCA annotations.</span>
<span class="sd">        :rtype: :class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">jvds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvdf</span><span class="o">.</span><span class="n">pca</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">joption</span><span class="p">(</span><span class="n">loadings</span><span class="p">),</span> <span class="n">joption</span><span class="p">(</span><span class="n">eigenvalues</span><span class="p">),</span> <span class="n">as_array</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">jvds</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.persist"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.persist">[docs]</a>    <span class="k">def</span> <span class="nf">persist</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">storage_level</span><span class="o">=</span><span class="s2">&quot;MEMORY_AND_DISK&quot;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Persist this variant dataset to memory and/or disk.</span>

<span class="sd">        **Examples**</span>

<span class="sd">        Persist the variant dataset to both memory and disk:</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds.persist()</span>

<span class="sd">        **Notes**</span>

<span class="sd">        The :py:meth:`~hail.VariantDataset.persist` and :py:meth:`~hail.VariantDataset.cache` commands </span>
<span class="sd">        allow you to store the current dataset on disk or in memory to avoid redundant computation and </span>
<span class="sd">        improve the performance of Hail pipelines.</span>

<span class="sd">        :py:meth:`~hail.VariantDataset.cache` is an alias for </span>
<span class="sd">        :func:`persist(&quot;MEMORY_ONLY&quot;) &lt;hail.VariantDataset.persist&gt;`.  Most users will want &quot;MEMORY_AND_DISK&quot;.</span>
<span class="sd">        See the `Spark documentation &lt;http://spark.apache.org/docs/latest/programming-guide.html#rdd-persistence&gt;`_ </span>
<span class="sd">        for a more in-depth discussion of persisting data.</span>
<span class="sd">        </span>
<span class="sd">        .. warning ::</span>
<span class="sd">            </span>
<span class="sd">            Persist, like all other :class:`.VariantDataset` functions, is functional.</span>
<span class="sd">            Its output must be captured. This is wrong:</span>
<span class="sd">            </span>
<span class="sd">            &gt;&gt;&gt; vds = vds.linreg(&#39;sa.phenotype&#39;) # doctest: +SKIP</span>
<span class="sd">            &gt;&gt;&gt; vds.persist() # doctest: SKIP</span>
<span class="sd">            </span>
<span class="sd">            The above code does NOT persist ``vds``. Instead, it copies ``vds`` and persists that result. </span>
<span class="sd">            The proper usage is this:</span>
<span class="sd">            </span>
<span class="sd">            &gt;&gt;&gt; vds = vds.pca().persist() # doctest: +SKIP</span>

<span class="sd">        :param storage_level: Storage level.  One of: NONE, DISK_ONLY,</span>
<span class="sd">            DISK_ONLY_2, MEMORY_ONLY, MEMORY_ONLY_2, MEMORY_ONLY_SER,</span>
<span class="sd">            MEMORY_ONLY_SER_2, MEMORY_AND_DISK, MEMORY_AND_DISK_2,</span>
<span class="sd">            MEMORY_AND_DISK_SER, MEMORY_AND_DISK_SER_2, OFF_HEAP</span>
<span class="sd">            </span>
<span class="sd">        :rtype: :class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvdf</span><span class="o">.</span><span class="n">persist</span><span class="p">(</span><span class="n">storage_level</span><span class="p">))</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">global_schema</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the signature of the global annotations contained in this VDS.</span>

<span class="sd">        &gt;&gt;&gt; print(vds.global_schema)</span>

<span class="sd">        :rtype: :class:`.Type`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_global_schema</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_global_schema</span> <span class="o">=</span> <span class="n">Type</span><span class="o">.</span><span class="n">_from_java</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">globalSignature</span><span class="p">())</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_global_schema</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">sample_schema</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the signature of the sample annotations contained in this VDS.</span>

<span class="sd">        &gt;&gt;&gt; print(vds.sample_schema)</span>

<span class="sd">        :rtype: :class:`.Type`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sa_schema</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_sa_schema</span> <span class="o">=</span> <span class="n">Type</span><span class="o">.</span><span class="n">_from_java</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">saSignature</span><span class="p">())</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sa_schema</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">variant_schema</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the signature of the variant annotations contained in this VDS.</span>

<span class="sd">        &gt;&gt;&gt; print(vds.variant_schema)</span>

<span class="sd">        :rtype: :class:`.Type`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_va_schema</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_va_schema</span> <span class="o">=</span> <span class="n">Type</span><span class="o">.</span><span class="n">_from_java</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">vaSignature</span><span class="p">())</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_va_schema</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">genotype_schema</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the signature of the genotypes contained in this VDS.</span>

<span class="sd">        &gt;&gt;&gt; print(vds.genotype_schema)</span>

<span class="sd">        :rtype: :class:`.Type`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_genotype_schema</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_genotype_schema</span> <span class="o">=</span> <span class="n">Type</span><span class="o">.</span><span class="n">_from_java</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">genotypeSignature</span><span class="p">())</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_genotype_schema</span>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.query_samples_typed"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.query_samples_typed">[docs]</a>    <span class="k">def</span> <span class="nf">query_samples_typed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">exprs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Performs aggregation queries over samples and sample annotations, and returns Python object(s) and type(s).</span>

<span class="sd">        **Examples**</span>

<span class="sd">        &gt;&gt;&gt; low_callrate_samples, t = vds.query_samples_typed(</span>
<span class="sd">        ...    &#39;samples.filter(s =&gt; sa.qc.callRate &lt; 0.95).collect()&#39;)</span>

<span class="sd">        See :py:meth:`.query_samples` for more information.</span>

<span class="sd">        :param exprs: query expressions</span>
<span class="sd">        :type exprs: str or list of str</span>

<span class="sd">        :rtype: (annotation or list of annotation,  :class:`.Type` or list of :class:`.Type`)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">exprs</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">result_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">querySamples</span><span class="p">(</span><span class="n">jarray</span><span class="p">(</span><span class="n">Env</span><span class="o">.</span><span class="n">jvm</span><span class="p">()</span><span class="o">.</span><span class="n">java</span><span class="o">.</span><span class="n">lang</span><span class="o">.</span><span class="n">String</span><span class="p">,</span> <span class="n">exprs</span><span class="p">))</span>
            <span class="n">ptypes</span> <span class="o">=</span> <span class="p">[</span><span class="n">Type</span><span class="o">.</span><span class="n">_from_java</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">_2</span><span class="p">())</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">result_list</span><span class="p">]</span>
            <span class="n">annotations</span> <span class="o">=</span> <span class="p">[</span><span class="n">ptypes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">_convert_to_py</span><span class="p">(</span><span class="n">result_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">_1</span><span class="p">())</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">xrange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ptypes</span><span class="p">))]</span>
            <span class="k">return</span> <span class="n">annotations</span><span class="p">,</span> <span class="n">ptypes</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">querySamples</span><span class="p">(</span><span class="n">exprs</span><span class="p">)</span>
            <span class="n">t</span> <span class="o">=</span> <span class="n">Type</span><span class="o">.</span><span class="n">_from_java</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">_2</span><span class="p">())</span>
            <span class="k">return</span> <span class="n">t</span><span class="o">.</span><span class="n">_convert_to_py</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">_1</span><span class="p">()),</span> <span class="n">t</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.query_samples"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.query_samples">[docs]</a>    <span class="k">def</span> <span class="nf">query_samples</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">exprs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Performs aggregation queries over samples and sample annotations, and returns Python object(s).</span>

<span class="sd">        **Examples**</span>

<span class="sd">        &gt;&gt;&gt; low_callrate_samples = vds.query_samples(&#39;samples.filter(s =&gt; sa.qc.callRate &lt; 0.95).collect()&#39;)</span>

<span class="sd">        **Notes**</span>

<span class="sd">        This method evaluates Hail expressions over samples and sample</span>
<span class="sd">        annotations.  The ``exprs`` argument requires either a single string</span>
<span class="sd">        or a list of strings. If a single string was passed, then a single</span>
<span class="sd">        result is returned. If a list is passed, a list is returned.</span>


<span class="sd">        The namespace of the expressions includes:</span>

<span class="sd">        - ``global``: global annotations</span>
<span class="sd">        - ``samples`` (*Aggregable[Sample]*): aggregable of :ref:`sample`</span>

<span class="sd">        Map and filter expressions on this aggregable have the additional</span>
<span class="sd">        namespace:</span>

<span class="sd">        - ``global``: global annotations</span>
<span class="sd">        - ``s``: sample</span>
<span class="sd">        - ``sa``: sample annotations</span>

<span class="sd">        :param exprs: query expressions</span>
<span class="sd">        :type exprs: str or list of str</span>

<span class="sd">        :rtype: annotation or list of annotation</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">r</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">query_samples_typed</span><span class="p">(</span><span class="n">exprs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">r</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.query_variants_typed"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.query_variants_typed">[docs]</a>    <span class="k">def</span> <span class="nf">query_variants_typed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">exprs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Performs aggregation queries over variants and variant annotations, and returns Python object(s) and type(s).</span>

<span class="sd">        **Examples**</span>

<span class="sd">        &gt;&gt;&gt; lof_variant_count, t = vds.query_variants_typed(</span>
<span class="sd">        ...     &#39;variants.filter(v =&gt; va.consequence == &quot;LOF&quot;).count()&#39;)</span>

<span class="sd">        &gt;&gt;&gt; [lof_variant_count, missense_count], [t1, t2] = vds.query_variants_typed([</span>
<span class="sd">        ...     &#39;variants.filter(v =&gt; va.consequence == &quot;LOF&quot;).count()&#39;,</span>
<span class="sd">        ...     &#39;variants.filter(v =&gt; va.consequence == &quot;Missense&quot;).count()&#39;])</span>

<span class="sd">        See :py:meth:`.query_variants` for more information.</span>

<span class="sd">        :param exprs: query expressions</span>
<span class="sd">        :type exprs: str or list of str</span>

<span class="sd">        :rtype: (annotation or list of annotation, :class:`.Type` or list of :class:`.Type`)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">exprs</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">result_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">queryVariants</span><span class="p">(</span><span class="n">jarray</span><span class="p">(</span><span class="n">Env</span><span class="o">.</span><span class="n">jvm</span><span class="p">()</span><span class="o">.</span><span class="n">java</span><span class="o">.</span><span class="n">lang</span><span class="o">.</span><span class="n">String</span><span class="p">,</span> <span class="n">exprs</span><span class="p">))</span>
            <span class="n">ptypes</span> <span class="o">=</span> <span class="p">[</span><span class="n">Type</span><span class="o">.</span><span class="n">_from_java</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">_2</span><span class="p">())</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">result_list</span><span class="p">]</span>
            <span class="n">annotations</span> <span class="o">=</span> <span class="p">[</span><span class="n">ptypes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">_convert_to_py</span><span class="p">(</span><span class="n">result_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">_1</span><span class="p">())</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">xrange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ptypes</span><span class="p">))]</span>
            <span class="k">return</span> <span class="n">annotations</span><span class="p">,</span> <span class="n">ptypes</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">queryVariants</span><span class="p">(</span><span class="n">exprs</span><span class="p">)</span>
            <span class="n">t</span> <span class="o">=</span> <span class="n">Type</span><span class="o">.</span><span class="n">_from_java</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">_2</span><span class="p">())</span>
            <span class="k">return</span> <span class="n">t</span><span class="o">.</span><span class="n">_convert_to_py</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">_1</span><span class="p">()),</span> <span class="n">t</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.query_variants"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.query_variants">[docs]</a>    <span class="k">def</span> <span class="nf">query_variants</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">exprs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Performs aggregation queries over variants and variant annotations, and returns Python object(s).</span>

<span class="sd">        **Examples**</span>

<span class="sd">        &gt;&gt;&gt; lof_variant_count = vds.query_variants(&#39;variants.filter(v =&gt; va.consequence == &quot;LOF&quot;).count()&#39;)</span>

<span class="sd">        &gt;&gt;&gt; [lof_variant_count, missense_count] = vds.query_variants([</span>
<span class="sd">        ...     &#39;variants.filter(v =&gt; va.consequence == &quot;LOF&quot;).count()&#39;,</span>
<span class="sd">        ...     &#39;variants.filter(v =&gt; va.consequence == &quot;Missense&quot;).count()&#39;])</span>

<span class="sd">        **Notes**</span>

<span class="sd">        This method evaluates Hail expressions over variants and variant</span>
<span class="sd">        annotations.  The ``exprs`` argument requires either a single string</span>
<span class="sd">        or a list of strings. If a single string was passed, then a single</span>
<span class="sd">        result is returned. If a list is passed, a list is returned.</span>


<span class="sd">        The namespace of the expressions includes:</span>

<span class="sd">        - ``global``: global annotations</span>
<span class="sd">        - ``variants`` (*Aggregable[Variant]*): aggregable of :ref:`variant`</span>

<span class="sd">        Map and filter expressions on this aggregable have the additional</span>
<span class="sd">        namespace:</span>

<span class="sd">        - ``global``: global annotations</span>
<span class="sd">        - ``v``: :ref:`variant`</span>
<span class="sd">        - ``va``: variant annotations</span>

<span class="sd">        **Performance Note**</span>
<span class="sd">        It is far faster to execute multiple queries in one method than</span>
<span class="sd">        to execute multiple query methods.  The combined query:</span>

<span class="sd">        &gt;&gt;&gt; exprs = [&#39;variants.count()&#39;, &#39;variants.filter(v =&gt; v.altAllele.isSNP()).count()&#39;]</span>
<span class="sd">        &gt;&gt;&gt; [num_variants, num_snps] = vds.query_variants(exprs)</span>

<span class="sd">        will be nearly twice as fast as the split query:</span>

<span class="sd">        &gt;&gt;&gt; result1 = vds.query_variants(&#39;variants.count()&#39;)</span>
<span class="sd">        &gt;&gt;&gt; result2 = vds.query_variants(&#39;variants.filter(v =&gt; v.altAllele.isSNP()).count()&#39;)</span>

<span class="sd">        :param exprs: query expressions</span>
<span class="sd">        :type exprs: str or list of str</span>

<span class="sd">        :rtype: annotation or list of annotation</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">r</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">query_variants_typed</span><span class="p">(</span><span class="n">exprs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">r</span></div>

<div class="viewcode-block" id="VariantDataset.query_genotypes_typed"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.query_genotypes_typed">[docs]</a>    <span class="k">def</span> <span class="nf">query_genotypes_typed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">exprs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Performs aggregation queries over genotypes, and returns Python object(s) and type(s).</span>

<span class="sd">        **Examples**</span>

<span class="sd">        &gt;&gt;&gt; gq_hist, t = vds.query_genotypes_typed(&#39;gs.map(g =&gt; g.gq).hist(0, 100, 100)&#39;)</span>

<span class="sd">        &gt;&gt;&gt; [gq_hist, dp_hist], [t1, t2] = vds.query_genotypes_typed([&#39;gs.map(g =&gt; g.gq).hist(0, 100, 100)&#39;,</span>
<span class="sd">        ...                                                           &#39;gs.map(g =&gt; g.dp).hist(0, 60, 60)&#39;])</span>

<span class="sd">        See :py:meth:`.query_genotypes` for more information.</span>

<span class="sd">        This method evaluates Hail expressions over genotypes, along with</span>
<span class="sd">        all variant and sample metadata for that genotype. The ``exprs``</span>
<span class="sd">        argument requires either a list of strings or a single string</span>
<span class="sd">        The method returns a list of results and a list of types (which</span>
<span class="sd">        each contain one element if the input parameter was a single str).</span>

<span class="sd">        The namespace of the expressions includes:</span>

<span class="sd">        - ``global``: global annotations</span>
<span class="sd">        - ``gs`` (*Aggregable[Genotype]*): aggregable of :ref:`genotype`</span>

<span class="sd">        Map and filter expressions on this aggregable have the following</span>
<span class="sd">        namespace:</span>

<span class="sd">        - ``global``: global annotations</span>
<span class="sd">        - ``g``: :ref:`genotype`</span>
<span class="sd">        - ``v``: :ref:`variant`</span>
<span class="sd">        - ``va``: variant annotations</span>
<span class="sd">        - ``s``: sample</span>
<span class="sd">        - ``sa``: sample annotations</span>

<span class="sd">        **Performance Note**</span>
<span class="sd">        It is far faster to execute multiple queries in one method than</span>
<span class="sd">        to execute multiple query methods.  This:</span>

<span class="sd">        &gt;&gt;&gt; result1 = vds.query_genotypes(&#39;gs.count()&#39;)</span>
<span class="sd">        &gt;&gt;&gt; result2 = vds.query_genotypes(&#39;gs.filter(g =&gt; v.altAllele.isSNP() &amp;&amp; g.isHet).count()&#39;)</span>

<span class="sd">        will be nearly twice as slow as this:</span>

<span class="sd">        &gt;&gt;&gt; exprs = [&#39;gs.count()&#39;, &#39;gs.filter(g =&gt; v.altAllele.isSNP() &amp;&amp; g.isHet).count()&#39;]</span>
<span class="sd">        &gt;&gt;&gt; [geno_count, snp_hets] = vds.query_genotypes(exprs)</span>

<span class="sd">        :param exprs: query expressions</span>
<span class="sd">        :type exprs: str or list of str</span>

<span class="sd">        :rtype: (annotation or list of annotation, :class:`.Type` or list of :class:`.Type`)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">exprs</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">result_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">queryGenotypes</span><span class="p">(</span><span class="n">jarray</span><span class="p">(</span><span class="n">Env</span><span class="o">.</span><span class="n">jvm</span><span class="p">()</span><span class="o">.</span><span class="n">java</span><span class="o">.</span><span class="n">lang</span><span class="o">.</span><span class="n">String</span><span class="p">,</span> <span class="n">exprs</span><span class="p">))</span>
            <span class="n">ptypes</span> <span class="o">=</span> <span class="p">[</span><span class="n">Type</span><span class="o">.</span><span class="n">_from_java</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">_2</span><span class="p">())</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">result_list</span><span class="p">]</span>
            <span class="n">annotations</span> <span class="o">=</span> <span class="p">[</span><span class="n">ptypes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">_convert_to_py</span><span class="p">(</span><span class="n">result_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">_1</span><span class="p">())</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">xrange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ptypes</span><span class="p">))]</span>
            <span class="k">return</span> <span class="n">annotations</span><span class="p">,</span> <span class="n">ptypes</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">queryGenotypes</span><span class="p">(</span><span class="n">exprs</span><span class="p">)</span>
            <span class="n">t</span> <span class="o">=</span> <span class="n">Type</span><span class="o">.</span><span class="n">_from_java</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">_2</span><span class="p">())</span>
            <span class="k">return</span> <span class="n">t</span><span class="o">.</span><span class="n">_convert_to_py</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">_1</span><span class="p">()),</span> <span class="n">t</span></div>

<div class="viewcode-block" id="VariantDataset.query_genotypes"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.query_genotypes">[docs]</a>    <span class="k">def</span> <span class="nf">query_genotypes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">exprs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Performs aggregation queries over genotypes, and returns Python object(s).</span>

<span class="sd">        **Examples**</span>

<span class="sd">        Compute global GQ histogram</span>

<span class="sd">        &gt;&gt;&gt; gq_hist = vds.query_genotypes(&#39;gs.map(g =&gt; g.gq).hist(0, 100, 100)&#39;)</span>

<span class="sd">        Compute call rate</span>

<span class="sd">        &gt;&gt;&gt; call_rate = vds.query_genotypes(&#39;gs.fraction(g =&gt; g.isCalled)&#39;)</span>

<span class="sd">        Compute GQ and DP histograms</span>

<span class="sd">        &gt;&gt;&gt; [gq_hist, dp_hist] = vds.query_genotypes([&#39;gs.map(g =&gt; g.gq).hist(0, 100, 100)&#39;,</span>
<span class="sd">        ...                                                     &#39;gs.map(g =&gt; g.dp).hist(0, 60, 60)&#39;])</span>


<span class="sd">        :param exprs: query expressions</span>
<span class="sd">        :type exprs: str or list of str</span>

<span class="sd">        :rtype: annotation or list of annotation</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">r</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">query_genotypes_typed</span><span class="p">(</span><span class="n">exprs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">r</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.rename_samples"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.rename_samples">[docs]</a>    <span class="k">def</span> <span class="nf">rename_samples</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mapping</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Rename samples.</span>

<span class="sd">        **Examples**</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds.rename_samples({&#39;ID1&#39;: &#39;id1&#39;, &#39;ID2&#39;: &#39;id2&#39;})</span>

<span class="sd">        :param dict mapping: Mapping from old to new sample IDs.</span>

<span class="sd">        :return: Dataset with remapped sample IDs.</span>
<span class="sd">        :rtype: :class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">jvds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">renameSamples</span><span class="p">(</span><span class="n">mapping</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">jvds</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.repartition"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.repartition">[docs]</a>    <span class="k">def</span> <span class="nf">repartition</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_partitions</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Increase or decrease the number of variant dataset partitions.</span>

<span class="sd">        **Examples**</span>

<span class="sd">        Repartition the variant dataset to have 500 partitions:</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds.repartition(500)</span>

<span class="sd">        **Notes**</span>

<span class="sd">        Check the current number of partitions with :py:meth:`.num_partitions`.</span>

<span class="sd">        The data in a variant dataset is divided into chunks called partitions, which may be stored together or across a network, so that each partition may be read and processed in parallel by available cores. When a variant dataset with :math:`M` variants is first imported, each of the :math:`k` partition will contain about :math:`M/k` of the variants. Since each partition has some computational overhead, decreasing the number of partitions can improve performance after significant filtering. Since it&#39;s recommended to have at least 2 - 4 partitions per core, increasing the number of partitions can allow one to take advantage of more cores.</span>

<span class="sd">        Partitions are a core concept of distributed computation in Spark, see `here &lt;http://spark.apache.org/docs/latest/programming-guide.html#resilient-distributed-datasets-rdds&gt;`_ for details. With ``shuffle=True``, Hail does a full shuffle of the data and creates equal sized partitions. With ``shuffle=False``, Hail combines existing partitions to avoid a full shuffle. These algorithms correspond to the ``repartition`` and ``coalesce`` commands in Spark, respectively. In particular, when ``shuffle=False``, ``num_partitions`` cannot exceed current number of partitions.</span>

<span class="sd">        :param int num_partitions: Desired number of partitions, must be less than the current number if ``shuffle=False``</span>

<span class="sd">        :param bool shuffle: If True, use full shuffle to repartition.</span>

<span class="sd">        :return: Variant dataset with the number of partitions equal to at most ``num_partitions``</span>
<span class="sd">        :rtype: :class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">jvds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvdf</span><span class="o">.</span><span class="n">coalesce</span><span class="p">(</span><span class="n">num_partitions</span><span class="p">,</span> <span class="n">shuffle</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">jvds</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.rrm"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.rrm">[docs]</a>    <span class="k">def</span> <span class="nf">rrm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">force_block</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">force_gramian</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Computes the Realized Relationship Matrix (RRM).</span>

<span class="sd">        **Examples**</span>

<span class="sd">        &gt;&gt;&gt; kinship_matrix = vds.rrm()</span>

<span class="sd">        **Notes**</span>

<span class="sd">        The Realized Relationship Matrix is defined as follows. Consider the :math:`n \\times m` matrix :math:`C` of raw genotypes, with rows indexed by :math:`n` samples and</span>
<span class="sd">        columns indexed by the :math:`m` bialellic autosomal variants; :math:`C_{ij}` is the number of alternate alleles of variant :math:`j` carried by sample :math:`i`, which</span>
<span class="sd">        can be 0, 1, 2, or missing. For each variant :math:`j`, the sample alternate allele frequency :math:`p_j` is computed as half the mean of the non-missing entries of column</span>
<span class="sd">        :math:`j`. Entries of :math:`M` are then mean-centered and variance-normalized as</span>

<span class="sd">        .. math::</span>

<span class="sd">          M_{ij} = \\frac{C_{ij}-2p_j}{\sqrt{\\frac{m}{n} \sum_{k=1}^n (C_{ij}-2p_j)^2}},</span>

<span class="sd">        with :math:`M_{ij} = 0` for :math:`C_{ij}` missing (i.e. mean genotype imputation). This scaling normalizes each variant column to have empirical variance :math:`1/m`, which gives each sample row approximately unit total variance (assuming linkage equilibrium) and yields the :math:`n \\times n` sample correlation or realized relationship matrix (RRM) :math:`K` as simply</span>

<span class="sd">        .. math::</span>

<span class="sd">          K = MM^T</span>

<span class="sd">        Note that the only difference between the Realized Relationship Matrix and the Genetic Relationship Matrix (GRM) used in :py:meth:`~hail.VariantDataset.grm` is the variant (column) normalization: where RRM uses empirical variance, GRM uses expected variance under Hardy-Weinberg Equilibrium.</span>

<span class="sd">        :param bool force_block: Force using Spark&#39;s BlockMatrix to compute kinship (advanced).</span>

<span class="sd">        :param bool force_gramian: Force using Spark&#39;s RowMatrix.computeGramian to compute kinship (advanced).</span>

<span class="sd">        :return: Realized Relationship Matrix for all samples.</span>
<span class="sd">        :rtype: :py:class:`KinshipMatrix`</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">KinshipMatrix</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_jvdf</span><span class="o">.</span><span class="n">rrm</span><span class="p">(</span><span class="n">force_block</span><span class="p">,</span> <span class="n">force_gramian</span><span class="p">))</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.same"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.same">[docs]</a>    <span class="k">def</span> <span class="nf">same</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">tolerance</span><span class="o">=</span><span class="mi">1</span><span class="n">e</span><span class="o">-</span><span class="mi">6</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;True if the two variant datasets have the same variants, samples, genotypes, and annotation schemata and values.</span>

<span class="sd">        **Examples**</span>

<span class="sd">        This will return True:</span>

<span class="sd">        &gt;&gt;&gt; vds.same(vds)</span>

<span class="sd">        **Notes**</span>

<span class="sd">        The ``tolerance`` parameter sets the tolerance for equality when comparing floating-point fields. More precisely, :math:`x` and :math:`y` are equal if</span>

<span class="sd">        .. math::</span>

<span class="sd">            \abs{x - y} \leq tolerance * \max{\abs{x}, \abs{y}}</span>

<span class="sd">        :param other: variant dataset to compare against</span>
<span class="sd">        :type other: :class:`.VariantDataset`</span>

<span class="sd">        :param float tolerance: floating-point tolerance for equality</span>

<span class="sd">        :rtype: bool</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">same</span><span class="p">(</span><span class="n">other</span><span class="o">.</span><span class="n">_jvds</span><span class="p">,</span> <span class="n">tolerance</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
    <span class="nd">@requireTGenotype</span>
<div class="viewcode-block" id="VariantDataset.sample_qc"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.sample_qc">[docs]</a>    <span class="k">def</span> <span class="nf">sample_qc</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">root</span><span class="o">=</span><span class="s1">&#39;sa.qc&#39;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Compute per-sample QC metrics.</span>

<span class="sd">        .. include:: requireTGenotype.rst</span>

<span class="sd">        **Annotations**</span>

<span class="sd">        :py:meth:`~hail.VariantDataset.sample_qc` computes 20 sample statistics from the </span>
<span class="sd">        genotype data and stores the results as sample annotations that can be accessed with</span>
<span class="sd">         ``sa.qc.&lt;identifier&gt;`` (or ``&lt;root&gt;.&lt;identifier&gt;`` if a non-default root was passed):</span>

<span class="sd">        +---------------------------+--------+----------------------------------------------------------+</span>
<span class="sd">        | Name                      | Type   | Description                                              |</span>
<span class="sd">        +===========================+========+==========================================================+</span>
<span class="sd">        | ``callRate``              | Double | Fraction of genotypes called                             |</span>
<span class="sd">        +---------------------------+--------+----------------------------------------------------------+</span>
<span class="sd">        | ``nHomRef``               | Int    | Number of homozygous reference genotypes                 |</span>
<span class="sd">        +---------------------------+--------+----------------------------------------------------------+</span>
<span class="sd">        | ``nHet``                  | Int    | Number of heterozygous genotypes                         |</span>
<span class="sd">        +---------------------------+--------+----------------------------------------------------------+</span>
<span class="sd">        | ``nHomVar``               | Int    | Number of homozygous alternate genotypes                 |</span>
<span class="sd">        +---------------------------+--------+----------------------------------------------------------+</span>
<span class="sd">        | ``nCalled``               | Int    | Sum of ``nHomRef`` + ``nHet`` + ``nHomVar``              |</span>
<span class="sd">        +---------------------------+--------+----------------------------------------------------------+</span>
<span class="sd">        | ``nNotCalled``            | Int    | Number of uncalled genotypes                             |</span>
<span class="sd">        +---------------------------+--------+----------------------------------------------------------+</span>
<span class="sd">        | ``nSNP``                  | Int    | Number of SNP alternate alleles                          |</span>
<span class="sd">        +---------------------------+--------+----------------------------------------------------------+</span>
<span class="sd">        | ``nInsertion``            | Int    | Number of insertion alternate alleles                    |</span>
<span class="sd">        +---------------------------+--------+----------------------------------------------------------+</span>
<span class="sd">        | ``nDeletion``             | Int    | Number of deletion alternate alleles                     |</span>
<span class="sd">        +---------------------------+--------+----------------------------------------------------------+</span>
<span class="sd">        | ``nSingleton``            | Int    | Number of private alleles                                |</span>
<span class="sd">        +---------------------------+--------+----------------------------------------------------------+</span>
<span class="sd">        | ``nTransition``           | Int    | Number of transition (A-G, C-T) alternate alleles        |</span>
<span class="sd">        +---------------------------+--------+----------------------------------------------------------+</span>
<span class="sd">        | ``nTransversion``         | Int    | Number of transversion alternate alleles                 |</span>
<span class="sd">        +---------------------------+--------+----------------------------------------------------------+</span>
<span class="sd">        | ``nNonRef``               | Int    | Sum of ``nHet`` and ``nHomVar``                          |</span>
<span class="sd">        +---------------------------+--------+----------------------------------------------------------+</span>
<span class="sd">        | ``rTiTv``                 | Double | Transition/Transversion ratio                            |</span>
<span class="sd">        +---------------------------+--------+----------------------------------------------------------+</span>
<span class="sd">        | ``rHetHomVar``            | Double | Het/HomVar genotype ratio                                |</span>
<span class="sd">        +---------------------------+--------+----------------------------------------------------------+</span>
<span class="sd">        | ``rInsertionDeletion``    | Double | Insertion/Deletion ratio                                 |</span>
<span class="sd">        +---------------------------+--------+----------------------------------------------------------+</span>
<span class="sd">        | ``dpMean``                | Double | Depth mean across all genotypes                          |</span>
<span class="sd">        +---------------------------+--------+----------------------------------------------------------+</span>
<span class="sd">        | ``dpStDev``               | Double | Depth standard deviation across all genotypes            |</span>
<span class="sd">        +---------------------------+--------+----------------------------------------------------------+</span>
<span class="sd">        | ``gqMean``                | Double | The average genotype quality across all genotypes        |</span>
<span class="sd">        +---------------------------+--------+----------------------------------------------------------+</span>
<span class="sd">        | ``gqStDev``               | Double | Genotype quality standard deviation across all genotypes |</span>
<span class="sd">        +---------------------------+--------+----------------------------------------------------------+</span>

<span class="sd">        Missing values ``NA`` may result (for example, due to division by zero) and are handled properly in filtering and written as &quot;NA&quot; in export modules. The empirical standard deviation is computed with zero degrees of freedom.</span>

<span class="sd">        :param str root: Sample annotation root for the computed struct.</span>
<span class="sd">        </span>
<span class="sd">        :return: Annotated variant dataset with new sample qc annotations.</span>
<span class="sd">        :rtype: :class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">root</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">root</span><span class="p">,</span> <span class="n">unicode</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Parameter &#39;root&#39; must be type str, but found </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="nb">type</span><span class="p">(</span><span class="n">root</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvdf</span><span class="o">.</span><span class="n">sampleQC</span><span class="p">(</span><span class="n">root</span><span class="p">))</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.storage_level"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.storage_level">[docs]</a>    <span class="k">def</span> <span class="nf">storage_level</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the storage (persistence) level of the variant dataset.</span>

<span class="sd">        **Notes**</span>

<span class="sd">        See the `Spark documentation &lt;http://spark.apache.org/docs/latest/programming-guide.html#rdd-persistence&gt;`_ for details on persistence levels.</span>

<span class="sd">        :rtype: str</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">storageLevel</span><span class="p">()</span></div>

    <span class="nd">@handle_py4j</span>
    <span class="nd">@requireTGenotype</span>
<div class="viewcode-block" id="VariantDataset.summarize"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.summarize">[docs]</a>    <span class="k">def</span> <span class="nf">summarize</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns a summary of useful information about the dataset.</span>
<span class="sd">        </span>
<span class="sd">        .. include:: requireTGenotype.rst</span>

<span class="sd">        </span>
<span class="sd">        **Examples**</span>
<span class="sd">        </span>
<span class="sd">        &gt;&gt;&gt; s = vds.summarize()</span>
<span class="sd">        &gt;&gt;&gt; print(s.contigs)</span>
<span class="sd">        &gt;&gt;&gt; print(&#39;call rate is %.2f&#39; % s.call_rate)</span>
<span class="sd">        &gt;&gt;&gt; s.report()</span>
<span class="sd">        </span>
<span class="sd">        The following information is contained in the summary:</span>
<span class="sd">        </span>
<span class="sd">         - **samples** (*int*) - Number of samples.</span>
<span class="sd">         - **variants** (*int*) - Number of variants.</span>
<span class="sd">         - **call_rate** (*float*) - Fraction of all genotypes called.</span>
<span class="sd">         - **contigs** (*list of str*) - List of all unique contigs found in the dataset.</span>
<span class="sd">         - **multiallelics** (*int*) - Number of multiallelic variants.</span>
<span class="sd">         - **snps** (*int*) - Number of SNP alternate alleles.</span>
<span class="sd">         - **mnps** (*int*) - Number of MNP alternate alleles.</span>
<span class="sd">         - **insertions** (*int*) - Number of insertion alternate alleles.</span>
<span class="sd">         - **deletions** (*int*) - Number of deletions alternate alleles.</span>
<span class="sd">         - **complex** (*int*) - Number of complex alternate alleles.</span>
<span class="sd">         - **star** (*int*) - Number of star (upstream deletion) alternate alleles.</span>
<span class="sd">         - **max_alleles** (*int*) - The highest number of alleles at any variant.</span>
<span class="sd">         </span>
<span class="sd">        :return: Object containing summary information.</span>
<span class="sd">        :rtype: :class:`~hail.utils.Summary`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">js</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvdf</span><span class="o">.</span><span class="n">summarize</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">Summary</span><span class="o">.</span><span class="n">_from_java</span><span class="p">(</span><span class="n">js</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.set_va_attributes"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.set_va_attributes">[docs]</a>    <span class="k">def</span> <span class="nf">set_va_attributes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ann_path</span><span class="p">,</span> <span class="n">attributes</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Sets attributes for a variant annotation.</span>
<span class="sd">        Attributes are key/value pairs that can be attached to a variant annotation field.</span>

<span class="sd">        The following attributes are read from the VCF header when importing a VCF and written</span>
<span class="sd">        to the VCF header when exporting a VCF:</span>
<span class="sd">        - INFO fields attributes (attached to (`va.info.*`)):</span>
<span class="sd">            - &#39;Number&#39;: The arity of the field. Can take values</span>
<span class="sd">            `0` (Boolean flag),</span>
<span class="sd">            `1` (single value),</span>
<span class="sd">            `R` (one value per allele, including the reference),</span>
<span class="sd">            `A` (one value per non-reference allele),</span>
<span class="sd">            `G` (one value per genotype), and</span>
<span class="sd">            `.` (any number of values)</span>
<span class="sd">                - When importing: The value in read from the VCF INFO field definition</span>
<span class="sd">                - When exporting: The default value is `0` for **Boolean**, `.` for **Arrays** and 1 for all other types</span>
<span class="sd">            - &#39;Description&#39; (default is &#39;&#39;)</span>
<span class="sd">        - FILTER entries in the VCF header are generated based on the attributes of `va.filters`.</span>
<span class="sd">        Each key/value pair in the attributes will generate a FILTER entry in the VCF with ID = key and Description = value.</span>

<span class="sd">        **Examples**</span>

<span class="sd">        Consider the following command which adds a filter and an annotation to the VDS (we&#39;re assuming a split VDS for simplicity):</span>
<span class="sd">        1) an INFO field `AC_HC`, which stores the allele count of high confidence genotypes (DP &gt;= 10, GQ &gt;= 20) for each non-reference allele,</span>
<span class="sd">        2) a filter `HardFilter` that filters all sites with the [GATK suggested hard filters]</span>
<span class="sd">        (http://gatkforums.broadinstitute.org/gatk/discussion/2806/howto-apply-hard-filters-to-a-call-set):</span>
<span class="sd">            - For SNVs: QD &lt; 2.0 || FS &lt; 60 || MQ &lt; 40 || MQRankSum &lt; -12.5 || ReadPosRankSum &lt; -8.0</span>
<span class="sd">            - For Indels (and other complex): QD &lt; 2.0 || FS &lt; 200.0 || ReadPosRankSum &lt; 20.0</span>
<span class="sd">        &gt;&gt;&gt; annotated_vds = vds.annotate_variants_expr([</span>
<span class="sd">        ... &#39;va.info.AC_HC = gs.filter(g =&gt; g.dp &gt;= 10 &amp;&amp; g.gq &gt;= 20).callStats(g =&gt; v).AC[1:]&#39;,</span>
<span class="sd">        ... &#39;va.filters = if((v.altAllele.isSNP &amp;&amp; (va.info.QD &lt; 2.0 || va.info.FS &lt; 60 || va.info.MQ &lt; 40 || &#39; +</span>
<span class="sd">        ... &#39;va.info.MQRankSum &lt; -12.5 || va.info.ReadPosRankSum &lt; -8.0)) || &#39; +</span>
<span class="sd">        ... &#39;(va.info.QD &lt; 2.0 || va.info.FS &lt; 200.0 || va.info.ReadPosRankSum &lt; 20.0)) va.filters.add(&quot;HardFilter&quot;) else va.filters&#39;])</span>

<span class="sd">        If we now export this VDS as VCF, it would produce the following header (for these new fields):</span>
<span class="sd">        ```</span>
<span class="sd">        ##INFO=&lt;ID=AC_HC,Number=.,Type=String,Description=&quot;&quot;</span>
<span class="sd">        ```</span>

<span class="sd">        This header doesn&#39;t contain all information that should be present in an optimal VCF header:</span>
<span class="sd">        1) There is no FILTER entry for `HardFilter`</span>
<span class="sd">        2) Since `AC_HC` has one entry per non-reference allele, its `Number` should be `A`</span>
<span class="sd">        3) `AC_HC` should have a Description</span>

<span class="sd">        We can fix this by setting the attributes of these fields:</span>
<span class="sd">        &gt;&gt;&gt; annotated_vds = vds.set_va_attributes(&#39;va.info.AC_HC&#39;, {&#39;Description&#39;:&#39;Allele count for high quality genotypes (DP &gt;= 10, GQ &gt;= 20)&#39;,</span>
<span class="sd">        ... &#39;Number&#39;: &#39;A&#39;})</span>
<span class="sd">        &gt;&gt;&gt; annotated_vds = vds.set_va_attributes(&#39;va.filters&#39;, {&#39;HardFilter&#39;: &#39;This site fails GATK suggested hard filters.&#39;})</span>

<span class="sd">        Exporting the VDS with the attributes now prints the following header lines:</span>
<span class="sd">        ```</span>
<span class="sd">        ##INFO=&lt;ID=test,Number=A,Type=String,Description=&quot;Allele count for high quality genotypes (DP &gt;= 10, GQ &gt;= 20)&quot;</span>
<span class="sd">        ##FILTER=&lt;ID=HardFilter,Description=&quot;This site fails GATK suggested hard filters.&quot;&gt;</span>
<span class="sd">        ```</span>

<span class="sd">        :param str ann_path: Path to variant annotation beginning with `va`.</span>

<span class="sd">        :param dict attributes: A str-str dict containing the attributes to set</span>

<span class="sd">        :return: Annotated dataset with the attribute added to the variant annotation.</span>
<span class="sd">        :rtype: :class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">setVaAttributes</span><span class="p">(</span><span class="n">ann_path</span><span class="p">,</span> <span class="n">Env</span><span class="o">.</span><span class="n">jutils</span><span class="p">()</span><span class="o">.</span><span class="n">javaMapToMap</span><span class="p">(</span><span class="n">attributes</span><span class="p">)))</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.delete_va_attribute"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.delete_va_attribute">[docs]</a>    <span class="k">def</span> <span class="nf">delete_va_attribute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ann_path</span><span class="p">,</span> <span class="n">attribute</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Removes an attribute from a variant annotation field.</span>
<span class="sd">        Attributes are key/value pairs that can be attached to a variant annotation field.</span>

<span class="sd">        The following attributes are read from the VCF header when importing a VCF and written</span>
<span class="sd">        to the VCF header when exporting a VCF:</span>
<span class="sd">        - INFO fields attributes (attached to (`va.info.*`)):</span>
<span class="sd">            - &#39;Number&#39;: The arity of the field. Can take values</span>
<span class="sd">            `0` (Boolean flag),</span>
<span class="sd">            `1` (single value),</span>
<span class="sd">            `R` (one value per allele, including the reference),</span>
<span class="sd">            `A` (one value per non-reference allele),</span>
<span class="sd">            `G` (one value per genotype), and</span>
<span class="sd">            `.` (any number of values)</span>
<span class="sd">                - When importing: The value in read from the VCF INFO field definition</span>
<span class="sd">                - When exporting: The default value is `0` for **Boolean**, `.` for **Arrays** and 1 for all other types</span>
<span class="sd">            - &#39;Description&#39; (default is &#39;&#39;)</span>
<span class="sd">        - FILTER entries in the VCF header are generated based on the attributes of `va.filters`.</span>
<span class="sd">        Each key/value pair in the attributes will generate a FILTER entry in the VCF with ID = key and Description = value.</span>

<span class="sd">        :param str ann_path: Variant annotation path starting with &#39;va&#39;, period-delimited.</span>

<span class="sd">        :param str attribute: The attribute to remove (key).</span>

<span class="sd">        :return: Annotated dataset with the updated variant annotation without the attribute.</span>
<span class="sd">        :rtype: :class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">deleteVaAttribute</span><span class="p">(</span><span class="n">ann_path</span><span class="p">,</span> <span class="n">attribute</span><span class="p">))</span></div>

    <span class="nd">@handle_py4j</span>
    <span class="nd">@requireTGenotype</span>
<div class="viewcode-block" id="VariantDataset.split_multi"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.split_multi">[docs]</a>    <span class="k">def</span> <span class="nf">split_multi</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">propagate_gq</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">keep_star_alleles</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">max_shift</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Split multiallelic variants.</span>

<span class="sd">        .. include:: requireTGenotype.rst</span>

<span class="sd">        **Examples**</span>

<span class="sd">        &gt;&gt;&gt; vds.split_multi().write(&#39;output/split.vds&#39;)</span>

<span class="sd">        **Notes**</span>

<span class="sd">        We will explain by example. Consider a hypothetical 3-allelic</span>
<span class="sd">        variant:</span>

<span class="sd">        .. code-block:: text</span>

<span class="sd">          A   C,T 0/2:7,2,6:15:45:99,50,99,0,45,99</span>

<span class="sd">        split_multi will create two biallelic variants (one for each</span>
<span class="sd">        alternate allele) at the same position</span>

<span class="sd">        .. code-block:: text</span>

<span class="sd">          A   C   0/0:13,2:15:45:0,45,99</span>
<span class="sd">          A   T   0/1:9,6:15:50:50,0,99</span>

<span class="sd">        Each multiallelic GT field is downcoded once for each</span>
<span class="sd">        alternate allele. A call for an alternate allele maps to 1 in</span>
<span class="sd">        the biallelic variant corresponding to itself and 0</span>
<span class="sd">        otherwise. For example, in the example above, 0/2 maps to 0/0</span>
<span class="sd">        and 0/1. The genotype 1/2 maps to 0/1 and 0/1.</span>

<span class="sd">        The biallelic alt AD entry is just the multiallelic AD entry</span>
<span class="sd">        corresponding to the alternate allele. The ref AD entry is the</span>
<span class="sd">        sum of the other multiallelic entries.</span>

<span class="sd">        The biallelic DP is the same as the multiallelic DP.</span>

<span class="sd">        The biallelic PL entry for for a genotype g is the minimum</span>
<span class="sd">        over PL entries for multiallelic genotypes that downcode to</span>
<span class="sd">        g. For example, the PL for (A, T) at 0/1 is the minimum of the</span>
<span class="sd">        PLs for 0/1 (50) and 1/2 (45), and thus 45.</span>

<span class="sd">        Fixing an alternate allele and biallelic variant, downcoding</span>
<span class="sd">        gives a map from multiallelic to biallelic alleles and</span>
<span class="sd">        genotypes. The biallelic AD entry for an allele is just the</span>
<span class="sd">        sum of the multiallelic AD entries for alleles that map to</span>
<span class="sd">        that allele. Similarly, the biallelic PL entry for a genotype</span>
<span class="sd">        is the minimum over multiallelic PL entries for genotypes that</span>
<span class="sd">        map to that genotype.</span>

<span class="sd">        By default, GQ is recomputed from PL. If ``propagate_gq=True``</span>
<span class="sd">        is passed, the biallelic GQ field is simply the multiallelic</span>
<span class="sd">        GQ field, that is, genotype qualities are unchanged.</span>

<span class="sd">        Here is a second example for a het non-ref</span>

<span class="sd">        .. code-block:: text</span>

<span class="sd">          A   C,T 1/2:2,8,6:16:45:99,50,99,45,0,99</span>

<span class="sd">        splits as</span>

<span class="sd">        .. code-block:: text</span>

<span class="sd">          A   C   0/1:8,8:16:45:45,0,99</span>
<span class="sd">          A   T   0/1:10,6:16:50:50,0,99</span>

<span class="sd">        **VCF Info Fields**</span>

<span class="sd">        Hail does not split annotations in the info field. This means</span>
<span class="sd">        that if a multiallelic site with ``info.AC`` value ``[10, 2]`` is</span>
<span class="sd">        split, each split site will contain the same array ``[10,</span>
<span class="sd">        2]``. The provided allele index annotation ``va.aIndex`` can be used</span>
<span class="sd">        to select the value corresponding to the split allele&#39;s</span>
<span class="sd">        position:</span>

<span class="sd">        &gt;&gt;&gt; vds_result = (vds.split_multi()</span>
<span class="sd">        ...     .filter_variants_expr(&#39;va.info.AC[va.aIndex - 1] &lt; 10&#39;, keep = False))</span>

<span class="sd">        VCFs split by Hail and exported to new VCFs may be</span>
<span class="sd">        incompatible with other tools, if action is not taken</span>
<span class="sd">        first. Since the &quot;Number&quot; of the arrays in split multiallelic</span>
<span class="sd">        sites no longer matches the structure on import (&quot;A&quot; for 1 per</span>
<span class="sd">        allele, for example), Hail will export these fields with</span>
<span class="sd">        number &quot;.&quot;.</span>

<span class="sd">        If the desired output is one value per site, then it is</span>
<span class="sd">        possible to use annotate_variants_expr to remap these</span>
<span class="sd">        values. Here is an example:</span>

<span class="sd">        &gt;&gt;&gt; (vds.split_multi()</span>
<span class="sd">        ...     .annotate_variants_expr(&#39;va.info.AC = va.info.AC[va.aIndex - 1]&#39;)</span>
<span class="sd">        ...     .export_vcf(&#39;output/export.vcf&#39;))</span>

<span class="sd">        The info field AC in *data/export.vcf* will have ``Number=1``.</span>

<span class="sd">        **Annotations**</span>

<span class="sd">        :py:meth:`~hail.VariantDataset.split_multi` adds the</span>
<span class="sd">        following annotations:</span>

<span class="sd">         - **va.wasSplit** (*Boolean*) -- true if this variant was</span>
<span class="sd">           originally multiallelic, otherwise false.</span>
<span class="sd">         - **va.aIndex** (*Int*) -- The original index of this</span>
<span class="sd">           alternate allele in the multiallelic representation (NB: 1</span>
<span class="sd">           is the first alternate allele or the only alternate allele</span>
<span class="sd">           in a biallelic variant). For example, 1:100:A:T,C splits</span>
<span class="sd">           into two variants: 1:100:A:T with ``aIndex = 1`` and</span>
<span class="sd">           1:100:A:C with ``aIndex = 2``.</span>

<span class="sd">        :param bool propagate_gq: Set the GQ of output (split)</span>
<span class="sd">          genotypes to be the GQ of the input (multi-allelic) variants</span>
<span class="sd">          instead of recompute GQ as the difference between the two</span>
<span class="sd">          smallest PL values.  Intended to be used in conjunction with</span>
<span class="sd">          ``import_vcf(store_gq=True)``.  This option will be obviated</span>
<span class="sd">          in the future by generic genotype schemas.  Experimental.</span>
<span class="sd">        :param bool keep_star_alleles: Do not filter out * alleles.</span>
<span class="sd">        :param int max_shift: maximum number of base pairs by which</span>
<span class="sd">          a split variant can move.  Affects memory usage, and will</span>
<span class="sd">          cause Hail to throw an error if a variant that moves further</span>
<span class="sd">          is encountered.</span>

<span class="sd">        :return: A biallelic variant dataset.</span>
<span class="sd">        :rtype: :py:class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">jvds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvdf</span><span class="o">.</span><span class="n">splitMulti</span><span class="p">(</span><span class="n">propagate_gq</span><span class="p">,</span> <span class="n">keep_star_alleles</span><span class="p">,</span> <span class="n">max_shift</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">jvds</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
    <span class="nd">@requireTGenotype</span>
<div class="viewcode-block" id="VariantDataset.tdt"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.tdt">[docs]</a>    <span class="k">def</span> <span class="nf">tdt</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fam</span><span class="p">,</span> <span class="n">root</span><span class="o">=</span><span class="s1">&#39;va.tdt&#39;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Find transmitted and untransmitted variants; count per variant and</span>
<span class="sd">        nuclear family.</span>

<span class="sd">        .. include:: requireTGenotype.rst</span>

<span class="sd">        **Examples**</span>

<span class="sd">        Compute TDT association results:</span>

<span class="sd">        &gt;&gt;&gt; (vds.tdt(&quot;data/trios.fam&quot;)</span>
<span class="sd">        ...     .export_variants(&quot;output/tdt_results.tsv&quot;, &quot;Variant = v, va.tdt.*&quot;))</span>

<span class="sd">        **Notes**</span>

<span class="sd">        The transmission disequilibrium test tracks the number of times the alternate allele is transmitted (t) or not transmitted (u) from a heterozgyous parent to an affected child under the null that the rate of such transmissions is 0.5.  For variants where transmission is guaranteed (i.e., the Y chromosome, mitochondria, and paternal chromosome X variants outside of the PAR), the test cannot be used.</span>

<span class="sd">        The TDT statistic is given by</span>

<span class="sd">        .. math::</span>

<span class="sd">            (t-u)^2 \over (t+u)</span>

<span class="sd">        and follows a 1 degree of freedom chi-squared distribution under the null hypothesis.</span>


<span class="sd">        The number of transmissions and untransmissions for each possible set of genotypes is determined from the table below.  The copy state of a locus with respect to a trio is defined as follows, where PAR is the pseudoautosomal region (PAR).</span>

<span class="sd">        - HemiX -- in non-PAR of X and child is male</span>
<span class="sd">        - Auto -- otherwise (in autosome or PAR, or child is female)</span>

<span class="sd">        +--------+--------+--------+------------+---+---+</span>
<span class="sd">        |  Kid   | Dad    | Mom    | Copy State | T | U |</span>
<span class="sd">        +========+========+========+============+===+===+</span>
<span class="sd">        | HomRef | Het    | Het    | Auto       | 0 | 2 |</span>
<span class="sd">        +--------+--------+--------+------------+---+---+</span>
<span class="sd">        | HomRef | HomRef | Het    | Auto       | 0 | 1 |</span>
<span class="sd">        +--------+--------+--------+------------+---+---+</span>
<span class="sd">        | HomRef | Het    | HomRef | Auto       | 0 | 1 |</span>
<span class="sd">        +--------+--------+--------+------------+---+---+</span>
<span class="sd">        | Het    | Het    | Het    | Auto       | 1 | 1 |</span>
<span class="sd">        +--------+--------+--------+------------+---+---+</span>
<span class="sd">        | Het    | HomRef | Het    | Auto       | 1 | 0 |</span>
<span class="sd">        +--------+--------+--------+------------+---+---+</span>
<span class="sd">        | Het    | Het    | HomRef | Auto       | 1 | 0 |</span>
<span class="sd">        +--------+--------+--------+------------+---+---+</span>
<span class="sd">        | Het    | HomVar | Het    | Auto       | 0 | 1 |</span>
<span class="sd">        +--------+--------+--------+------------+---+---+</span>
<span class="sd">        | Het    | Het    | HomVar | Auto       | 0 | 1 |</span>
<span class="sd">        +--------+--------+--------+------------+---+---+</span>
<span class="sd">        | HomVar | Het    | Het    | Auto       | 2 | 0 |</span>
<span class="sd">        +--------+--------+--------+------------+---+---+</span>
<span class="sd">        | HomVar | Het    | HomVar | Auto       | 1 | 0 |</span>
<span class="sd">        +--------+--------+--------+------------+---+---+</span>
<span class="sd">        | HomVar | HomVar | Het    | Auto       | 1 | 0 |</span>
<span class="sd">        +--------+--------+--------+------------+---+---+</span>
<span class="sd">        | HomRef | HomRef | Het    | HemiX      | 0 | 1 |</span>
<span class="sd">        +--------+--------+--------+------------+---+---+</span>
<span class="sd">        | HomRef | HomVar | Het    | HemiX      | 0 | 1 |</span>
<span class="sd">        +--------+--------+--------+------------+---+---+</span>
<span class="sd">        | HomVar | HomRef | Het    | HemiX      | 1 | 0 |</span>
<span class="sd">        +--------+--------+--------+------------+---+---+</span>
<span class="sd">        | HomVar | HomVar | Het    | HemiX      | 1 | 0 |</span>
<span class="sd">        +--------+--------+--------+------------+---+---+</span>


<span class="sd">        :py:meth:`~hail.VariantDataset.tdt` only considers complete trios (two parents and a proband) with defined sex.</span>

<span class="sd">        PAR is currently defined with respect to reference `GRCh37 &lt;http://www.ncbi.nlm.nih.gov/projects/genome/assembly/grc/human/&gt;`_:</span>

<span class="sd">        - X: 60001-2699520</span>
<span class="sd">        - X: 154931044-155260560</span>
<span class="sd">        - Y: 10001-2649520</span>
<span class="sd">        - Y: 59034050-59363566</span>

<span class="sd">        :py:meth:`~hail.VariantDataset.tdt` assumes all contigs apart from X and Y are fully autosomal; decoys, etc. are not given special treatment.</span>

<span class="sd">        **Annotations**</span>

<span class="sd">        :py:meth:`~hail.VariantDataset.tdt` adds the following annotations:</span>

<span class="sd">         - **tdt.nTransmitted** (*Int*) -- Number of transmitted alternate alleles.</span>

<span class="sd">         - **va.tdt.nUntransmitted** (*Int*) -- Number of untransmitted alternate alleles.</span>

<span class="sd">         - **va.tdt.chi2** (*Double*) -- TDT statistic.</span>

<span class="sd">         - **va.tdt.pval** (*Double*) -- p-value.</span>

<span class="sd">        :param str fam: Path to FAM file.</span>

<span class="sd">        :param root: Variant annotation root to store TDT result.</span>

<span class="sd">        :return: Variant dataset with TDT association results added to variant annotations.</span>
<span class="sd">        :rtype: :py:class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">jvds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvdf</span><span class="o">.</span><span class="n">tdt</span><span class="p">(</span><span class="n">fam</span><span class="p">,</span> <span class="n">root</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">jvds</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
    <span class="k">def</span> <span class="nf">_typecheck</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Check if all sample, variant and global annotations are consistent with the schema.&quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">typecheck</span><span class="p">()</span>

    <span class="nd">@handle_py4j</span>
    <span class="nd">@requireTGenotype</span>
<div class="viewcode-block" id="VariantDataset.variant_qc"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.variant_qc">[docs]</a>    <span class="k">def</span> <span class="nf">variant_qc</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">root</span><span class="o">=</span><span class="s1">&#39;va.qc&#39;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Compute common variant statistics (quality control metrics).</span>

<span class="sd">        .. include:: requireTGenotype.rst</span>

<span class="sd">        **Examples**</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds.variant_qc()</span>

<span class="sd">        .. _variantqc_annotations:</span>

<span class="sd">        **Annotations**</span>

<span class="sd">        :py:meth:`~hail.VariantDataset.variant_qc` computes 18 variant statistics from the </span>
<span class="sd">        genotype data and stores the results as variant annotations that can be accessed </span>
<span class="sd">        with ``va.qc.&lt;identifier&gt;`` (or ``&lt;root&gt;.&lt;identifier&gt;`` if a non-default root was passed):</span>

<span class="sd">        +---------------------------+--------+--------------------------------------------------------+</span>
<span class="sd">        | Name                      | Type   | Description                                            |</span>
<span class="sd">        +===========================+========+========================================================+</span>
<span class="sd">        | ``callRate``              | Double | Fraction of samples with called genotypes              |</span>
<span class="sd">        +---------------------------+--------+--------------------------------------------------------+</span>
<span class="sd">        | ``AF``                    | Double | Calculated minor allele frequency (q)                  |</span>
<span class="sd">        +---------------------------+--------+--------------------------------------------------------+</span>
<span class="sd">        | ``AC``                    | Int    | Count of alternate alleles                             |</span>
<span class="sd">        +---------------------------+--------+--------------------------------------------------------+</span>
<span class="sd">        | ``rHeterozygosity``       | Double | Proportion of heterozygotes                            |</span>
<span class="sd">        +---------------------------+--------+--------------------------------------------------------+</span>
<span class="sd">        | ``rHetHomVar``            | Double | Ratio of heterozygotes to homozygous alternates        |</span>
<span class="sd">        +---------------------------+--------+--------------------------------------------------------+</span>
<span class="sd">        | ``rExpectedHetFrequency`` | Double | Expected rHeterozygosity based on HWE                  |</span>
<span class="sd">        +---------------------------+--------+--------------------------------------------------------+</span>
<span class="sd">        | ``pHWE``                  | Double | p-value from Hardy Weinberg Equilibrium null model     |</span>
<span class="sd">        +---------------------------+--------+--------------------------------------------------------+</span>
<span class="sd">        | ``nHomRef``               | Int    | Number of homozygous reference samples                 |</span>
<span class="sd">        +---------------------------+--------+--------------------------------------------------------+</span>
<span class="sd">        | ``nHet``                  | Int    | Number of heterozygous samples                         |</span>
<span class="sd">        +---------------------------+--------+--------------------------------------------------------+</span>
<span class="sd">        | ``nHomVar``               | Int    | Number of homozygous alternate samples                 |</span>
<span class="sd">        +---------------------------+--------+--------------------------------------------------------+</span>
<span class="sd">        | ``nCalled``               | Int    | Sum of ``nHomRef``, ``nHet``, and ``nHomVar``          |</span>
<span class="sd">        +---------------------------+--------+--------------------------------------------------------+</span>
<span class="sd">        | ``nNotCalled``            | Int    | Number of uncalled samples                             |</span>
<span class="sd">        +---------------------------+--------+--------------------------------------------------------+</span>
<span class="sd">        | ``nNonRef``               | Int    | Sum of ``nHet`` and ``nHomVar``                        |</span>
<span class="sd">        +---------------------------+--------+--------------------------------------------------------+</span>
<span class="sd">        | ``rHetHomVar``            | Double | Het/HomVar ratio across all samples                    |</span>
<span class="sd">        +---------------------------+--------+--------------------------------------------------------+</span>
<span class="sd">        | ``dpMean``                | Double | Depth mean across all samples                          |</span>
<span class="sd">        +---------------------------+--------+--------------------------------------------------------+</span>
<span class="sd">        | ``dpStDev``               | Double | Depth standard deviation across all samples            |</span>
<span class="sd">        +---------------------------+--------+--------------------------------------------------------+</span>
<span class="sd">        | ``gqMean``                | Double | The average genotype quality across all samples        |</span>
<span class="sd">        +---------------------------+--------+--------------------------------------------------------+</span>
<span class="sd">        | ``gqStDev``               | Double | Genotype quality standard deviation across all samples |</span>
<span class="sd">        +---------------------------+--------+--------------------------------------------------------+</span>

<span class="sd">        Missing values ``NA`` may result (for example, due to division by zero) and are handled properly </span>
<span class="sd">        in filtering and written as &quot;NA&quot; in export modules. The empirical standard deviation is computed</span>
<span class="sd">        with zero degrees of freedom.</span>

<span class="sd">        :param str root: Variant annotation root for computed struct.</span>

<span class="sd">        :return: Annotated variant dataset with new variant QC annotations.</span>
<span class="sd">        :rtype: :py:class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">root</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">root</span><span class="p">,</span> <span class="n">unicode</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Parameter &#39;root&#39; must be type str, but found </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="nb">type</span><span class="p">(</span><span class="n">root</span><span class="p">))</span>

        <span class="n">jvds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvdf</span><span class="o">.</span><span class="n">variantQC</span><span class="p">(</span><span class="n">root</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">jvds</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.vep"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.vep">[docs]</a>    <span class="k">def</span> <span class="nf">vep</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">block_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">root</span><span class="o">=</span><span class="s1">&#39;va.vep&#39;</span><span class="p">,</span> <span class="n">csq</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Annotate variants with VEP.</span>

<span class="sd">        :py:meth:`~hail.VariantDataset.vep` runs `Variant Effect Predictor &lt;http://www.ensembl.org/info/docs/tools/vep/index.html&gt;`_ with</span>
<span class="sd">        the `LOFTEE plugin &lt;https://github.com/konradjk/loftee&gt;`_</span>
<span class="sd">        on the current variant dataset and adds the result as a variant annotation.</span>

<span class="sd">        If the variant annotation path defined by ``root`` already exists and its schema matches the VEP schema, then</span>
<span class="sd">        Hail only runs VEP for variants for which the annotation is missing.</span>

<span class="sd">        **Examples**</span>

<span class="sd">        Add VEP annotations to the dataset:</span>

<span class="sd">        &gt;&gt;&gt; vds_result = vds.vep(&quot;data/vep.properties&quot;) # doctest: +SKIP</span>

<span class="sd">        **Configuration**</span>

<span class="sd">        :py:meth:`~hail.VariantDataset.vep` needs a configuration file to tell it how to run</span>
<span class="sd">        VEP. The format is a `.properties file &lt;https://en.wikipedia.org/wiki/.properties&gt;`_.</span>
<span class="sd">        Roughly, each line defines a property as a key-value pair of the form `key = value`. `vep` supports the following properties:</span>

<span class="sd">        - **hail.vep.perl** -- Location of Perl. Optional, default: perl.</span>
<span class="sd">        - **hail.vep.perl5lib** -- Value for the PERL5LIB environment variable when invoking VEP. Optional, by default PERL5LIB is not set.</span>
<span class="sd">        - **hail.vep.path** -- Value of the PATH environment variable when invoking VEP.  Optional, by default PATH is not set.</span>
<span class="sd">        - **hail.vep.location** -- Location of the VEP Perl script.  Required.</span>
<span class="sd">        - **hail.vep.cache_dir** -- Location of the VEP cache dir, passed to VEP with the `--dir` option.  Required.</span>
<span class="sd">        - **hail.vep.fasta** -- Location of the FASTA file to use to look up the reference sequence, passed to VEP with the `--fasta` option.  Required.</span>
<span class="sd">        - **hail.vep.lof.human_ancestor** -- Location of the human ancestor file for the LOFTEE plugin.  Required.</span>
<span class="sd">        - **hail.vep.lof.conservation_file** -- Location of the conservation file for the LOFTEE plugin.  Required.</span>

<span class="sd">        Here is an example `vep.properties` configuration file</span>

<span class="sd">        .. code-block:: text</span>

<span class="sd">            hail.vep.perl = /usr/bin/perl</span>
<span class="sd">            hail.vep.path = /usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin</span>
<span class="sd">            hail.vep.location = /path/to/vep/ensembl-tools-release-81/scripts/variant_effect_predictor/variant_effect_predictor.pl</span>
<span class="sd">            hail.vep.cache_dir = /path/to/vep</span>
<span class="sd">            hail.vep.lof.human_ancestor = /path/to/loftee_data/human_ancestor.fa.gz</span>
<span class="sd">            hail.vep.lof.conservation_file = /path/to/loftee_data//phylocsf.sql</span>

<span class="sd">        **VEP Invocation**</span>

<span class="sd">        .. code-block:: text</span>

<span class="sd">            &lt;hail.vep.perl&gt;</span>
<span class="sd">            &lt;hail.vep.location&gt;</span>
<span class="sd">            --format vcf</span>
<span class="sd">            --json</span>
<span class="sd">            --everything</span>
<span class="sd">            --allele_number</span>
<span class="sd">            --no_stats</span>
<span class="sd">            --cache --offline</span>
<span class="sd">            --dir &lt;hail.vep.cache_dir&gt;</span>
<span class="sd">            --fasta &lt;hail.vep.cache_dir&gt;/homo_sapiens/81_GRCh37/Homo_sapiens.GRCh37.75.dna.primary_assembly.fa</span>
<span class="sd">            --minimal</span>
<span class="sd">            --assembly GRCh37</span>
<span class="sd">            --plugin LoF,human_ancestor_fa:$&lt;hail.vep.lof.human_ancestor&gt;,filter_position:0.05,min_intron_size:15,conservation_file:&lt;hail.vep.lof.conservation_file&gt;</span>
<span class="sd">            -o STDOUT</span>

<span class="sd">        **Annotations**</span>

<span class="sd">        Annotations with the following schema are placed in the location specified by ``root``.</span>
<span class="sd">        The schema can be confirmed with :py:attr:`~hail.VariantDataset.variant_schema`, :py:attr:`~hail.VariantDataset.sample_schema`, and :py:attr:`~hail.VariantDataset.global_schema`.</span>

<span class="sd">        .. code-block:: text</span>

<span class="sd">            Struct{</span>
<span class="sd">              assembly_name: String,</span>
<span class="sd">              allele_string: String,</span>
<span class="sd">              colocated_variants: Array[Struct{</span>
<span class="sd">                aa_allele: String,</span>
<span class="sd">                aa_maf: Double,</span>
<span class="sd">                afr_allele: String,</span>
<span class="sd">                afr_maf: Double,</span>
<span class="sd">                allele_string: String,</span>
<span class="sd">                amr_allele: String,</span>
<span class="sd">                amr_maf: Double,</span>
<span class="sd">                clin_sig: Array[String],</span>
<span class="sd">                end: Int,</span>
<span class="sd">                eas_allele: String,</span>
<span class="sd">                eas_maf: Double,</span>
<span class="sd">                ea_allele: String,,</span>
<span class="sd">                ea_maf: Double,</span>
<span class="sd">                eur_allele: String,</span>
<span class="sd">                eur_maf: Double,</span>
<span class="sd">                exac_adj_allele: String,</span>
<span class="sd">                exac_adj_maf: Double,</span>
<span class="sd">                exac_allele: String,</span>
<span class="sd">                exac_afr_allele: String,</span>
<span class="sd">                exac_afr_maf: Double,</span>
<span class="sd">                exac_amr_allele: String,</span>
<span class="sd">                exac_amr_maf: Double,</span>
<span class="sd">                exac_eas_allele: String,</span>
<span class="sd">                exac_eas_maf: Double,</span>
<span class="sd">                exac_fin_allele: String,</span>
<span class="sd">                exac_fin_maf: Double,</span>
<span class="sd">                exac_maf: Double,</span>
<span class="sd">                exac_nfe_allele: String,</span>
<span class="sd">                exac_nfe_maf: Double,</span>
<span class="sd">                exac_oth_allele: String,</span>
<span class="sd">                exac_oth_maf: Double,</span>
<span class="sd">                exac_sas_allele: String,</span>
<span class="sd">                exac_sas_maf: Double,</span>
<span class="sd">                id: String,</span>
<span class="sd">                minor_allele: String,</span>
<span class="sd">                minor_allele_freq: Double,</span>
<span class="sd">                phenotype_or_disease: Int,</span>
<span class="sd">                pubmed: Array[Int],</span>
<span class="sd">                sas_allele: String,</span>
<span class="sd">                sas_maf: Double,</span>
<span class="sd">                somatic: Int,</span>
<span class="sd">                start: Int,</span>
<span class="sd">                strand: Int</span>
<span class="sd">              }],</span>
<span class="sd">              end: Int,</span>
<span class="sd">              id: String,</span>
<span class="sd">              input: String,</span>
<span class="sd">              intergenic_consequences: Array[Struct{</span>
<span class="sd">                allele_num: Int,</span>
<span class="sd">                consequence_terms: Array[String],</span>
<span class="sd">                impact: String,</span>
<span class="sd">                minimised: Int,</span>
<span class="sd">                variant_allele: String</span>
<span class="sd">              }],</span>
<span class="sd">              most_severe_consequence: String,</span>
<span class="sd">              motif_feature_consequences: Array[Struct{</span>
<span class="sd">                allele_num: Int,</span>
<span class="sd">                consequence_terms: Array[String],</span>
<span class="sd">                high_inf_pos: String,</span>
<span class="sd">                impact: String,</span>
<span class="sd">                minimised: Int,</span>
<span class="sd">                motif_feature_id: String,</span>
<span class="sd">                motif_name: String,</span>
<span class="sd">                motif_pos: Int,</span>
<span class="sd">                motif_score_change: Double,</span>
<span class="sd">                strand: Int,</span>
<span class="sd">                variant_allele: String</span>
<span class="sd">              }],</span>
<span class="sd">              regulatory_feature_consequences: Array[Struct{</span>
<span class="sd">                allele_num: Int,</span>
<span class="sd">                biotype: String,</span>
<span class="sd">                consequence_terms: Array[String],</span>
<span class="sd">                impact: String,</span>
<span class="sd">                minimised: Int,</span>
<span class="sd">                regulatory_feature_id: String,</span>
<span class="sd">                variant_allele: String</span>
<span class="sd">              }],</span>
<span class="sd">              seq_region_name: String,</span>
<span class="sd">              start: Int,</span>
<span class="sd">              strand: Int,</span>
<span class="sd">              transcript_consequences: Array[Struct{</span>
<span class="sd">                allele_num: Int,</span>
<span class="sd">                amino_acids: String,</span>
<span class="sd">                biotype: String,</span>
<span class="sd">                canonical: Int,</span>
<span class="sd">                ccds: String,</span>
<span class="sd">                cdna_start: Int,</span>
<span class="sd">                cdna_end: Int,</span>
<span class="sd">                cds_end: Int,</span>
<span class="sd">                cds_start: Int,</span>
<span class="sd">                codons: String,</span>
<span class="sd">                consequence_terms: Array[String],</span>
<span class="sd">                distance: Int,</span>
<span class="sd">                domains: Array[Struct{</span>
<span class="sd">                  db: String</span>
<span class="sd">                  name: String</span>
<span class="sd">                }],</span>
<span class="sd">                exon: String,</span>
<span class="sd">                gene_id: String,</span>
<span class="sd">                gene_pheno: Int,</span>
<span class="sd">                gene_symbol: String,</span>
<span class="sd">                gene_symbol_source: String,</span>
<span class="sd">                hgnc_id: Int,</span>
<span class="sd">                hgvsc: String,</span>
<span class="sd">                hgvsp: String,</span>
<span class="sd">                hgvs_offset: Int,</span>
<span class="sd">                impact: String,</span>
<span class="sd">                intron: String,</span>
<span class="sd">                lof: String,</span>
<span class="sd">                lof_flags: String,</span>
<span class="sd">                lof_filter: String,</span>
<span class="sd">                lof_info: String,</span>
<span class="sd">                minimised: Int,</span>
<span class="sd">                polyphen_prediction: String,</span>
<span class="sd">                polyphen_score: Double,</span>
<span class="sd">                protein_end: Int,</span>
<span class="sd">                protein_start: Int,</span>
<span class="sd">                protein_id: String,</span>
<span class="sd">                sift_prediction: String,</span>
<span class="sd">                sift_score: Double,</span>
<span class="sd">                strand: Int,</span>
<span class="sd">                swissprot: String,</span>
<span class="sd">                transcript_id: String,</span>
<span class="sd">                trembl: String,</span>
<span class="sd">                uniparc: String,</span>
<span class="sd">                variant_allele: String</span>
<span class="sd">              }],</span>
<span class="sd">              variant_class: String</span>
<span class="sd">            }</span>

<span class="sd">        :param str config: Path to VEP configuration file.</span>

<span class="sd">        :param block_size: Number of variants to annotate per VEP invocation.</span>
<span class="sd">        :type block_size: int</span>

<span class="sd">        :param str root: Variant annotation path to store VEP output.</span>

<span class="sd">        :param bool force: If True, force VEP annotation from scratch.</span>

<span class="sd">        :param bool csq: If True, annotates VCF CSQ field as a String.</span>
<span class="sd">            If False, annotates with the full nested struct schema</span>

<span class="sd">        :return: An annotated with variant annotations from VEP.</span>
<span class="sd">        :rtype: :py:class:`.VariantDataset`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">jvds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">vep</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">root</span><span class="p">,</span> <span class="n">csq</span><span class="p">,</span> <span class="n">block_size</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">VariantDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">jvds</span><span class="p">)</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.variants_keytable"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.variants_keytable">[docs]</a>    <span class="k">def</span> <span class="nf">variants_keytable</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Convert variants and variant annotations to a KeyTable.</span>

<span class="sd">        The resulting KeyTable has schema:</span>

<span class="sd">        .. code-block:: text</span>

<span class="sd">          Struct {</span>
<span class="sd">            v: Variant</span>
<span class="sd">            va: variant annotations</span>
<span class="sd">          }</span>

<span class="sd">        with a single key ``v``.</span>

<span class="sd">        :return: Key table with variants and variant annotations.</span>
<span class="sd">        :rtype: :class:`.KeyTable`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">KeyTable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">variantsKT</span><span class="p">())</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.samples_keytable"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.samples_keytable">[docs]</a>    <span class="k">def</span> <span class="nf">samples_keytable</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Convert samples and sample annotations to KeyTable.</span>

<span class="sd">        The resulting KeyTable has schema:</span>

<span class="sd">        .. code-block:: text</span>

<span class="sd">          Struct {</span>
<span class="sd">            s: Sample</span>
<span class="sd">            sa: sample annotations</span>
<span class="sd">          }</span>

<span class="sd">        with a single key ``s``.</span>

<span class="sd">        :return: Key table with samples and sample annotations.</span>
<span class="sd">        :rtype: :class:`.KeyTable`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">KeyTable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">samplesKT</span><span class="p">())</span></div>

    <span class="nd">@handle_py4j</span>
<div class="viewcode-block" id="VariantDataset.make_keytable"><a class="viewcode-back" href="../../hail.VariantDataset.html#hail.VariantDataset.make_keytable">[docs]</a>    <span class="k">def</span> <span class="nf">make_keytable</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variant_expr</span><span class="p">,</span> <span class="n">genotype_expr</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="p">[],</span> <span class="n">separator</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Make a KeyTable with one row per variant.</span>

<span class="sd">        Per sample field names in the result are formed by</span>
<span class="sd">        concatenating the sample ID with the ``genotype_expr`` left</span>
<span class="sd">        hand side with ``seperator`` (default: dot (.)).  If the left</span>
<span class="sd">        hand side is empty::</span>

<span class="sd">          `` = expr</span>

<span class="sd">        then the dot (.) is ommited.</span>

<span class="sd">        **Examples**</span>

<span class="sd">        Consider a :py:class:`VariantDataset` ``vds`` with 2 variants and 3 samples:</span>

<span class="sd">        .. code-block:: text</span>

<span class="sd">          Variant	FORMAT	A	B	C</span>
<span class="sd">          1:1:A:T	GT:GQ	0/1:99	./.	0/0:99</span>
<span class="sd">          1:2:G:C	GT:GQ	0/1:89	0/1:99	1/1:93</span>

<span class="sd">        Then:</span>

<span class="sd">        &gt;&gt;&gt; kt = vds.make_keytable(&#39;v = v&#39;, [&#39;gt = g.gt&#39;, &#39;gq = g.gq&#39;])</span>

<span class="sd">        returns a :py:class:`KeyTable` with schema</span>

<span class="sd">        .. code-block:: text</span>

<span class="sd">            v: Variant</span>
<span class="sd">            A.gt: Int</span>
<span class="sd">            B.gt: Int</span>
<span class="sd">            C.gt: Int</span>
<span class="sd">            A.gq: Int</span>
<span class="sd">            B.gq: Int</span>
<span class="sd">            C.gq: Int</span>

<span class="sd">        in particular, the values would be</span>

<span class="sd">        .. code-block:: text</span>

<span class="sd">            v	A.gt	B.gt	C.gt	A.gq	B.gq	C.gq</span>
<span class="sd">            1:1:A:T	1	NA	0	99	NA	99</span>
<span class="sd">            1:2:G:C	1	1	2	89	99	93</span>

<span class="sd">        :param variant_expr: Variant annotation expressions.</span>
<span class="sd">        :type variant_expr: str or list of str</span>

<span class="sd">        :param genotype_expr: Genotype annotation expressions.</span>
<span class="sd">        :type genotype_expr: str or list of str</span>

<span class="sd">        :param key: List of key columns.</span>
<span class="sd">        :type key: str or list of str</span>

<span class="sd">        :param str separator: Seperator to use between sample IDs and genotype expression left hand side identifiers.</span>

<span class="sd">        :rtype: :py:class:`.KeyTable`</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">variant_expr</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">variant_expr</span> <span class="o">=</span> <span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">variant_expr</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">genotype_expr</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">genotype_expr</span> <span class="o">=</span> <span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">genotype_expr</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">key</span> <span class="o">=</span> <span class="p">[</span><span class="n">key</span><span class="p">]</span>

        <span class="n">jkt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jvds</span><span class="o">.</span><span class="n">makeKT</span><span class="p">(</span><span class="n">variant_expr</span><span class="p">,</span> <span class="n">genotype_expr</span><span class="p">,</span>
                                <span class="n">jarray</span><span class="p">(</span><span class="n">Env</span><span class="o">.</span><span class="n">jvm</span><span class="p">()</span><span class="o">.</span><span class="n">java</span><span class="o">.</span><span class="n">lang</span><span class="o">.</span><span class="n">String</span><span class="p">,</span> <span class="n">key</span><span class="p">),</span> <span class="n">separator</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">KeyTable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="p">,</span> <span class="n">jkt</span><span class="p">)</span></div></div>
</pre></div>

           </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016, Hail Team.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../',
            VERSION:'devel',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      <script type="text/javascript" src="../../../bootstrap.min.js"></script>

  

  
  
    <script type="text/javascript" src="../../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
  
  
   

</body>
</html>